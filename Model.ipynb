{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,RobustScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train                 = pd.read_csv('Data/train.csv')\n",
    "test                  = pd.read_csv('Data/test.csv')\n",
    "monthly_expenditures  = pd.read_csv('Data/monthly_expenditures.csv')\n",
    "sample_submission     = pd.read_csv('Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_egitim                       = LabelEncoder().fit(train['egitim'])\n",
    "train['egitim']                 = le_egitim.transform(train['egitim'])\n",
    "test['egitim']                  = le_egitim.transform(test['egitim'])\n",
    "\n",
    "\n",
    "le_is_durumu                    = LabelEncoder().fit(train['is_durumu'])\n",
    "train['is_durumu']              = le_is_durumu.transform(train['is_durumu'])\n",
    "test['is_durumu']               = le_is_durumu.transform(test['is_durumu'])\n",
    "\n",
    "le_meslek_grubu                 = LabelEncoder().fit(train['meslek_grubu'])\n",
    "train['meslek_grubu']           = le_meslek_grubu.transform(train['meslek_grubu'])\n",
    "test['meslek_grubu']            = le_meslek_grubu.transform(test['meslek_grubu'])\n",
    "\n",
    "le_musteri                      = LabelEncoder().fit(monthly_expenditures['musteri'])\n",
    "train['musteri']                = le_musteri.transform(train['musteri'])\n",
    "test['musteri']                 = le_musteri.transform(test['musteri'])\n",
    "monthly_expenditures['musteri'] = le_musteri.transform(monthly_expenditures['musteri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplam_islem_adedi = monthly_expenditures.groupby('musteri',as_index=False)[['islem_adedi']].sum().rename(columns={'islem_adedi':'toplam_islem_adedi'})\n",
    "\n",
    "toplam_islem_tutari = monthly_expenditures.groupby('musteri',as_index=False)[['aylik_toplam_tutar']].sum().rename(columns={'aylik_toplam_tutar':'toplam_islem_tutari'})\n",
    "\n",
    "aylik_ortalama_islem_adedi = monthly_expenditures.groupby(['musteri','tarih'],as_index=False)[['islem_adedi']].sum().groupby('musteri',as_index=False)[['islem_adedi']].mean().rename(columns={'islem_adedi':'aylik_ortalama_islem_adedi'})\n",
    "\n",
    "aylik_ortalama_islem_tutari = monthly_expenditures.groupby(['musteri','tarih'],as_index=False)[['aylik_toplam_tutar']].sum().groupby('musteri',as_index=False)[['aylik_toplam_tutar']].mean().rename(columns={'aylik_toplam_tutar':'aylik_ortalama_islem_tutari'})\n",
    "\n",
    "\n",
    "musteri_bilgileri = pd.merge(pd.merge(toplam_islem_adedi,toplam_islem_tutari,on='musteri'),pd.merge(aylik_ortalama_islem_adedi,aylik_ortalama_islem_tutari,on='musteri'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>musteri</th>\n",
       "      <th>toplam_islem_adedi</th>\n",
       "      <th>toplam_islem_tutari</th>\n",
       "      <th>aylik_ortalama_islem_adedi</th>\n",
       "      <th>aylik_ortalama_islem_tutari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>363.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>3830.0</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>5610.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>935.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99995</td>\n",
       "      <td>7</td>\n",
       "      <td>450.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99996</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99997</td>\n",
       "      <td>18</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>983.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99998</td>\n",
       "      <td>39</td>\n",
       "      <td>10160.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1693.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>510.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       musteri  toplam_islem_adedi  toplam_islem_tutari  \\\n",
       "0            0                   7               1470.0   \n",
       "1            1                   6               1090.0   \n",
       "2            2                  31               3830.0   \n",
       "3            3                   3                300.0   \n",
       "4            4                  33               5610.0   \n",
       "...        ...                 ...                  ...   \n",
       "99995    99995                   7                450.0   \n",
       "99996    99996                   1                 10.0   \n",
       "99997    99997                  18               2950.0   \n",
       "99998    99998                  39              10160.0   \n",
       "99999    99999                   2                510.0   \n",
       "\n",
       "       aylik_ortalama_islem_adedi  aylik_ortalama_islem_tutari  \n",
       "0                        7.000000                  1470.000000  \n",
       "1                        2.000000                   363.333333  \n",
       "2                        6.200000                   766.000000  \n",
       "3                        3.000000                   300.000000  \n",
       "4                        5.500000                   935.000000  \n",
       "...                           ...                          ...  \n",
       "99995                    2.333333                   150.000000  \n",
       "99996                    1.000000                    10.000000  \n",
       "99997                    6.000000                   983.333333  \n",
       "99998                    6.500000                  1693.333333  \n",
       "99999                    1.000000                   255.000000  \n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musteri_bilgileri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "aylik_toplam_islem_tutari = pd.pivot_table(monthly_expenditures,index='musteri', columns='tarih',aggfunc='sum',values='aylik_toplam_tutar',fill_value=0).add_prefix('toplam_islem_tutari_').reset_index()\n",
    "\n",
    "aylik_toplam_islem_adedi = pd.pivot_table(monthly_expenditures,index='musteri', columns='tarih',aggfunc='sum',values='islem_adedi',fill_value=0).add_prefix('toplam_islem_adedi_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "musteri_bilgileri = pd.merge(musteri_bilgileri,pd.merge(aylik_toplam_islem_tutari,aylik_toplam_islem_adedi,on='musteri'),on='musteri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.merge(train,musteri_bilgileri,on='musteri').drop(columns=['target','musteri','tarih'])\n",
    "y_train = pd.merge(train,musteri_bilgileri,on='musteri')[['target']]\n",
    "\n",
    "x_test  = pd.merge(test,musteri_bilgileri,on='musteri').drop(columns=['tarih','musteri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yas</th>\n",
       "      <th>kidem_suresi</th>\n",
       "      <th>egitim</th>\n",
       "      <th>is_durumu</th>\n",
       "      <th>meslek_grubu</th>\n",
       "      <th>toplam_islem_adedi</th>\n",
       "      <th>toplam_islem_tutari</th>\n",
       "      <th>aylik_ortalama_islem_adedi</th>\n",
       "      <th>aylik_ortalama_islem_tutari</th>\n",
       "      <th>toplam_islem_tutari_20190101</th>\n",
       "      <th>...</th>\n",
       "      <th>toplam_islem_tutari_20190301</th>\n",
       "      <th>toplam_islem_tutari_20190401</th>\n",
       "      <th>toplam_islem_tutari_20190501</th>\n",
       "      <th>toplam_islem_tutari_20190601</th>\n",
       "      <th>toplam_islem_adedi_20190101</th>\n",
       "      <th>toplam_islem_adedi_20190201</th>\n",
       "      <th>toplam_islem_adedi_20190301</th>\n",
       "      <th>toplam_islem_adedi_20190401</th>\n",
       "      <th>toplam_islem_adedi_20190501</th>\n",
       "      <th>toplam_islem_adedi_20190601</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>8150.0</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>1630.000000</td>\n",
       "      <td>430</td>\n",
       "      <td>...</td>\n",
       "      <td>1540</td>\n",
       "      <td>3770</td>\n",
       "      <td>1470</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>916.666667</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>1800</td>\n",
       "      <td>3380</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4020.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4020.000000</td>\n",
       "      <td>4020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>4770.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1192.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>1480</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>22.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>41.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>5330.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>888.333333</td>\n",
       "      <td>270</td>\n",
       "      <td>...</td>\n",
       "      <td>1540</td>\n",
       "      <td>400</td>\n",
       "      <td>1530</td>\n",
       "      <td>1280</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>31.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>39.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>21900.0</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>3650.000000</td>\n",
       "      <td>1510</td>\n",
       "      <td>...</td>\n",
       "      <td>2280</td>\n",
       "      <td>3860</td>\n",
       "      <td>1900</td>\n",
       "      <td>6400</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        yas  kidem_suresi  egitim  is_durumu  meslek_grubu  \\\n",
       "0      44.0          46.0       2          5             3   \n",
       "1      39.0         194.0       0          5             3   \n",
       "2      38.0         182.0       4         10             3   \n",
       "3      34.0         101.0       2          6             3   \n",
       "4      41.0         125.0       3          0            15   \n",
       "...     ...           ...     ...        ...           ...   \n",
       "59995  20.0          24.0       2          3            20   \n",
       "59996  22.0          56.0       4         10            20   \n",
       "59997  41.0         188.0       4          9            18   \n",
       "59998  31.0         143.0       4          6             1   \n",
       "59999  39.0         252.0       4          9            14   \n",
       "\n",
       "       toplam_islem_adedi  toplam_islem_tutari  aylik_ortalama_islem_adedi  \\\n",
       "0                      28               8150.0                    5.600000   \n",
       "1                      14               5500.0                    2.333333   \n",
       "2                       1                 40.0                    1.000000   \n",
       "3                       1               2700.0                    1.000000   \n",
       "4                       5               4020.0                    5.000000   \n",
       "...                   ...                  ...                         ...   \n",
       "59995                  20               4770.0                    5.000000   \n",
       "59996                   1                 10.0                    1.000000   \n",
       "59997                  26               5330.0                    4.333333   \n",
       "59998                   1                 30.0                    1.000000   \n",
       "59999                  57              21900.0                    9.500000   \n",
       "\n",
       "       aylik_ortalama_islem_tutari  toplam_islem_tutari_20190101  ...  \\\n",
       "0                      1630.000000                           430  ...   \n",
       "1                       916.666667                            90  ...   \n",
       "2                        40.000000                             0  ...   \n",
       "3                      2700.000000                             0  ...   \n",
       "4                      4020.000000                          4020  ...   \n",
       "...                            ...                           ...  ...   \n",
       "59995                  1192.500000                             0  ...   \n",
       "59996                    10.000000                             0  ...   \n",
       "59997                   888.333333                           270  ...   \n",
       "59998                    30.000000                             0  ...   \n",
       "59999                  3650.000000                          1510  ...   \n",
       "\n",
       "       toplam_islem_tutari_20190301  toplam_islem_tutari_20190401  \\\n",
       "0                              1540                          3770   \n",
       "1                                70                            90   \n",
       "2                                 0                             0   \n",
       "3                                 0                             0   \n",
       "4                                 0                             0   \n",
       "...                             ...                           ...   \n",
       "59995                          1710                             0   \n",
       "59996                            10                             0   \n",
       "59997                          1540                           400   \n",
       "59998                             0                             0   \n",
       "59999                          2280                          3860   \n",
       "\n",
       "       toplam_islem_tutari_20190501  toplam_islem_tutari_20190601  \\\n",
       "0                              1470                             0   \n",
       "1                              1800                          3380   \n",
       "2                                 0                             0   \n",
       "3                              2700                             0   \n",
       "4                                 0                             0   \n",
       "...                             ...                           ...   \n",
       "59995                          1480                          1440   \n",
       "59996                             0                             0   \n",
       "59997                          1530                          1280   \n",
       "59998                            30                             0   \n",
       "59999                          1900                          6400   \n",
       "\n",
       "       toplam_islem_adedi_20190101  toplam_islem_adedi_20190201  \\\n",
       "0                                4                            6   \n",
       "1                                2                            1   \n",
       "2                                0                            1   \n",
       "3                                0                            0   \n",
       "4                                5                            0   \n",
       "...                            ...                          ...   \n",
       "59995                            0                            2   \n",
       "59996                            0                            0   \n",
       "59997                            2                            3   \n",
       "59998                            0                            0   \n",
       "59999                            7                           10   \n",
       "\n",
       "       toplam_islem_adedi_20190301  toplam_islem_adedi_20190401  \\\n",
       "0                                7                            8   \n",
       "1                                1                            2   \n",
       "2                                0                            0   \n",
       "3                                0                            0   \n",
       "4                                0                            0   \n",
       "...                            ...                          ...   \n",
       "59995                            8                            0   \n",
       "59996                            1                            0   \n",
       "59997                            6                            4   \n",
       "59998                            0                            0   \n",
       "59999                            9                           10   \n",
       "\n",
       "       toplam_islem_adedi_20190501  toplam_islem_adedi_20190601  \n",
       "0                                3                            0  \n",
       "1                                4                            4  \n",
       "2                                0                            0  \n",
       "3                                1                            0  \n",
       "4                                0                            0  \n",
       "...                            ...                          ...  \n",
       "59995                            6                            4  \n",
       "59996                            0                            0  \n",
       "59997                            7                            4  \n",
       "59998                            1                            0  \n",
       "59999                            9                           12  \n",
       "\n",
       "[60000 rows x 21 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(12,10))\n",
    "corr = pd.concat([x_train,y_train],axis=1).corr()\n",
    "sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"Set3\",fmt='.1f',annot=True,vmin=-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler  = StandardScaler().fit(x_train)\n",
    "\n",
    "scaled_x_train   = standard_scaler.transform(x_train)\n",
    "scaled_x_test    = standard_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler  = RobustScaler().fit(x_train)\n",
    "\n",
    "scaled_x_train = robust_scaler.transform(x_train)\n",
    "scaled_x_test = robust_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler  = MinMaxScaler().fit(x_train)\n",
    "\n",
    "scaled_x_train = minmax_scaler.transform(x_train)\n",
    "scaled_x_test = minmax_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_over_sampling = SMOTE(random_state=1)\n",
    "x_train_resampled, y_train_resampled = smote_over_sampling.fit_sample(scaled_x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = 0\n",
    "sample_submission.to_csv('Submission/Submission_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/Ä°ÅŸBankasÄ± ML Challenge TR 3/venv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/sufyan/Desktop/Ä°ÅŸBankasÄ± ML Challenge TR 3/venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:15:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(x_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9683592981452003"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train_resampled, xgb_classifier.predict(x_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = xgb_classifier.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-316-aee262032cd6>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_classifier.fit(x_train_resampled, y_train_resampled)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(x_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999982626522351"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train_resampled, rf_classifier.predict(x_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = rf_classifier.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\"balanced\",np.unique(y_train['target']), y_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52119527, 12.29508197])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-342-d30d36755bc2>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_classifier.fit(scaled_x_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.52119527, 1: 12.29508197})"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(class_weight={1:12.29508197, 0:0.52119527})\n",
    "\n",
    "rf_classifier.fit(scaled_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995903318312167"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, rf_classifier.predict(scaled_x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = rf_classifier.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(scaled_x_train.shape[1],)),\n",
    "keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "keras.layers.Dense(90, activation=tf.nn.relu),\n",
    "keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "keras.layers.Dense(30, activation=tf.nn.relu),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 60)                1860      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 90)                5490      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 15,002\n",
      "Trainable params: 15,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "47168/48000 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/Ä°ÅŸBankasÄ± ML Challenge TR 3/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1634 - accuracy: 0.9588 - val_loss: 0.1596 - val_accuracy: 0.9596\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1570 - accuracy: 0.9593 - val_loss: 0.1549 - val_accuracy: 0.9596\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1566 - accuracy: 0.9593 - val_loss: 0.1544 - val_accuracy: 0.9596\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 2s 31us/sample - loss: 0.1563 - accuracy: 0.9593 - val_loss: 0.1547 - val_accuracy: 0.9596\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1556 - accuracy: 0.9593 - val_loss: 0.1561 - val_accuracy: 0.9596\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1554 - accuracy: 0.9593 - val_loss: 0.1549 - val_accuracy: 0.9596\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1551 - accuracy: 0.9593 - val_loss: 0.1547 - val_accuracy: 0.9596\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1550 - accuracy: 0.9593 - val_loss: 0.1546 - val_accuracy: 0.9596\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1543 - accuracy: 0.9593 - val_loss: 0.1564 - val_accuracy: 0.9596\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1542 - accuracy: 0.9593 - val_loss: 0.1546 - val_accuracy: 0.9596\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1541 - accuracy: 0.9593 - val_loss: 0.1542 - val_accuracy: 0.9596\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.1539 - accuracy: 0.9593 - val_loss: 0.1545 - val_accuracy: 0.9596\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1535 - accuracy: 0.9593 - val_loss: 0.1544 - val_accuracy: 0.9596\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1533 - accuracy: 0.9593 - val_loss: 0.1547 - val_accuracy: 0.9596\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1531 - accuracy: 0.9593 - val_loss: 0.1554 - val_accuracy: 0.9596\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1530 - accuracy: 0.9593 - val_loss: 0.1562 - val_accuracy: 0.9596\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1525 - accuracy: 0.9593 - val_loss: 0.1564 - val_accuracy: 0.9596\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1526 - accuracy: 0.9593 - val_loss: 0.1547 - val_accuracy: 0.9596\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.1521 - accuracy: 0.9593 - val_loss: 0.1549 - val_accuracy: 0.9596\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1517 - accuracy: 0.9593 - val_loss: 0.1553 - val_accuracy: 0.9596\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1516 - accuracy: 0.9593 - val_loss: 0.1555 - val_accuracy: 0.9596\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1513 - accuracy: 0.9593 - val_loss: 0.1554 - val_accuracy: 0.9596\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1512 - accuracy: 0.9593 - val_loss: 0.1557 - val_accuracy: 0.9596\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1509 - accuracy: 0.9593 - val_loss: 0.1568 - val_accuracy: 0.9596\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1505 - accuracy: 0.9592 - val_loss: 0.1579 - val_accuracy: 0.9588\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.1505 - accuracy: 0.9593 - val_loss: 0.1568 - val_accuracy: 0.9596\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1500 - accuracy: 0.9592 - val_loss: 0.1558 - val_accuracy: 0.9596\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1499 - accuracy: 0.9593 - val_loss: 0.1583 - val_accuracy: 0.9596\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1494 - accuracy: 0.9593 - val_loss: 0.1581 - val_accuracy: 0.9596\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1493 - accuracy: 0.9592 - val_loss: 0.1582 - val_accuracy: 0.9594\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1493 - accuracy: 0.9593 - val_loss: 0.1622 - val_accuracy: 0.9595\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1491 - accuracy: 0.9592 - val_loss: 0.1577 - val_accuracy: 0.9594\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1487 - accuracy: 0.9593 - val_loss: 0.1602 - val_accuracy: 0.9591\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1487 - accuracy: 0.9592 - val_loss: 0.1599 - val_accuracy: 0.9593\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1481 - accuracy: 0.9593 - val_loss: 0.1594 - val_accuracy: 0.9593\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1481 - accuracy: 0.9593 - val_loss: 0.1579 - val_accuracy: 0.9594\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1477 - accuracy: 0.9593 - val_loss: 0.1604 - val_accuracy: 0.9596\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1473 - accuracy: 0.9595 - val_loss: 0.1593 - val_accuracy: 0.9593\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1470 - accuracy: 0.9592 - val_loss: 0.1629 - val_accuracy: 0.9595\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1467 - accuracy: 0.9593 - val_loss: 0.1607 - val_accuracy: 0.9590\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1464 - accuracy: 0.9595 - val_loss: 0.1612 - val_accuracy: 0.9586\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1462 - accuracy: 0.9594 - val_loss: 0.1609 - val_accuracy: 0.9593\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1458 - accuracy: 0.9593 - val_loss: 0.1645 - val_accuracy: 0.9590\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1459 - accuracy: 0.9594 - val_loss: 0.1640 - val_accuracy: 0.9592\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1453 - accuracy: 0.9595 - val_loss: 0.1628 - val_accuracy: 0.9584\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 2s 43us/sample - loss: 0.1451 - accuracy: 0.9594 - val_loss: 0.1660 - val_accuracy: 0.9582\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1450 - accuracy: 0.9597 - val_loss: 0.1627 - val_accuracy: 0.9590\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.1447 - accuracy: 0.9595 - val_loss: 0.1644 - val_accuracy: 0.9593\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1446 - accuracy: 0.9597 - val_loss: 0.1628 - val_accuracy: 0.9589\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1439 - accuracy: 0.9596 - val_loss: 0.1662 - val_accuracy: 0.9582\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 2s 43us/sample - loss: 0.1443 - accuracy: 0.9597 - val_loss: 0.1660 - val_accuracy: 0.9579\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1439 - accuracy: 0.9595 - val_loss: 0.1638 - val_accuracy: 0.9586\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1434 - accuracy: 0.9597 - val_loss: 0.1648 - val_accuracy: 0.9580\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1432 - accuracy: 0.9597 - val_loss: 0.1645 - val_accuracy: 0.9586\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.1431 - accuracy: 0.9596 - val_loss: 0.1684 - val_accuracy: 0.9586\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1424 - accuracy: 0.9597 - val_loss: 0.1675 - val_accuracy: 0.9581\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1429 - accuracy: 0.9597 - val_loss: 0.1667 - val_accuracy: 0.9577\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1422 - accuracy: 0.9599 - val_loss: 0.1726 - val_accuracy: 0.9591\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1417 - accuracy: 0.9599 - val_loss: 0.1660 - val_accuracy: 0.9576\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1418 - accuracy: 0.9598 - val_loss: 0.1676 - val_accuracy: 0.9589\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1413 - accuracy: 0.9600 - val_loss: 0.1705 - val_accuracy: 0.9577\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1410 - accuracy: 0.9599 - val_loss: 0.1698 - val_accuracy: 0.9588\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1407 - accuracy: 0.9600 - val_loss: 0.1705 - val_accuracy: 0.9582\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1407 - accuracy: 0.9601 - val_loss: 0.1728 - val_accuracy: 0.9582\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1406 - accuracy: 0.9600 - val_loss: 0.1702 - val_accuracy: 0.9585\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1405 - accuracy: 0.9600 - val_loss: 0.1701 - val_accuracy: 0.9584\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1399 - accuracy: 0.9600 - val_loss: 0.1732 - val_accuracy: 0.9579\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1397 - accuracy: 0.9601 - val_loss: 0.1696 - val_accuracy: 0.9577\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 2s 46us/sample - loss: 0.1389 - accuracy: 0.9601 - val_loss: 0.1696 - val_accuracy: 0.9588\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1391 - accuracy: 0.9602 - val_loss: 0.1687 - val_accuracy: 0.9589\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1387 - accuracy: 0.9603 - val_loss: 0.1754 - val_accuracy: 0.9574\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1388 - accuracy: 0.9602 - val_loss: 0.1762 - val_accuracy: 0.9584\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 2s 48us/sample - loss: 0.1385 - accuracy: 0.9603 - val_loss: 0.1711 - val_accuracy: 0.9586\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.1377 - accuracy: 0.9603 - val_loss: 0.1761 - val_accuracy: 0.9582\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1374 - accuracy: 0.9603 - val_loss: 0.1755 - val_accuracy: 0.9576\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.1372 - accuracy: 0.9603 - val_loss: 0.1791 - val_accuracy: 0.9578\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1369 - accuracy: 0.9604 - val_loss: 0.1758 - val_accuracy: 0.9577\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1373 - accuracy: 0.9604 - val_loss: 0.1724 - val_accuracy: 0.9586\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1368 - accuracy: 0.9605 - val_loss: 0.1755 - val_accuracy: 0.9570\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 2s 48us/sample - loss: 0.1366 - accuracy: 0.9604 - val_loss: 0.1752 - val_accuracy: 0.9578\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.1360 - accuracy: 0.9606 - val_loss: 0.1759 - val_accuracy: 0.9575\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 3s 54us/sample - loss: 0.1357 - accuracy: 0.9606 - val_loss: 0.1807 - val_accuracy: 0.9577\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 2s 46us/sample - loss: 0.1360 - accuracy: 0.9606 - val_loss: 0.1781 - val_accuracy: 0.9572\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1358 - accuracy: 0.9604 - val_loss: 0.1772 - val_accuracy: 0.9576\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 2s 43us/sample - loss: 0.1356 - accuracy: 0.9607 - val_loss: 0.1736 - val_accuracy: 0.9577\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1352 - accuracy: 0.9609 - val_loss: 0.1768 - val_accuracy: 0.9582\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1350 - accuracy: 0.9607 - val_loss: 0.1807 - val_accuracy: 0.9578\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1349 - accuracy: 0.9607 - val_loss: 0.1806 - val_accuracy: 0.9573\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1342 - accuracy: 0.9607 - val_loss: 0.1779 - val_accuracy: 0.9568\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1347 - accuracy: 0.9606 - val_loss: 0.1830 - val_accuracy: 0.9573\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.1340 - accuracy: 0.9607 - val_loss: 0.1795 - val_accuracy: 0.9578\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1337 - accuracy: 0.9608 - val_loss: 0.1841 - val_accuracy: 0.9586\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 2s 45us/sample - loss: 0.1339 - accuracy: 0.9606 - val_loss: 0.1914 - val_accuracy: 0.9581\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1335 - accuracy: 0.9609 - val_loss: 0.1885 - val_accuracy: 0.9576\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1333 - accuracy: 0.9608 - val_loss: 0.1851 - val_accuracy: 0.9578\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 2s 48us/sample - loss: 0.1333 - accuracy: 0.9610 - val_loss: 0.1817 - val_accuracy: 0.9580\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 2s 49us/sample - loss: 0.1334 - accuracy: 0.9608 - val_loss: 0.1824 - val_accuracy: 0.9573\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 2s 48us/sample - loss: 0.1327 - accuracy: 0.9611 - val_loss: 0.1836 - val_accuracy: 0.9575\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1332 - accuracy: 0.9608 - val_loss: 0.1783 - val_accuracy: 0.9573\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1318 - accuracy: 0.9612 - val_loss: 0.1850 - val_accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(scaled_x_train, y_train['target'].values, epochs=100,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(scaled_x_train)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_5.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "keras.layers.Dense(90, activation=tf.nn.relu),\n",
    "keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "keras.layers.Dense(30, activation=tf.nn.relu),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 60)                1860      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 90)                5490      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 15,002\n",
      "Trainable params: 15,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92096 samples, validate on 23024 samples\n",
      "Epoch 1/100\n",
      "91648/92096 [============================>.] - ETA: 0s - loss: 0.5618 - accuracy: 0.7032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/Ä°ÅŸBankasÄ± ML Challenge TR 3/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92096/92096 [==============================] - 4s 40us/sample - loss: 0.5618 - accuracy: 0.7033 - val_loss: 0.5419 - val_accuracy: 0.7187\n",
      "Epoch 2/100\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5360 - accuracy: 0.7212 - val_loss: 0.5317 - val_accuracy: 0.7272\n",
      "Epoch 3/100\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5173 - accuracy: 0.7345 - val_loss: 0.5056 - val_accuracy: 0.7432\n",
      "Epoch 4/100\n",
      "92096/92096 [==============================] - 4s 38us/sample - loss: 0.4980 - accuracy: 0.7457 - val_loss: 0.4891 - val_accuracy: 0.7522\n",
      "Epoch 5/100\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4834 - accuracy: 0.7553 - val_loss: 0.4842 - val_accuracy: 0.7532\n",
      "Epoch 6/100\n",
      "92096/92096 [==============================] - 4s 40us/sample - loss: 0.4674 - accuracy: 0.7664 - val_loss: 0.4631 - val_accuracy: 0.7718\n",
      "Epoch 7/100\n",
      "92096/92096 [==============================] - 3s 38us/sample - loss: 0.4522 - accuracy: 0.7773 - val_loss: 0.4528 - val_accuracy: 0.7779\n",
      "Epoch 8/100\n",
      "92096/92096 [==============================] - 4s 39us/sample - loss: 0.4382 - accuracy: 0.7866 - val_loss: 0.4412 - val_accuracy: 0.7874\n",
      "Epoch 9/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.4248 - accuracy: 0.7957 - val_loss: 0.4281 - val_accuracy: 0.7950\n",
      "Epoch 10/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.4145 - accuracy: 0.8024 - val_loss: 0.4196 - val_accuracy: 0.8043\n",
      "Epoch 11/100\n",
      "92096/92096 [==============================] - 4s 41us/sample - loss: 0.4032 - accuracy: 0.8095 - val_loss: 0.4052 - val_accuracy: 0.8122\n",
      "Epoch 12/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.3940 - accuracy: 0.8168 - val_loss: 0.4093 - val_accuracy: 0.8110\n",
      "Epoch 13/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.3837 - accuracy: 0.8218 - val_loss: 0.4024 - val_accuracy: 0.8136\n",
      "Epoch 14/100\n",
      "92096/92096 [==============================] - 4s 42us/sample - loss: 0.3747 - accuracy: 0.8279 - val_loss: 0.3885 - val_accuracy: 0.8212\n",
      "Epoch 15/100\n",
      "92096/92096 [==============================] - 4s 49us/sample - loss: 0.3675 - accuracy: 0.8329 - val_loss: 0.3892 - val_accuracy: 0.8240\n",
      "Epoch 16/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.3600 - accuracy: 0.8367 - val_loss: 0.3824 - val_accuracy: 0.8250\n",
      "Epoch 17/100\n",
      "92096/92096 [==============================] - 4s 42us/sample - loss: 0.3531 - accuracy: 0.8420 - val_loss: 0.3614 - val_accuracy: 0.8396\n",
      "Epoch 18/100\n",
      "92096/92096 [==============================] - 3s 38us/sample - loss: 0.3465 - accuracy: 0.8450 - val_loss: 0.3771 - val_accuracy: 0.8292\n",
      "Epoch 19/100\n",
      "92096/92096 [==============================] - 4s 38us/sample - loss: 0.3383 - accuracy: 0.8497 - val_loss: 0.3640 - val_accuracy: 0.8364\n",
      "Epoch 20/100\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.3348 - accuracy: 0.8514 - val_loss: 0.3650 - val_accuracy: 0.8399\n",
      "Epoch 21/100\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.3268 - accuracy: 0.8556 - val_loss: 0.3513 - val_accuracy: 0.8455\n",
      "Epoch 22/100\n",
      "92096/92096 [==============================] - 4s 40us/sample - loss: 0.3239 - accuracy: 0.8576 - val_loss: 0.3752 - val_accuracy: 0.8327\n",
      "Epoch 23/100\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.3190 - accuracy: 0.8608 - val_loss: 0.3631 - val_accuracy: 0.8425\n",
      "Epoch 24/100\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.3153 - accuracy: 0.8621 - val_loss: 0.3587 - val_accuracy: 0.8440\n",
      "Epoch 25/100\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.3098 - accuracy: 0.8652 - val_loss: 0.3492 - val_accuracy: 0.8476\n",
      "Epoch 26/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.3060 - accuracy: 0.8686 - val_loss: 0.3513 - val_accuracy: 0.8482\n",
      "Epoch 27/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.3015 - accuracy: 0.8700 - val_loss: 0.3446 - val_accuracy: 0.8492\n",
      "Epoch 28/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.2979 - accuracy: 0.8715 - val_loss: 0.3477 - val_accuracy: 0.8525\n",
      "Epoch 29/100\n",
      "92096/92096 [==============================] - 4s 42us/sample - loss: 0.2946 - accuracy: 0.8738 - val_loss: 0.3432 - val_accuracy: 0.8524\n",
      "Epoch 30/100\n",
      "92096/92096 [==============================] - 5s 53us/sample - loss: 0.2906 - accuracy: 0.8762 - val_loss: 0.3382 - val_accuracy: 0.8592\n",
      "Epoch 31/100\n",
      "92096/92096 [==============================] - 4s 49us/sample - loss: 0.2885 - accuracy: 0.8768 - val_loss: 0.3410 - val_accuracy: 0.8566\n",
      "Epoch 32/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2851 - accuracy: 0.8796 - val_loss: 0.3233 - val_accuracy: 0.8665\n",
      "Epoch 33/100\n",
      "92096/92096 [==============================] - 5s 50us/sample - loss: 0.2806 - accuracy: 0.8812 - val_loss: 0.3339 - val_accuracy: 0.8593\n",
      "Epoch 34/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.2786 - accuracy: 0.8825 - val_loss: 0.3258 - val_accuracy: 0.8633\n",
      "Epoch 35/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2777 - accuracy: 0.8823 - val_loss: 0.3265 - val_accuracy: 0.8631\n",
      "Epoch 36/100\n",
      "92096/92096 [==============================] - 4s 44us/sample - loss: 0.2717 - accuracy: 0.8862 - val_loss: 0.3202 - val_accuracy: 0.8652\n",
      "Epoch 37/100\n",
      "92096/92096 [==============================] - 4s 44us/sample - loss: 0.2715 - accuracy: 0.8864 - val_loss: 0.3284 - val_accuracy: 0.8646\n",
      "Epoch 38/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.2699 - accuracy: 0.8866 - val_loss: 0.3182 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2670 - accuracy: 0.8874 - val_loss: 0.3154 - val_accuracy: 0.8688\n",
      "Epoch 40/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2647 - accuracy: 0.8894 - val_loss: 0.3116 - val_accuracy: 0.8694\n",
      "Epoch 41/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.2618 - accuracy: 0.8910 - val_loss: 0.3246 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.2596 - accuracy: 0.8917 - val_loss: 0.3205 - val_accuracy: 0.8671\n",
      "Epoch 43/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2579 - accuracy: 0.8919 - val_loss: 0.3090 - val_accuracy: 0.8720\n",
      "Epoch 44/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.2561 - accuracy: 0.8934 - val_loss: 0.3197 - val_accuracy: 0.8696\n",
      "Epoch 45/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.2524 - accuracy: 0.8958 - val_loss: 0.3124 - val_accuracy: 0.8730\n",
      "Epoch 46/100\n",
      "92096/92096 [==============================] - 5s 50us/sample - loss: 0.2522 - accuracy: 0.8953 - val_loss: 0.3197 - val_accuracy: 0.8697\n",
      "Epoch 47/100\n",
      "92096/92096 [==============================] - 5s 53us/sample - loss: 0.2505 - accuracy: 0.8963 - val_loss: 0.3270 - val_accuracy: 0.8673\n",
      "Epoch 48/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2498 - accuracy: 0.8966 - val_loss: 0.3140 - val_accuracy: 0.8732\n",
      "Epoch 49/100\n",
      "92096/92096 [==============================] - 5s 59us/sample - loss: 0.2457 - accuracy: 0.8981 - val_loss: 0.3135 - val_accuracy: 0.8763\n",
      "Epoch 50/100\n",
      "92096/92096 [==============================] - 4s 49us/sample - loss: 0.2454 - accuracy: 0.8984 - val_loss: 0.3138 - val_accuracy: 0.8765\n",
      "Epoch 51/100\n",
      "92096/92096 [==============================] - 5s 54us/sample - loss: 0.2430 - accuracy: 0.8991 - val_loss: 0.3087 - val_accuracy: 0.8769\n",
      "Epoch 52/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2415 - accuracy: 0.9007 - val_loss: 0.3002 - val_accuracy: 0.8796\n",
      "Epoch 53/100\n",
      "92096/92096 [==============================] - 5s 56us/sample - loss: 0.2388 - accuracy: 0.9021 - val_loss: 0.3176 - val_accuracy: 0.8744\n",
      "Epoch 54/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2394 - accuracy: 0.9020 - val_loss: 0.3078 - val_accuracy: 0.8790\n",
      "Epoch 55/100\n",
      "92096/92096 [==============================] - 6s 60us/sample - loss: 0.2375 - accuracy: 0.9018 - val_loss: 0.3082 - val_accuracy: 0.8792\n",
      "Epoch 56/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2330 - accuracy: 0.9043 - val_loss: 0.3122 - val_accuracy: 0.8771\n",
      "Epoch 57/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2360 - accuracy: 0.9024 - val_loss: 0.3093 - val_accuracy: 0.8791\n",
      "Epoch 58/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2311 - accuracy: 0.9054 - val_loss: 0.3084 - val_accuracy: 0.8783\n",
      "Epoch 59/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2307 - accuracy: 0.9057 - val_loss: 0.3094 - val_accuracy: 0.8813\n",
      "Epoch 60/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.2302 - accuracy: 0.9061 - val_loss: 0.3021 - val_accuracy: 0.8842\n",
      "Epoch 61/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2283 - accuracy: 0.9072 - val_loss: 0.3001 - val_accuracy: 0.8816\n",
      "Epoch 62/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2286 - accuracy: 0.9063 - val_loss: 0.3054 - val_accuracy: 0.8788\n",
      "Epoch 63/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.2254 - accuracy: 0.9085 - val_loss: 0.3074 - val_accuracy: 0.8796\n",
      "Epoch 64/100\n",
      "92096/92096 [==============================] - 5s 50us/sample - loss: 0.2238 - accuracy: 0.9089 - val_loss: 0.3049 - val_accuracy: 0.8807\n",
      "Epoch 65/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2218 - accuracy: 0.9098 - val_loss: 0.3020 - val_accuracy: 0.8839\n",
      "Epoch 66/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2228 - accuracy: 0.9093 - val_loss: 0.3212 - val_accuracy: 0.8770\n",
      "Epoch 67/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2187 - accuracy: 0.9111 - val_loss: 0.3077 - val_accuracy: 0.8807\n",
      "Epoch 68/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.2182 - accuracy: 0.9120 - val_loss: 0.3105 - val_accuracy: 0.8773\n",
      "Epoch 69/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.2180 - accuracy: 0.9124 - val_loss: 0.3036 - val_accuracy: 0.8839\n",
      "Epoch 70/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.2170 - accuracy: 0.9123 - val_loss: 0.3011 - val_accuracy: 0.8839\n",
      "Epoch 71/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.2160 - accuracy: 0.9126 - val_loss: 0.2946 - val_accuracy: 0.8848\n",
      "Epoch 72/100\n",
      "92096/92096 [==============================] - 5s 49us/sample - loss: 0.2162 - accuracy: 0.9121 - val_loss: 0.2903 - val_accuracy: 0.8873\n",
      "Epoch 73/100\n",
      "92096/92096 [==============================] - 5s 59us/sample - loss: 0.2126 - accuracy: 0.9137 - val_loss: 0.3005 - val_accuracy: 0.8864\n",
      "Epoch 74/100\n",
      "92096/92096 [==============================] - 5s 56us/sample - loss: 0.2116 - accuracy: 0.9143 - val_loss: 0.2989 - val_accuracy: 0.8896\n",
      "Epoch 75/100\n",
      "92096/92096 [==============================] - 6s 64us/sample - loss: 0.2125 - accuracy: 0.9149 - val_loss: 0.3013 - val_accuracy: 0.8851\n",
      "Epoch 76/100\n",
      "92096/92096 [==============================] - 5s 54us/sample - loss: 0.2099 - accuracy: 0.9160 - val_loss: 0.3025 - val_accuracy: 0.8873\n",
      "Epoch 77/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.2093 - accuracy: 0.9160 - val_loss: 0.2891 - val_accuracy: 0.8911\n",
      "Epoch 78/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.2100 - accuracy: 0.9151 - val_loss: 0.2995 - val_accuracy: 0.8880\n",
      "Epoch 79/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2090 - accuracy: 0.9162 - val_loss: 0.2917 - val_accuracy: 0.8900\n",
      "Epoch 80/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.2064 - accuracy: 0.9172 - val_loss: 0.2916 - val_accuracy: 0.8901\n",
      "Epoch 81/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.2044 - accuracy: 0.9177 - val_loss: 0.2953 - val_accuracy: 0.8887\n",
      "Epoch 82/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.2047 - accuracy: 0.9178 - val_loss: 0.2947 - val_accuracy: 0.8931\n",
      "Epoch 83/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.2021 - accuracy: 0.9194 - val_loss: 0.3024 - val_accuracy: 0.8854\n",
      "Epoch 84/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2031 - accuracy: 0.9189 - val_loss: 0.3118 - val_accuracy: 0.8850\n",
      "Epoch 85/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2025 - accuracy: 0.9198 - val_loss: 0.2950 - val_accuracy: 0.8882\n",
      "Epoch 86/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.1992 - accuracy: 0.9194 - val_loss: 0.2903 - val_accuracy: 0.8912\n",
      "Epoch 87/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.1988 - accuracy: 0.9201 - val_loss: 0.3118 - val_accuracy: 0.8872\n",
      "Epoch 88/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.1989 - accuracy: 0.9201 - val_loss: 0.2981 - val_accuracy: 0.8893\n",
      "Epoch 89/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.1986 - accuracy: 0.9212 - val_loss: 0.2951 - val_accuracy: 0.8917\n",
      "Epoch 90/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.1971 - accuracy: 0.9218 - val_loss: 0.2979 - val_accuracy: 0.8915\n",
      "Epoch 91/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.1984 - accuracy: 0.9203 - val_loss: 0.3069 - val_accuracy: 0.8865\n",
      "Epoch 92/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.1954 - accuracy: 0.9217 - val_loss: 0.2939 - val_accuracy: 0.8917\n",
      "Epoch 93/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.1939 - accuracy: 0.9219 - val_loss: 0.3000 - val_accuracy: 0.8884\n",
      "Epoch 94/100\n",
      "92096/92096 [==============================] - 4s 44us/sample - loss: 0.1930 - accuracy: 0.9224 - val_loss: 0.2899 - val_accuracy: 0.8932\n",
      "Epoch 95/100\n",
      "92096/92096 [==============================] - 4s 44us/sample - loss: 0.1928 - accuracy: 0.9228 - val_loss: 0.3002 - val_accuracy: 0.8915\n",
      "Epoch 96/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.1928 - accuracy: 0.9226 - val_loss: 0.2934 - val_accuracy: 0.8895\n",
      "Epoch 97/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.1912 - accuracy: 0.9249 - val_loss: 0.3048 - val_accuracy: 0.8875\n",
      "Epoch 98/100\n",
      "92096/92096 [==============================] - 4s 49us/sample - loss: 0.1897 - accuracy: 0.9251 - val_loss: 0.2993 - val_accuracy: 0.8919\n",
      "Epoch 99/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.1912 - accuracy: 0.9244 - val_loss: 0.2994 - val_accuracy: 0.8943\n",
      "Epoch 100/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.1900 - accuracy: 0.9245 - val_loss: 0.2942 - val_accuracy: 0.8915\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(shuffle(pd.DataFrame(x_train_resampled),random_state=1), shuffle(pd.DataFrame(y_train_resampled),random_state=1), epochs=100,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/Ä°ÅŸBankasÄ± ML Challenge TR 3/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "train_predictions = model.predict(x_train_resampled)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_6.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(30, activation=tf.nn.relu),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 1,292\n",
      "Trainable params: 1,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92096 samples, validate on 23024 samples\n",
      "Epoch 1/500\n",
      "90944/92096 [============================>.] - ETA: 0s - loss: 0.5734 - accuracy: 0.6922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/Ä°ÅŸBankasÄ± ML Challenge TR 3/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5732 - accuracy: 0.6925 - val_loss: 0.5591 - val_accuracy: 0.7070\n",
      "Epoch 2/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5548 - accuracy: 0.7093 - val_loss: 0.5484 - val_accuracy: 0.7138\n",
      "Epoch 3/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5484 - accuracy: 0.7146 - val_loss: 0.5445 - val_accuracy: 0.7179\n",
      "Epoch 4/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5432 - accuracy: 0.7182 - val_loss: 0.5430 - val_accuracy: 0.7191\n",
      "Epoch 5/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5390 - accuracy: 0.7205 - val_loss: 0.5351 - val_accuracy: 0.7204\n",
      "Epoch 6/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5350 - accuracy: 0.7226 - val_loss: 0.5315 - val_accuracy: 0.7256\n",
      "Epoch 7/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5315 - accuracy: 0.7261 - val_loss: 0.5320 - val_accuracy: 0.7249\n",
      "Epoch 8/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5278 - accuracy: 0.7293 - val_loss: 0.5278 - val_accuracy: 0.7302\n",
      "Epoch 9/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5248 - accuracy: 0.7304 - val_loss: 0.5222 - val_accuracy: 0.7371\n",
      "Epoch 10/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5218 - accuracy: 0.7332 - val_loss: 0.5204 - val_accuracy: 0.7365\n",
      "Epoch 11/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5190 - accuracy: 0.7357 - val_loss: 0.5222 - val_accuracy: 0.7331\n",
      "Epoch 12/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5162 - accuracy: 0.7379 - val_loss: 0.5178 - val_accuracy: 0.7372\n",
      "Epoch 13/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5137 - accuracy: 0.7397 - val_loss: 0.5189 - val_accuracy: 0.7354\n",
      "Epoch 14/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5113 - accuracy: 0.7403 - val_loss: 0.5163 - val_accuracy: 0.7426\n",
      "Epoch 15/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5096 - accuracy: 0.7421 - val_loss: 0.5111 - val_accuracy: 0.7433\n",
      "Epoch 16/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5069 - accuracy: 0.7435 - val_loss: 0.5096 - val_accuracy: 0.7436\n",
      "Epoch 17/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5048 - accuracy: 0.7458 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 18/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5027 - accuracy: 0.7463 - val_loss: 0.5065 - val_accuracy: 0.7483\n",
      "Epoch 19/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5004 - accuracy: 0.7482 - val_loss: 0.5045 - val_accuracy: 0.7508\n",
      "Epoch 20/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4984 - accuracy: 0.7516 - val_loss: 0.5033 - val_accuracy: 0.7492\n",
      "Epoch 21/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4967 - accuracy: 0.7520 - val_loss: 0.5007 - val_accuracy: 0.7530\n",
      "Epoch 22/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4947 - accuracy: 0.7530 - val_loss: 0.4998 - val_accuracy: 0.7513\n",
      "Epoch 23/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4934 - accuracy: 0.7553 - val_loss: 0.4964 - val_accuracy: 0.7571\n",
      "Epoch 24/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4926 - accuracy: 0.7556 - val_loss: 0.4937 - val_accuracy: 0.7596\n",
      "Epoch 25/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4900 - accuracy: 0.7566 - val_loss: 0.4954 - val_accuracy: 0.7565\n",
      "Epoch 26/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4896 - accuracy: 0.7569 - val_loss: 0.4966 - val_accuracy: 0.7545\n",
      "Epoch 27/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4881 - accuracy: 0.7583 - val_loss: 0.4954 - val_accuracy: 0.7516\n",
      "Epoch 28/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4872 - accuracy: 0.7584 - val_loss: 0.4921 - val_accuracy: 0.7598\n",
      "Epoch 29/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4864 - accuracy: 0.7593 - val_loss: 0.4884 - val_accuracy: 0.7605\n",
      "Epoch 30/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4850 - accuracy: 0.7605 - val_loss: 0.4881 - val_accuracy: 0.7596\n",
      "Epoch 31/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4840 - accuracy: 0.7603 - val_loss: 0.4877 - val_accuracy: 0.7623\n",
      "Epoch 32/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4833 - accuracy: 0.7612 - val_loss: 0.4909 - val_accuracy: 0.7580\n",
      "Epoch 33/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4818 - accuracy: 0.7618 - val_loss: 0.4901 - val_accuracy: 0.7556\n",
      "Epoch 34/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4808 - accuracy: 0.7624 - val_loss: 0.4886 - val_accuracy: 0.7583\n",
      "Epoch 35/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4806 - accuracy: 0.7627 - val_loss: 0.4881 - val_accuracy: 0.7609\n",
      "Epoch 36/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4803 - accuracy: 0.7630 - val_loss: 0.4877 - val_accuracy: 0.7616\n",
      "Epoch 37/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4783 - accuracy: 0.7638 - val_loss: 0.4862 - val_accuracy: 0.7597\n",
      "Epoch 38/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.4786 - accuracy: 0.7642 - val_loss: 0.4819 - val_accuracy: 0.7660\n",
      "Epoch 39/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4775 - accuracy: 0.7647 - val_loss: 0.4859 - val_accuracy: 0.7620\n",
      "Epoch 40/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4764 - accuracy: 0.7653 - val_loss: 0.4811 - val_accuracy: 0.7609\n",
      "Epoch 41/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4763 - accuracy: 0.7651 - val_loss: 0.4819 - val_accuracy: 0.7613\n",
      "Epoch 42/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.4755 - accuracy: 0.7655 - val_loss: 0.4836 - val_accuracy: 0.7615\n",
      "Epoch 43/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4748 - accuracy: 0.7656 - val_loss: 0.4783 - val_accuracy: 0.7659\n",
      "Epoch 44/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4742 - accuracy: 0.7665 - val_loss: 0.4781 - val_accuracy: 0.7662\n",
      "Epoch 45/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.4736 - accuracy: 0.7663 - val_loss: 0.4823 - val_accuracy: 0.7651\n",
      "Epoch 46/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4732 - accuracy: 0.7669 - val_loss: 0.4758 - val_accuracy: 0.7701\n",
      "Epoch 47/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4716 - accuracy: 0.7680 - val_loss: 0.4792 - val_accuracy: 0.7685\n",
      "Epoch 48/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4718 - accuracy: 0.7683 - val_loss: 0.4781 - val_accuracy: 0.7688\n",
      "Epoch 49/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.4708 - accuracy: 0.7701 - val_loss: 0.4770 - val_accuracy: 0.7681\n",
      "Epoch 50/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.4705 - accuracy: 0.7698 - val_loss: 0.4790 - val_accuracy: 0.7647\n",
      "Epoch 51/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.4703 - accuracy: 0.7694 - val_loss: 0.4814 - val_accuracy: 0.7657\n",
      "Epoch 52/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4696 - accuracy: 0.7695 - val_loss: 0.4828 - val_accuracy: 0.7622\n",
      "Epoch 53/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4694 - accuracy: 0.7684 - val_loss: 0.4755 - val_accuracy: 0.7675\n",
      "Epoch 54/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4688 - accuracy: 0.7707 - val_loss: 0.4769 - val_accuracy: 0.7696\n",
      "Epoch 55/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4681 - accuracy: 0.7704 - val_loss: 0.4754 - val_accuracy: 0.7705\n",
      "Epoch 56/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4681 - accuracy: 0.7706 - val_loss: 0.4745 - val_accuracy: 0.7692\n",
      "Epoch 57/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4678 - accuracy: 0.7704 - val_loss: 0.4731 - val_accuracy: 0.7721\n",
      "Epoch 58/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4669 - accuracy: 0.7723 - val_loss: 0.4738 - val_accuracy: 0.7725\n",
      "Epoch 59/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4666 - accuracy: 0.7721 - val_loss: 0.4766 - val_accuracy: 0.7674\n",
      "Epoch 60/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4669 - accuracy: 0.7712 - val_loss: 0.4798 - val_accuracy: 0.7659\n",
      "Epoch 61/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4659 - accuracy: 0.7712 - val_loss: 0.4727 - val_accuracy: 0.7698\n",
      "Epoch 62/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4653 - accuracy: 0.7730 - val_loss: 0.4767 - val_accuracy: 0.7718\n",
      "Epoch 63/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4651 - accuracy: 0.7733 - val_loss: 0.4747 - val_accuracy: 0.7693\n",
      "Epoch 64/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4649 - accuracy: 0.7732 - val_loss: 0.4687 - val_accuracy: 0.7734\n",
      "Epoch 65/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4646 - accuracy: 0.7734 - val_loss: 0.4678 - val_accuracy: 0.7747\n",
      "Epoch 66/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4643 - accuracy: 0.7741 - val_loss: 0.4754 - val_accuracy: 0.7726\n",
      "Epoch 67/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.4721 - val_accuracy: 0.7730\n",
      "Epoch 68/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4636 - accuracy: 0.7740 - val_loss: 0.4695 - val_accuracy: 0.7697\n",
      "Epoch 69/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4637 - accuracy: 0.7734 - val_loss: 0.4795 - val_accuracy: 0.7634\n",
      "Epoch 70/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4635 - accuracy: 0.7750 - val_loss: 0.4697 - val_accuracy: 0.7735\n",
      "Epoch 71/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4622 - accuracy: 0.7746 - val_loss: 0.4747 - val_accuracy: 0.7704\n",
      "Epoch 72/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4699 - val_accuracy: 0.7699\n",
      "Epoch 73/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4632 - accuracy: 0.7759 - val_loss: 0.4705 - val_accuracy: 0.7739\n",
      "Epoch 74/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4727 - val_accuracy: 0.7691\n",
      "Epoch 75/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4617 - accuracy: 0.7754 - val_loss: 0.4770 - val_accuracy: 0.7641\n",
      "Epoch 76/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4730 - val_accuracy: 0.7715\n",
      "Epoch 77/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4609 - accuracy: 0.7768 - val_loss: 0.4667 - val_accuracy: 0.7776\n",
      "Epoch 78/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4601 - accuracy: 0.7761 - val_loss: 0.4735 - val_accuracy: 0.7729\n",
      "Epoch 79/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4605 - accuracy: 0.7767 - val_loss: 0.4675 - val_accuracy: 0.7720\n",
      "Epoch 80/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4602 - accuracy: 0.7766 - val_loss: 0.4648 - val_accuracy: 0.7772\n",
      "Epoch 81/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4601 - accuracy: 0.7773 - val_loss: 0.4681 - val_accuracy: 0.7727\n",
      "Epoch 82/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4599 - accuracy: 0.7770 - val_loss: 0.4683 - val_accuracy: 0.7719\n",
      "Epoch 83/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4598 - accuracy: 0.7777 - val_loss: 0.4666 - val_accuracy: 0.7751\n",
      "Epoch 84/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4594 - accuracy: 0.7764 - val_loss: 0.4666 - val_accuracy: 0.7745\n",
      "Epoch 85/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4588 - accuracy: 0.7776 - val_loss: 0.4686 - val_accuracy: 0.7708\n",
      "Epoch 86/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4590 - accuracy: 0.7783 - val_loss: 0.4731 - val_accuracy: 0.7743\n",
      "Epoch 87/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4583 - accuracy: 0.7776 - val_loss: 0.4690 - val_accuracy: 0.7773\n",
      "Epoch 88/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4577 - accuracy: 0.7784 - val_loss: 0.4700 - val_accuracy: 0.7689\n",
      "Epoch 89/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4584 - accuracy: 0.7781 - val_loss: 0.4721 - val_accuracy: 0.7756\n",
      "Epoch 90/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4579 - accuracy: 0.7787 - val_loss: 0.4679 - val_accuracy: 0.7761\n",
      "Epoch 91/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4572 - accuracy: 0.7788 - val_loss: 0.4632 - val_accuracy: 0.7758\n",
      "Epoch 92/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4572 - accuracy: 0.7781 - val_loss: 0.4828 - val_accuracy: 0.7709\n",
      "Epoch 93/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4566 - accuracy: 0.7801 - val_loss: 0.4757 - val_accuracy: 0.7710\n",
      "Epoch 94/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4572 - accuracy: 0.7796 - val_loss: 0.4634 - val_accuracy: 0.7768\n",
      "Epoch 95/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4568 - accuracy: 0.7785 - val_loss: 0.4782 - val_accuracy: 0.7718\n",
      "Epoch 96/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4564 - accuracy: 0.7793 - val_loss: 0.4714 - val_accuracy: 0.7752\n",
      "Epoch 97/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4561 - accuracy: 0.7775 - val_loss: 0.4641 - val_accuracy: 0.7775\n",
      "Epoch 98/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4568 - accuracy: 0.7793 - val_loss: 0.4713 - val_accuracy: 0.7693\n",
      "Epoch 99/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4559 - accuracy: 0.7801 - val_loss: 0.4636 - val_accuracy: 0.7738\n",
      "Epoch 100/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4561 - accuracy: 0.7782 - val_loss: 0.4651 - val_accuracy: 0.7766\n",
      "Epoch 101/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4560 - accuracy: 0.7793 - val_loss: 0.4676 - val_accuracy: 0.7767\n",
      "Epoch 102/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4554 - accuracy: 0.7804 - val_loss: 0.4645 - val_accuracy: 0.7786\n",
      "Epoch 103/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4550 - accuracy: 0.7804 - val_loss: 0.4650 - val_accuracy: 0.7710\n",
      "Epoch 104/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4553 - accuracy: 0.7793 - val_loss: 0.4668 - val_accuracy: 0.7712\n",
      "Epoch 105/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4558 - accuracy: 0.7797 - val_loss: 0.4645 - val_accuracy: 0.7771\n",
      "Epoch 106/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.4660 - val_accuracy: 0.7755\n",
      "Epoch 107/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4541 - accuracy: 0.7813 - val_loss: 0.4635 - val_accuracy: 0.7778\n",
      "Epoch 108/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4541 - accuracy: 0.7804 - val_loss: 0.4663 - val_accuracy: 0.7738\n",
      "Epoch 109/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4545 - accuracy: 0.7810 - val_loss: 0.4648 - val_accuracy: 0.7809\n",
      "Epoch 110/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4538 - accuracy: 0.7811 - val_loss: 0.4705 - val_accuracy: 0.7740\n",
      "Epoch 111/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4543 - accuracy: 0.7808 - val_loss: 0.4604 - val_accuracy: 0.7787\n",
      "Epoch 112/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4545 - accuracy: 0.7814 - val_loss: 0.4574 - val_accuracy: 0.7810\n",
      "Epoch 113/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4539 - accuracy: 0.7816 - val_loss: 0.4626 - val_accuracy: 0.7774\n",
      "Epoch 114/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4539 - accuracy: 0.7815 - val_loss: 0.4712 - val_accuracy: 0.7729\n",
      "Epoch 115/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4541 - accuracy: 0.7809 - val_loss: 0.4707 - val_accuracy: 0.7669\n",
      "Epoch 116/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4534 - accuracy: 0.7811 - val_loss: 0.4729 - val_accuracy: 0.7744\n",
      "Epoch 117/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4532 - accuracy: 0.7814 - val_loss: 0.4605 - val_accuracy: 0.7803\n",
      "Epoch 118/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4535 - accuracy: 0.7825 - val_loss: 0.4654 - val_accuracy: 0.7728\n",
      "Epoch 119/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4529 - accuracy: 0.7825 - val_loss: 0.4624 - val_accuracy: 0.7765\n",
      "Epoch 120/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4527 - accuracy: 0.7832 - val_loss: 0.4724 - val_accuracy: 0.7690\n",
      "Epoch 121/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4531 - accuracy: 0.7827 - val_loss: 0.4625 - val_accuracy: 0.7794\n",
      "Epoch 122/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4524 - accuracy: 0.7820 - val_loss: 0.4635 - val_accuracy: 0.7787\n",
      "Epoch 123/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4524 - accuracy: 0.7828 - val_loss: 0.4641 - val_accuracy: 0.7791\n",
      "Epoch 124/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4528 - accuracy: 0.7832 - val_loss: 0.4779 - val_accuracy: 0.7671\n",
      "Epoch 125/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4522 - accuracy: 0.7827 - val_loss: 0.4676 - val_accuracy: 0.7707\n",
      "Epoch 126/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4524 - accuracy: 0.7824 - val_loss: 0.4702 - val_accuracy: 0.7727\n",
      "Epoch 127/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4519 - accuracy: 0.7821 - val_loss: 0.4573 - val_accuracy: 0.7817\n",
      "Epoch 128/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4525 - accuracy: 0.7823 - val_loss: 0.4630 - val_accuracy: 0.7774\n",
      "Epoch 129/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4519 - accuracy: 0.7826 - val_loss: 0.4634 - val_accuracy: 0.7795\n",
      "Epoch 130/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4514 - accuracy: 0.7831 - val_loss: 0.4606 - val_accuracy: 0.7814\n",
      "Epoch 131/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4511 - accuracy: 0.7833 - val_loss: 0.4650 - val_accuracy: 0.7749\n",
      "Epoch 132/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4516 - accuracy: 0.7825 - val_loss: 0.4636 - val_accuracy: 0.7825\n",
      "Epoch 133/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4516 - accuracy: 0.7816 - val_loss: 0.4604 - val_accuracy: 0.7800\n",
      "Epoch 134/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4509 - accuracy: 0.7843 - val_loss: 0.4691 - val_accuracy: 0.7757\n",
      "Epoch 135/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4516 - accuracy: 0.7838 - val_loss: 0.4688 - val_accuracy: 0.7725\n",
      "Epoch 136/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4511 - accuracy: 0.7833 - val_loss: 0.4606 - val_accuracy: 0.7786\n",
      "Epoch 137/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4512 - accuracy: 0.7831 - val_loss: 0.4627 - val_accuracy: 0.7799\n",
      "Epoch 138/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.4595 - val_accuracy: 0.7805\n",
      "Epoch 139/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4501 - accuracy: 0.7837 - val_loss: 0.4675 - val_accuracy: 0.7728\n",
      "Epoch 140/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4508 - accuracy: 0.7839 - val_loss: 0.4637 - val_accuracy: 0.7792\n",
      "Epoch 141/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4499 - accuracy: 0.7834 - val_loss: 0.4699 - val_accuracy: 0.7745\n",
      "Epoch 142/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4501 - accuracy: 0.7844 - val_loss: 0.4618 - val_accuracy: 0.7771\n",
      "Epoch 143/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4499 - accuracy: 0.7858 - val_loss: 0.4587 - val_accuracy: 0.7790\n",
      "Epoch 144/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4501 - accuracy: 0.7843 - val_loss: 0.4614 - val_accuracy: 0.7820\n",
      "Epoch 145/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4496 - accuracy: 0.7850 - val_loss: 0.4588 - val_accuracy: 0.7819\n",
      "Epoch 146/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4493 - accuracy: 0.7836 - val_loss: 0.4624 - val_accuracy: 0.7786\n",
      "Epoch 147/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4500 - accuracy: 0.7853 - val_loss: 0.4625 - val_accuracy: 0.7785\n",
      "Epoch 148/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4495 - accuracy: 0.7852 - val_loss: 0.4647 - val_accuracy: 0.7835\n",
      "Epoch 149/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4494 - accuracy: 0.7857 - val_loss: 0.4641 - val_accuracy: 0.7778\n",
      "Epoch 150/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.4622 - val_accuracy: 0.7822\n",
      "Epoch 151/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4493 - accuracy: 0.7849 - val_loss: 0.4588 - val_accuracy: 0.7791\n",
      "Epoch 152/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4489 - accuracy: 0.7852 - val_loss: 0.4619 - val_accuracy: 0.7774\n",
      "Epoch 153/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4489 - accuracy: 0.7852 - val_loss: 0.4556 - val_accuracy: 0.7841\n",
      "Epoch 154/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4486 - accuracy: 0.7859 - val_loss: 0.4552 - val_accuracy: 0.7803\n",
      "Epoch 155/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4483 - accuracy: 0.7861 - val_loss: 0.4570 - val_accuracy: 0.7840\n",
      "Epoch 156/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4480 - accuracy: 0.7857 - val_loss: 0.4662 - val_accuracy: 0.7797\n",
      "Epoch 157/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4482 - accuracy: 0.7848 - val_loss: 0.4607 - val_accuracy: 0.7778\n",
      "Epoch 158/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4481 - accuracy: 0.7852 - val_loss: 0.4652 - val_accuracy: 0.7776\n",
      "Epoch 159/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4478 - accuracy: 0.7859 - val_loss: 0.4657 - val_accuracy: 0.7820\n",
      "Epoch 160/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4481 - accuracy: 0.7862 - val_loss: 0.4588 - val_accuracy: 0.7807\n",
      "Epoch 161/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4479 - accuracy: 0.7860 - val_loss: 0.4640 - val_accuracy: 0.7741\n",
      "Epoch 162/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4478 - accuracy: 0.7860 - val_loss: 0.4570 - val_accuracy: 0.7832\n",
      "Epoch 163/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4479 - accuracy: 0.7862 - val_loss: 0.4619 - val_accuracy: 0.7779\n",
      "Epoch 164/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4473 - accuracy: 0.7866 - val_loss: 0.4587 - val_accuracy: 0.7820\n",
      "Epoch 165/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4474 - accuracy: 0.7863 - val_loss: 0.4630 - val_accuracy: 0.7770\n",
      "Epoch 166/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4471 - accuracy: 0.7870 - val_loss: 0.4565 - val_accuracy: 0.7837\n",
      "Epoch 167/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4471 - accuracy: 0.7864 - val_loss: 0.4597 - val_accuracy: 0.7783\n",
      "Epoch 168/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4476 - accuracy: 0.7860 - val_loss: 0.4583 - val_accuracy: 0.7828\n",
      "Epoch 169/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.4578 - val_accuracy: 0.7849\n",
      "Epoch 170/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4466 - accuracy: 0.7873 - val_loss: 0.4719 - val_accuracy: 0.7728\n",
      "Epoch 171/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4467 - accuracy: 0.7870 - val_loss: 0.4620 - val_accuracy: 0.7804\n",
      "Epoch 172/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4470 - accuracy: 0.7863 - val_loss: 0.4610 - val_accuracy: 0.7805\n",
      "Epoch 173/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4467 - accuracy: 0.7867 - val_loss: 0.4580 - val_accuracy: 0.7850\n",
      "Epoch 174/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4475 - accuracy: 0.7871 - val_loss: 0.4670 - val_accuracy: 0.7738\n",
      "Epoch 175/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4464 - accuracy: 0.7870 - val_loss: 0.4576 - val_accuracy: 0.7788\n",
      "Epoch 176/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4469 - accuracy: 0.7868 - val_loss: 0.4560 - val_accuracy: 0.7846\n",
      "Epoch 177/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4466 - accuracy: 0.7878 - val_loss: 0.4559 - val_accuracy: 0.7839\n",
      "Epoch 178/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4468 - accuracy: 0.7865 - val_loss: 0.4575 - val_accuracy: 0.7854\n",
      "Epoch 179/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4470 - accuracy: 0.7855 - val_loss: 0.4560 - val_accuracy: 0.7848\n",
      "Epoch 180/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4464 - accuracy: 0.7872 - val_loss: 0.4563 - val_accuracy: 0.7817\n",
      "Epoch 181/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4460 - accuracy: 0.7878 - val_loss: 0.4586 - val_accuracy: 0.7797\n",
      "Epoch 182/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4458 - accuracy: 0.7861 - val_loss: 0.4583 - val_accuracy: 0.7835\n",
      "Epoch 183/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4458 - accuracy: 0.7872 - val_loss: 0.4556 - val_accuracy: 0.7842\n",
      "Epoch 184/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4458 - accuracy: 0.7887 - val_loss: 0.4614 - val_accuracy: 0.7812\n",
      "Epoch 185/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4460 - accuracy: 0.7863 - val_loss: 0.4572 - val_accuracy: 0.7816\n",
      "Epoch 186/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4454 - accuracy: 0.7873 - val_loss: 0.4553 - val_accuracy: 0.7829\n",
      "Epoch 187/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4454 - accuracy: 0.7885 - val_loss: 0.4571 - val_accuracy: 0.7821\n",
      "Epoch 188/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4602 - val_accuracy: 0.7817\n",
      "Epoch 189/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4456 - accuracy: 0.7878 - val_loss: 0.4626 - val_accuracy: 0.7812\n",
      "Epoch 190/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4452 - accuracy: 0.7875 - val_loss: 0.4587 - val_accuracy: 0.7799\n",
      "Epoch 191/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4453 - accuracy: 0.7891 - val_loss: 0.4650 - val_accuracy: 0.7745\n",
      "Epoch 192/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4447 - accuracy: 0.7875 - val_loss: 0.4611 - val_accuracy: 0.7828\n",
      "Epoch 193/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4454 - accuracy: 0.7878 - val_loss: 0.4645 - val_accuracy: 0.7803\n",
      "Epoch 194/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4456 - accuracy: 0.7878 - val_loss: 0.4636 - val_accuracy: 0.7757\n",
      "Epoch 195/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4453 - accuracy: 0.7866 - val_loss: 0.4541 - val_accuracy: 0.7854\n",
      "Epoch 196/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4445 - accuracy: 0.7881 - val_loss: 0.4537 - val_accuracy: 0.7841\n",
      "Epoch 197/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4454 - accuracy: 0.7881 - val_loss: 0.4656 - val_accuracy: 0.7777\n",
      "Epoch 198/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4450 - accuracy: 0.7881 - val_loss: 0.4564 - val_accuracy: 0.7824\n",
      "Epoch 199/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4452 - accuracy: 0.7877 - val_loss: 0.4752 - val_accuracy: 0.7715\n",
      "Epoch 200/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4449 - accuracy: 0.7888 - val_loss: 0.4566 - val_accuracy: 0.7816\n",
      "Epoch 201/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4446 - accuracy: 0.7880 - val_loss: 0.4612 - val_accuracy: 0.7787\n",
      "Epoch 202/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4444 - accuracy: 0.7885 - val_loss: 0.4620 - val_accuracy: 0.7816\n",
      "Epoch 203/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4450 - accuracy: 0.7877 - val_loss: 0.4596 - val_accuracy: 0.7811\n",
      "Epoch 204/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4448 - accuracy: 0.7872 - val_loss: 0.4552 - val_accuracy: 0.7856\n",
      "Epoch 205/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4442 - accuracy: 0.7889 - val_loss: 0.4557 - val_accuracy: 0.7827\n",
      "Epoch 206/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4444 - accuracy: 0.7875 - val_loss: 0.4603 - val_accuracy: 0.7791\n",
      "Epoch 207/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4443 - accuracy: 0.7886 - val_loss: 0.4548 - val_accuracy: 0.7840\n",
      "Epoch 208/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4445 - accuracy: 0.7881 - val_loss: 0.4547 - val_accuracy: 0.7855\n",
      "Epoch 209/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4442 - accuracy: 0.7877 - val_loss: 0.4555 - val_accuracy: 0.7867\n",
      "Epoch 210/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4444 - accuracy: 0.7881 - val_loss: 0.4534 - val_accuracy: 0.7874\n",
      "Epoch 211/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4443 - accuracy: 0.7883 - val_loss: 0.4510 - val_accuracy: 0.7870\n",
      "Epoch 212/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4437 - accuracy: 0.7885 - val_loss: 0.4511 - val_accuracy: 0.7843\n",
      "Epoch 213/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4444 - accuracy: 0.7874 - val_loss: 0.4536 - val_accuracy: 0.7827\n",
      "Epoch 214/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4440 - accuracy: 0.7895 - val_loss: 0.4639 - val_accuracy: 0.7836\n",
      "Epoch 215/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4436 - accuracy: 0.7887 - val_loss: 0.4526 - val_accuracy: 0.7871\n",
      "Epoch 216/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4440 - accuracy: 0.7878 - val_loss: 0.4640 - val_accuracy: 0.7731\n",
      "Epoch 217/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4430 - accuracy: 0.7886 - val_loss: 0.4641 - val_accuracy: 0.7789\n",
      "Epoch 218/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4436 - accuracy: 0.7886 - val_loss: 0.4625 - val_accuracy: 0.7723\n",
      "Epoch 219/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4436 - accuracy: 0.7885 - val_loss: 0.4598 - val_accuracy: 0.7817\n",
      "Epoch 220/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4432 - accuracy: 0.7891 - val_loss: 0.4586 - val_accuracy: 0.7850\n",
      "Epoch 221/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4438 - accuracy: 0.7886 - val_loss: 0.4540 - val_accuracy: 0.7824\n",
      "Epoch 222/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4426 - accuracy: 0.7901 - val_loss: 0.4530 - val_accuracy: 0.7827\n",
      "Epoch 223/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4431 - accuracy: 0.7892 - val_loss: 0.4533 - val_accuracy: 0.7852\n",
      "Epoch 224/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4432 - accuracy: 0.7893 - val_loss: 0.4597 - val_accuracy: 0.7781\n",
      "Epoch 225/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4428 - accuracy: 0.7898 - val_loss: 0.4609 - val_accuracy: 0.7827\n",
      "Epoch 226/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4431 - accuracy: 0.7883 - val_loss: 0.4559 - val_accuracy: 0.7813\n",
      "Epoch 227/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4431 - accuracy: 0.7891 - val_loss: 0.4634 - val_accuracy: 0.7778\n",
      "Epoch 228/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4426 - accuracy: 0.7895 - val_loss: 0.4516 - val_accuracy: 0.7869\n",
      "Epoch 229/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4423 - accuracy: 0.7891 - val_loss: 0.4540 - val_accuracy: 0.7813\n",
      "Epoch 230/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4430 - accuracy: 0.7888 - val_loss: 0.4537 - val_accuracy: 0.7847\n",
      "Epoch 231/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4427 - accuracy: 0.7890 - val_loss: 0.4579 - val_accuracy: 0.7847\n",
      "Epoch 232/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4422 - accuracy: 0.7894 - val_loss: 0.4511 - val_accuracy: 0.7847\n",
      "Epoch 233/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4430 - accuracy: 0.7894 - val_loss: 0.4527 - val_accuracy: 0.7873\n",
      "Epoch 234/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4430 - accuracy: 0.7896 - val_loss: 0.4679 - val_accuracy: 0.7751\n",
      "Epoch 235/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4428 - accuracy: 0.7901 - val_loss: 0.4524 - val_accuracy: 0.7858\n",
      "Epoch 236/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4426 - accuracy: 0.7888 - val_loss: 0.4564 - val_accuracy: 0.7829\n",
      "Epoch 237/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4419 - accuracy: 0.7893 - val_loss: 0.4585 - val_accuracy: 0.7834\n",
      "Epoch 238/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4424 - accuracy: 0.7887 - val_loss: 0.4479 - val_accuracy: 0.7889\n",
      "Epoch 239/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4429 - accuracy: 0.7896 - val_loss: 0.4509 - val_accuracy: 0.7859\n",
      "Epoch 240/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4426 - accuracy: 0.7904 - val_loss: 0.4532 - val_accuracy: 0.7844\n",
      "Epoch 241/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4528 - val_accuracy: 0.7869\n",
      "Epoch 242/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4418 - accuracy: 0.7908 - val_loss: 0.4529 - val_accuracy: 0.7842\n",
      "Epoch 243/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4423 - accuracy: 0.7896 - val_loss: 0.4652 - val_accuracy: 0.7851\n",
      "Epoch 244/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4420 - accuracy: 0.7891 - val_loss: 0.4572 - val_accuracy: 0.7846\n",
      "Epoch 245/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4428 - accuracy: 0.7886 - val_loss: 0.4482 - val_accuracy: 0.7886\n",
      "Epoch 246/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4426 - accuracy: 0.7908 - val_loss: 0.4594 - val_accuracy: 0.7821\n",
      "Epoch 247/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4418 - accuracy: 0.7892 - val_loss: 0.4538 - val_accuracy: 0.7871\n",
      "Epoch 248/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4425 - accuracy: 0.7888 - val_loss: 0.4544 - val_accuracy: 0.7868\n",
      "Epoch 249/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4416 - accuracy: 0.7909 - val_loss: 0.4516 - val_accuracy: 0.7863\n",
      "Epoch 250/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4420 - accuracy: 0.7907 - val_loss: 0.4488 - val_accuracy: 0.7891\n",
      "Epoch 251/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4421 - accuracy: 0.7893 - val_loss: 0.4554 - val_accuracy: 0.7892\n",
      "Epoch 252/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4412 - accuracy: 0.7906 - val_loss: 0.4558 - val_accuracy: 0.7814\n",
      "Epoch 253/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4409 - accuracy: 0.7906 - val_loss: 0.4519 - val_accuracy: 0.7870\n",
      "Epoch 254/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4416 - accuracy: 0.7901 - val_loss: 0.4559 - val_accuracy: 0.7833\n",
      "Epoch 255/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4419 - accuracy: 0.7895 - val_loss: 0.4516 - val_accuracy: 0.7887\n",
      "Epoch 256/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4410 - accuracy: 0.7911 - val_loss: 0.4538 - val_accuracy: 0.7839\n",
      "Epoch 257/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4415 - accuracy: 0.7898 - val_loss: 0.4614 - val_accuracy: 0.7851\n",
      "Epoch 258/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4412 - accuracy: 0.7907 - val_loss: 0.4495 - val_accuracy: 0.7894\n",
      "Epoch 259/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4411 - accuracy: 0.7904 - val_loss: 0.4563 - val_accuracy: 0.7837\n",
      "Epoch 260/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4408 - accuracy: 0.7908 - val_loss: 0.4521 - val_accuracy: 0.7873\n",
      "Epoch 261/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4415 - accuracy: 0.7902 - val_loss: 0.4594 - val_accuracy: 0.7794\n",
      "Epoch 262/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4413 - accuracy: 0.7900 - val_loss: 0.4554 - val_accuracy: 0.7851\n",
      "Epoch 263/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4414 - accuracy: 0.7910 - val_loss: 0.4495 - val_accuracy: 0.7891\n",
      "Epoch 264/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4406 - accuracy: 0.7898 - val_loss: 0.4608 - val_accuracy: 0.7831\n",
      "Epoch 265/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4408 - accuracy: 0.7907 - val_loss: 0.4538 - val_accuracy: 0.7851\n",
      "Epoch 266/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4405 - accuracy: 0.7912 - val_loss: 0.4510 - val_accuracy: 0.7876\n",
      "Epoch 267/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4414 - accuracy: 0.7900 - val_loss: 0.4519 - val_accuracy: 0.7850\n",
      "Epoch 268/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4410 - accuracy: 0.7914 - val_loss: 0.4531 - val_accuracy: 0.7836\n",
      "Epoch 269/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4405 - accuracy: 0.7913 - val_loss: 0.4585 - val_accuracy: 0.7864\n",
      "Epoch 270/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4408 - accuracy: 0.7911 - val_loss: 0.4511 - val_accuracy: 0.7893\n",
      "Epoch 271/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4398 - accuracy: 0.7922 - val_loss: 0.4556 - val_accuracy: 0.7825\n",
      "Epoch 272/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4405 - accuracy: 0.7910 - val_loss: 0.4540 - val_accuracy: 0.7844\n",
      "Epoch 273/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4405 - accuracy: 0.7912 - val_loss: 0.4544 - val_accuracy: 0.7851\n",
      "Epoch 274/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4402 - accuracy: 0.7905 - val_loss: 0.4537 - val_accuracy: 0.7887\n",
      "Epoch 275/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4399 - accuracy: 0.7907 - val_loss: 0.4582 - val_accuracy: 0.7883\n",
      "Epoch 276/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4399 - accuracy: 0.7918 - val_loss: 0.4568 - val_accuracy: 0.7881\n",
      "Epoch 277/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4406 - accuracy: 0.7905 - val_loss: 0.4534 - val_accuracy: 0.7825\n",
      "Epoch 278/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4407 - accuracy: 0.7905 - val_loss: 0.4508 - val_accuracy: 0.7868\n",
      "Epoch 279/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4395 - accuracy: 0.7914 - val_loss: 0.4535 - val_accuracy: 0.7857\n",
      "Epoch 280/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4402 - accuracy: 0.7916 - val_loss: 0.4519 - val_accuracy: 0.7862\n",
      "Epoch 281/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.4586 - val_accuracy: 0.7834\n",
      "Epoch 282/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4401 - accuracy: 0.7912 - val_loss: 0.4577 - val_accuracy: 0.7860\n",
      "Epoch 283/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4401 - accuracy: 0.7908 - val_loss: 0.4599 - val_accuracy: 0.7819\n",
      "Epoch 284/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4398 - accuracy: 0.7906 - val_loss: 0.4511 - val_accuracy: 0.7883\n",
      "Epoch 285/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4397 - accuracy: 0.7922 - val_loss: 0.4522 - val_accuracy: 0.7856\n",
      "Epoch 286/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4393 - accuracy: 0.7920 - val_loss: 0.4536 - val_accuracy: 0.7871\n",
      "Epoch 287/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4394 - accuracy: 0.7918 - val_loss: 0.4514 - val_accuracy: 0.7877\n",
      "Epoch 288/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4393 - accuracy: 0.7919 - val_loss: 0.4553 - val_accuracy: 0.7834\n",
      "Epoch 289/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4397 - accuracy: 0.7909 - val_loss: 0.4505 - val_accuracy: 0.7887\n",
      "Epoch 290/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4393 - accuracy: 0.7914 - val_loss: 0.4526 - val_accuracy: 0.7864\n",
      "Epoch 291/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4398 - accuracy: 0.7908 - val_loss: 0.4529 - val_accuracy: 0.7857\n",
      "Epoch 292/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4396 - accuracy: 0.7920 - val_loss: 0.4553 - val_accuracy: 0.7813\n",
      "Epoch 293/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4395 - accuracy: 0.7917 - val_loss: 0.4549 - val_accuracy: 0.7830\n",
      "Epoch 294/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4400 - accuracy: 0.7903 - val_loss: 0.4639 - val_accuracy: 0.7835\n",
      "Epoch 295/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4396 - accuracy: 0.7906 - val_loss: 0.4520 - val_accuracy: 0.7885\n",
      "Epoch 296/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4392 - accuracy: 0.7906 - val_loss: 0.4531 - val_accuracy: 0.7859\n",
      "Epoch 297/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4395 - accuracy: 0.7915 - val_loss: 0.4487 - val_accuracy: 0.7896\n",
      "Epoch 298/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4391 - accuracy: 0.7914 - val_loss: 0.4502 - val_accuracy: 0.7857\n",
      "Epoch 299/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4389 - accuracy: 0.7930 - val_loss: 0.4485 - val_accuracy: 0.7896\n",
      "Epoch 300/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4387 - accuracy: 0.7923 - val_loss: 0.4571 - val_accuracy: 0.7843\n",
      "Epoch 301/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4391 - accuracy: 0.7919 - val_loss: 0.4467 - val_accuracy: 0.7898\n",
      "Epoch 302/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4391 - accuracy: 0.7918 - val_loss: 0.4499 - val_accuracy: 0.7881\n",
      "Epoch 303/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4398 - accuracy: 0.7911 - val_loss: 0.4503 - val_accuracy: 0.7857\n",
      "Epoch 304/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4384 - accuracy: 0.7914 - val_loss: 0.4471 - val_accuracy: 0.7904\n",
      "Epoch 305/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4390 - accuracy: 0.7916 - val_loss: 0.4522 - val_accuracy: 0.7882\n",
      "Epoch 306/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4383 - accuracy: 0.7926 - val_loss: 0.4531 - val_accuracy: 0.7860\n",
      "Epoch 307/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4389 - accuracy: 0.7914 - val_loss: 0.4516 - val_accuracy: 0.7868\n",
      "Epoch 308/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4379 - accuracy: 0.7925 - val_loss: 0.4507 - val_accuracy: 0.7887\n",
      "Epoch 309/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4385 - accuracy: 0.7916 - val_loss: 0.4581 - val_accuracy: 0.7828\n",
      "Epoch 310/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4382 - accuracy: 0.7931 - val_loss: 0.4515 - val_accuracy: 0.7877\n",
      "Epoch 311/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4383 - accuracy: 0.7927 - val_loss: 0.4529 - val_accuracy: 0.7901\n",
      "Epoch 312/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4388 - accuracy: 0.7916 - val_loss: 0.4495 - val_accuracy: 0.7890\n",
      "Epoch 313/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4386 - accuracy: 0.7915 - val_loss: 0.4515 - val_accuracy: 0.7925\n",
      "Epoch 314/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4381 - accuracy: 0.7933 - val_loss: 0.4641 - val_accuracy: 0.7788\n",
      "Epoch 315/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4395 - accuracy: 0.7918 - val_loss: 0.4498 - val_accuracy: 0.7878\n",
      "Epoch 316/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.4548 - val_accuracy: 0.7848\n",
      "Epoch 317/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4381 - accuracy: 0.7926 - val_loss: 0.4532 - val_accuracy: 0.7885\n",
      "Epoch 318/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4381 - accuracy: 0.7923 - val_loss: 0.4506 - val_accuracy: 0.7875\n",
      "Epoch 319/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4380 - accuracy: 0.7928 - val_loss: 0.4501 - val_accuracy: 0.7885\n",
      "Epoch 320/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4384 - accuracy: 0.7925 - val_loss: 0.4488 - val_accuracy: 0.7898\n",
      "Epoch 321/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4386 - accuracy: 0.7919 - val_loss: 0.4505 - val_accuracy: 0.7890\n",
      "Epoch 322/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4377 - accuracy: 0.7924 - val_loss: 0.4500 - val_accuracy: 0.7901\n",
      "Epoch 323/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4384 - accuracy: 0.7933 - val_loss: 0.4471 - val_accuracy: 0.7905\n",
      "Epoch 324/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4382 - accuracy: 0.7924 - val_loss: 0.4591 - val_accuracy: 0.7809\n",
      "Epoch 325/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4381 - accuracy: 0.7927 - val_loss: 0.4528 - val_accuracy: 0.7907\n",
      "Epoch 326/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4380 - accuracy: 0.7927 - val_loss: 0.4491 - val_accuracy: 0.7885\n",
      "Epoch 327/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4379 - accuracy: 0.7935 - val_loss: 0.4560 - val_accuracy: 0.7813\n",
      "Epoch 328/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4383 - accuracy: 0.7932 - val_loss: 0.4475 - val_accuracy: 0.7890\n",
      "Epoch 329/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4377 - accuracy: 0.7924 - val_loss: 0.4488 - val_accuracy: 0.7893\n",
      "Epoch 330/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4379 - accuracy: 0.7933 - val_loss: 0.4505 - val_accuracy: 0.7865\n",
      "Epoch 331/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4373 - accuracy: 0.7927 - val_loss: 0.4629 - val_accuracy: 0.7783\n",
      "Epoch 332/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4374 - accuracy: 0.7936 - val_loss: 0.4487 - val_accuracy: 0.7864\n",
      "Epoch 333/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4373 - accuracy: 0.7923 - val_loss: 0.4491 - val_accuracy: 0.7869\n",
      "Epoch 334/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4381 - accuracy: 0.7930 - val_loss: 0.4474 - val_accuracy: 0.7914\n",
      "Epoch 335/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4374 - accuracy: 0.7922 - val_loss: 0.4475 - val_accuracy: 0.7894\n",
      "Epoch 336/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4377 - accuracy: 0.7925 - val_loss: 0.4550 - val_accuracy: 0.7828\n",
      "Epoch 337/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4372 - accuracy: 0.7935 - val_loss: 0.4474 - val_accuracy: 0.7886\n",
      "Epoch 338/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4375 - accuracy: 0.7925 - val_loss: 0.4512 - val_accuracy: 0.7901\n",
      "Epoch 339/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4380 - accuracy: 0.7930 - val_loss: 0.4570 - val_accuracy: 0.7842\n",
      "Epoch 340/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4375 - accuracy: 0.7930 - val_loss: 0.4494 - val_accuracy: 0.7872\n",
      "Epoch 341/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4381 - accuracy: 0.7927 - val_loss: 0.4483 - val_accuracy: 0.7890\n",
      "Epoch 342/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4367 - accuracy: 0.7933 - val_loss: 0.4563 - val_accuracy: 0.7852\n",
      "Epoch 343/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4374 - accuracy: 0.7939 - val_loss: 0.4476 - val_accuracy: 0.7902\n",
      "Epoch 344/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4380 - accuracy: 0.7925 - val_loss: 0.4517 - val_accuracy: 0.7860\n",
      "Epoch 345/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4367 - accuracy: 0.7933 - val_loss: 0.4487 - val_accuracy: 0.7926\n",
      "Epoch 346/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4373 - accuracy: 0.7931 - val_loss: 0.4588 - val_accuracy: 0.7851\n",
      "Epoch 347/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4374 - accuracy: 0.7928 - val_loss: 0.4457 - val_accuracy: 0.7923\n",
      "Epoch 348/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4368 - accuracy: 0.7935 - val_loss: 0.4491 - val_accuracy: 0.7880\n",
      "Epoch 349/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4367 - accuracy: 0.7939 - val_loss: 0.4483 - val_accuracy: 0.7907\n",
      "Epoch 350/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4373 - accuracy: 0.7939 - val_loss: 0.4494 - val_accuracy: 0.7887\n",
      "Epoch 351/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4474 - val_accuracy: 0.7916\n",
      "Epoch 352/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4364 - accuracy: 0.7933 - val_loss: 0.4582 - val_accuracy: 0.7867\n",
      "Epoch 353/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4365 - accuracy: 0.7935 - val_loss: 0.4678 - val_accuracy: 0.7687\n",
      "Epoch 354/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4367 - accuracy: 0.7933 - val_loss: 0.4499 - val_accuracy: 0.7862\n",
      "Epoch 355/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4539 - val_accuracy: 0.7874\n",
      "Epoch 356/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4368 - accuracy: 0.7931 - val_loss: 0.4585 - val_accuracy: 0.7831\n",
      "Epoch 357/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4366 - accuracy: 0.7931 - val_loss: 0.4551 - val_accuracy: 0.7841\n",
      "Epoch 358/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4362 - accuracy: 0.7930 - val_loss: 0.4515 - val_accuracy: 0.7893\n",
      "Epoch 359/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4364 - accuracy: 0.7936 - val_loss: 0.4483 - val_accuracy: 0.7913\n",
      "Epoch 360/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4368 - accuracy: 0.7933 - val_loss: 0.4497 - val_accuracy: 0.7902\n",
      "Epoch 361/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4362 - accuracy: 0.7943 - val_loss: 0.4458 - val_accuracy: 0.7908\n",
      "Epoch 362/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4363 - accuracy: 0.7936 - val_loss: 0.4517 - val_accuracy: 0.7870\n",
      "Epoch 363/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4362 - accuracy: 0.7959 - val_loss: 0.4499 - val_accuracy: 0.7901\n",
      "Epoch 364/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.4512 - val_accuracy: 0.7901\n",
      "Epoch 365/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7928 - val_loss: 0.4493 - val_accuracy: 0.7907\n",
      "Epoch 366/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4365 - accuracy: 0.7938 - val_loss: 0.4577 - val_accuracy: 0.7842\n",
      "Epoch 367/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4363 - accuracy: 0.7943 - val_loss: 0.4508 - val_accuracy: 0.7879\n",
      "Epoch 368/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4359 - accuracy: 0.7940 - val_loss: 0.4471 - val_accuracy: 0.7906\n",
      "Epoch 369/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4363 - accuracy: 0.7939 - val_loss: 0.4442 - val_accuracy: 0.7921\n",
      "Epoch 370/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4360 - accuracy: 0.7948 - val_loss: 0.4465 - val_accuracy: 0.7899\n",
      "Epoch 371/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7937 - val_loss: 0.4458 - val_accuracy: 0.7893\n",
      "Epoch 372/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4360 - accuracy: 0.7929 - val_loss: 0.4491 - val_accuracy: 0.7893\n",
      "Epoch 373/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.4495 - val_accuracy: 0.7884\n",
      "Epoch 374/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7933 - val_loss: 0.4532 - val_accuracy: 0.7872\n",
      "Epoch 375/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4362 - accuracy: 0.7939 - val_loss: 0.4544 - val_accuracy: 0.7854\n",
      "Epoch 376/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4362 - accuracy: 0.7940 - val_loss: 0.4535 - val_accuracy: 0.7844\n",
      "Epoch 377/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4356 - accuracy: 0.7942 - val_loss: 0.4474 - val_accuracy: 0.7917\n",
      "Epoch 378/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4359 - accuracy: 0.7928 - val_loss: 0.4467 - val_accuracy: 0.7943\n",
      "Epoch 379/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4360 - accuracy: 0.7936 - val_loss: 0.4519 - val_accuracy: 0.7897\n",
      "Epoch 380/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4369 - accuracy: 0.7931 - val_loss: 0.4499 - val_accuracy: 0.7901\n",
      "Epoch 381/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4355 - accuracy: 0.7932 - val_loss: 0.4502 - val_accuracy: 0.7909\n",
      "Epoch 382/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4356 - accuracy: 0.7938 - val_loss: 0.4587 - val_accuracy: 0.7839\n",
      "Epoch 383/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4364 - accuracy: 0.7935 - val_loss: 0.4456 - val_accuracy: 0.7930\n",
      "Epoch 384/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4361 - accuracy: 0.7933 - val_loss: 0.4471 - val_accuracy: 0.7911\n",
      "Epoch 385/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4352 - accuracy: 0.7947 - val_loss: 0.4569 - val_accuracy: 0.7824\n",
      "Epoch 386/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4356 - accuracy: 0.7941 - val_loss: 0.4527 - val_accuracy: 0.7897\n",
      "Epoch 387/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7929 - val_loss: 0.4478 - val_accuracy: 0.7882\n",
      "Epoch 388/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4354 - accuracy: 0.7953 - val_loss: 0.4552 - val_accuracy: 0.7857\n",
      "Epoch 389/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4355 - accuracy: 0.7948 - val_loss: 0.4507 - val_accuracy: 0.7885\n",
      "Epoch 390/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4517 - val_accuracy: 0.7890\n",
      "Epoch 391/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4358 - accuracy: 0.7947 - val_loss: 0.4456 - val_accuracy: 0.7912\n",
      "Epoch 392/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4355 - accuracy: 0.7943 - val_loss: 0.4470 - val_accuracy: 0.7930\n",
      "Epoch 393/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7935 - val_loss: 0.4481 - val_accuracy: 0.7902\n",
      "Epoch 394/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4351 - accuracy: 0.7941 - val_loss: 0.4505 - val_accuracy: 0.7854\n",
      "Epoch 395/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4350 - accuracy: 0.7943 - val_loss: 0.4515 - val_accuracy: 0.7891\n",
      "Epoch 396/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7939 - val_loss: 0.4480 - val_accuracy: 0.7896\n",
      "Epoch 397/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4352 - accuracy: 0.7933 - val_loss: 0.4473 - val_accuracy: 0.7910\n",
      "Epoch 398/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4356 - accuracy: 0.7929 - val_loss: 0.4454 - val_accuracy: 0.7913\n",
      "Epoch 399/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4351 - accuracy: 0.7931 - val_loss: 0.4509 - val_accuracy: 0.7884\n",
      "Epoch 400/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4352 - accuracy: 0.7944 - val_loss: 0.4506 - val_accuracy: 0.7871\n",
      "Epoch 401/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.4517 - val_accuracy: 0.7865\n",
      "Epoch 402/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4345 - accuracy: 0.7943 - val_loss: 0.4462 - val_accuracy: 0.7923\n",
      "Epoch 403/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4345 - accuracy: 0.7948 - val_loss: 0.4536 - val_accuracy: 0.7844\n",
      "Epoch 404/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4353 - accuracy: 0.7939 - val_loss: 0.4476 - val_accuracy: 0.7900\n",
      "Epoch 405/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4346 - accuracy: 0.7935 - val_loss: 0.4540 - val_accuracy: 0.7878\n",
      "Epoch 406/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4349 - accuracy: 0.7946 - val_loss: 0.4523 - val_accuracy: 0.7846\n",
      "Epoch 407/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4352 - accuracy: 0.7946 - val_loss: 0.4490 - val_accuracy: 0.7884\n",
      "Epoch 408/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4351 - accuracy: 0.7950 - val_loss: 0.4537 - val_accuracy: 0.7877\n",
      "Epoch 409/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4343 - accuracy: 0.7942 - val_loss: 0.4534 - val_accuracy: 0.7801\n",
      "Epoch 410/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4347 - accuracy: 0.7943 - val_loss: 0.4447 - val_accuracy: 0.7966\n",
      "Epoch 411/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4515 - val_accuracy: 0.7904\n",
      "Epoch 412/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4348 - accuracy: 0.7943 - val_loss: 0.4549 - val_accuracy: 0.7821\n",
      "Epoch 413/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4350 - accuracy: 0.7945 - val_loss: 0.4490 - val_accuracy: 0.7897\n",
      "Epoch 414/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4479 - val_accuracy: 0.7904\n",
      "Epoch 415/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4345 - accuracy: 0.7945 - val_loss: 0.4554 - val_accuracy: 0.7825\n",
      "Epoch 416/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4342 - accuracy: 0.7950 - val_loss: 0.4449 - val_accuracy: 0.7905\n",
      "Epoch 417/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4343 - accuracy: 0.7947 - val_loss: 0.4456 - val_accuracy: 0.7909\n",
      "Epoch 418/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4346 - accuracy: 0.7956 - val_loss: 0.4491 - val_accuracy: 0.7878\n",
      "Epoch 419/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4677 - val_accuracy: 0.7851\n",
      "Epoch 420/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4347 - accuracy: 0.7948 - val_loss: 0.4508 - val_accuracy: 0.7885\n",
      "Epoch 421/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4350 - accuracy: 0.7942 - val_loss: 0.4559 - val_accuracy: 0.7783\n",
      "Epoch 422/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4348 - accuracy: 0.7942 - val_loss: 0.4567 - val_accuracy: 0.7851\n",
      "Epoch 423/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4345 - accuracy: 0.7945 - val_loss: 0.4593 - val_accuracy: 0.7805\n",
      "Epoch 424/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4343 - accuracy: 0.7954 - val_loss: 0.4490 - val_accuracy: 0.7874\n",
      "Epoch 425/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4348 - accuracy: 0.7950 - val_loss: 0.4462 - val_accuracy: 0.7938\n",
      "Epoch 426/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4346 - accuracy: 0.7952 - val_loss: 0.4445 - val_accuracy: 0.7920\n",
      "Epoch 427/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4339 - accuracy: 0.7947 - val_loss: 0.4517 - val_accuracy: 0.7865\n",
      "Epoch 428/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4339 - accuracy: 0.7940 - val_loss: 0.4533 - val_accuracy: 0.7879\n",
      "Epoch 429/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4349 - accuracy: 0.7958 - val_loss: 0.4462 - val_accuracy: 0.7925\n",
      "Epoch 430/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4336 - accuracy: 0.7961 - val_loss: 0.4427 - val_accuracy: 0.7946\n",
      "Epoch 431/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4344 - accuracy: 0.7954 - val_loss: 0.4502 - val_accuracy: 0.7879\n",
      "Epoch 432/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4335 - accuracy: 0.7958 - val_loss: 0.4547 - val_accuracy: 0.7865\n",
      "Epoch 433/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4342 - accuracy: 0.7942 - val_loss: 0.4463 - val_accuracy: 0.7886\n",
      "Epoch 434/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4339 - accuracy: 0.7957 - val_loss: 0.4446 - val_accuracy: 0.7931\n",
      "Epoch 435/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4335 - accuracy: 0.7953 - val_loss: 0.4458 - val_accuracy: 0.7890\n",
      "Epoch 436/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4341 - accuracy: 0.7949 - val_loss: 0.4585 - val_accuracy: 0.7878\n",
      "Epoch 437/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4342 - accuracy: 0.7941 - val_loss: 0.4457 - val_accuracy: 0.7925\n",
      "Epoch 438/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4339 - accuracy: 0.7958 - val_loss: 0.4481 - val_accuracy: 0.7883\n",
      "Epoch 439/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4340 - accuracy: 0.7952 - val_loss: 0.4467 - val_accuracy: 0.7936\n",
      "Epoch 440/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4337 - accuracy: 0.7959 - val_loss: 0.4482 - val_accuracy: 0.7890\n",
      "Epoch 441/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4340 - accuracy: 0.7955 - val_loss: 0.4455 - val_accuracy: 0.7884\n",
      "Epoch 442/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4340 - accuracy: 0.7955 - val_loss: 0.4580 - val_accuracy: 0.7802\n",
      "Epoch 443/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4331 - accuracy: 0.7952 - val_loss: 0.4482 - val_accuracy: 0.7887\n",
      "Epoch 444/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4337 - accuracy: 0.7960 - val_loss: 0.4468 - val_accuracy: 0.7912\n",
      "Epoch 445/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4339 - accuracy: 0.7955 - val_loss: 0.4461 - val_accuracy: 0.7905\n",
      "Epoch 446/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4335 - accuracy: 0.7955 - val_loss: 0.4457 - val_accuracy: 0.7939\n",
      "Epoch 447/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4342 - accuracy: 0.7948 - val_loss: 0.4512 - val_accuracy: 0.7880\n",
      "Epoch 448/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4344 - accuracy: 0.7946 - val_loss: 0.4472 - val_accuracy: 0.7895\n",
      "Epoch 449/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4334 - accuracy: 0.7965 - val_loss: 0.4501 - val_accuracy: 0.7890\n",
      "Epoch 450/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4337 - accuracy: 0.7956 - val_loss: 0.4487 - val_accuracy: 0.7911\n",
      "Epoch 451/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4335 - accuracy: 0.7956 - val_loss: 0.4483 - val_accuracy: 0.7867\n",
      "Epoch 452/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4335 - accuracy: 0.7946 - val_loss: 0.4506 - val_accuracy: 0.7881\n",
      "Epoch 453/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4328 - accuracy: 0.7963 - val_loss: 0.4495 - val_accuracy: 0.7886\n",
      "Epoch 454/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4335 - accuracy: 0.7953 - val_loss: 0.4471 - val_accuracy: 0.7918\n",
      "Epoch 455/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4335 - accuracy: 0.7945 - val_loss: 0.4451 - val_accuracy: 0.7933\n",
      "Epoch 456/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4337 - accuracy: 0.7945 - val_loss: 0.4476 - val_accuracy: 0.7881\n",
      "Epoch 457/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4337 - accuracy: 0.7952 - val_loss: 0.4458 - val_accuracy: 0.7917\n",
      "Epoch 458/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4338 - accuracy: 0.7958 - val_loss: 0.4521 - val_accuracy: 0.7837\n",
      "Epoch 459/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4329 - accuracy: 0.7957 - val_loss: 0.4457 - val_accuracy: 0.7947\n",
      "Epoch 460/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4340 - accuracy: 0.7954 - val_loss: 0.4430 - val_accuracy: 0.7942\n",
      "Epoch 461/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4331 - accuracy: 0.7957 - val_loss: 0.4465 - val_accuracy: 0.7909\n",
      "Epoch 462/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4333 - accuracy: 0.7958 - val_loss: 0.4475 - val_accuracy: 0.7877\n",
      "Epoch 463/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.4476 - val_accuracy: 0.7925\n",
      "Epoch 464/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4333 - accuracy: 0.7955 - val_loss: 0.4469 - val_accuracy: 0.7941\n",
      "Epoch 465/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4334 - accuracy: 0.7958 - val_loss: 0.4476 - val_accuracy: 0.7903\n",
      "Epoch 466/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4332 - accuracy: 0.7953 - val_loss: 0.4488 - val_accuracy: 0.7879\n",
      "Epoch 467/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4328 - accuracy: 0.7958 - val_loss: 0.4524 - val_accuracy: 0.7829\n",
      "Epoch 468/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4330 - accuracy: 0.7960 - val_loss: 0.4474 - val_accuracy: 0.7891\n",
      "Epoch 469/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4330 - accuracy: 0.7951 - val_loss: 0.4507 - val_accuracy: 0.7878\n",
      "Epoch 470/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4336 - accuracy: 0.7954 - val_loss: 0.4561 - val_accuracy: 0.7860\n",
      "Epoch 471/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4332 - accuracy: 0.7962 - val_loss: 0.4471 - val_accuracy: 0.7921\n",
      "Epoch 472/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4329 - accuracy: 0.7956 - val_loss: 0.4539 - val_accuracy: 0.7934\n",
      "Epoch 473/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4325 - accuracy: 0.7960 - val_loss: 0.4453 - val_accuracy: 0.7939\n",
      "Epoch 474/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4325 - accuracy: 0.7966 - val_loss: 0.4555 - val_accuracy: 0.7868\n",
      "Epoch 475/500\n",
      "92096/92096 [==============================] - 4s 41us/sample - loss: 0.4327 - accuracy: 0.7954 - val_loss: 0.4455 - val_accuracy: 0.7926\n",
      "Epoch 476/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4324 - accuracy: 0.7954 - val_loss: 0.4462 - val_accuracy: 0.7920\n",
      "Epoch 477/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4333 - accuracy: 0.7954 - val_loss: 0.4443 - val_accuracy: 0.7949\n",
      "Epoch 478/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4326 - accuracy: 0.7955 - val_loss: 0.4516 - val_accuracy: 0.7845\n",
      "Epoch 479/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4328 - accuracy: 0.7959 - val_loss: 0.4454 - val_accuracy: 0.7906\n",
      "Epoch 480/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4324 - accuracy: 0.7956 - val_loss: 0.4429 - val_accuracy: 0.7949\n",
      "Epoch 481/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4333 - accuracy: 0.7953 - val_loss: 0.4485 - val_accuracy: 0.7918\n",
      "Epoch 482/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4323 - accuracy: 0.7955 - val_loss: 0.4470 - val_accuracy: 0.7917\n",
      "Epoch 483/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4320 - accuracy: 0.7956 - val_loss: 0.4523 - val_accuracy: 0.7897\n",
      "Epoch 484/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4328 - accuracy: 0.7963 - val_loss: 0.4466 - val_accuracy: 0.7950\n",
      "Epoch 485/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4322 - accuracy: 0.7964 - val_loss: 0.4475 - val_accuracy: 0.7925\n",
      "Epoch 486/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4324 - accuracy: 0.7956 - val_loss: 0.4425 - val_accuracy: 0.7947\n",
      "Epoch 487/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4324 - accuracy: 0.7960 - val_loss: 0.4452 - val_accuracy: 0.7920\n",
      "Epoch 488/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4324 - accuracy: 0.7963 - val_loss: 0.4486 - val_accuracy: 0.7907\n",
      "Epoch 489/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.4448 - val_accuracy: 0.7907\n",
      "Epoch 490/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4323 - accuracy: 0.7962 - val_loss: 0.4483 - val_accuracy: 0.7880\n",
      "Epoch 491/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4322 - accuracy: 0.7965 - val_loss: 0.4469 - val_accuracy: 0.7902\n",
      "Epoch 492/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4322 - accuracy: 0.7962 - val_loss: 0.4461 - val_accuracy: 0.7910\n",
      "Epoch 493/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4322 - accuracy: 0.7959 - val_loss: 0.4450 - val_accuracy: 0.7921\n",
      "Epoch 494/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4324 - accuracy: 0.7953 - val_loss: 0.4486 - val_accuracy: 0.7862\n",
      "Epoch 495/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4332 - accuracy: 0.7953 - val_loss: 0.4456 - val_accuracy: 0.7880\n",
      "Epoch 496/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4319 - accuracy: 0.7961 - val_loss: 0.4439 - val_accuracy: 0.7905\n",
      "Epoch 497/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4322 - accuracy: 0.7970 - val_loss: 0.4476 - val_accuracy: 0.7898\n",
      "Epoch 498/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4327 - accuracy: 0.7968 - val_loss: 0.4505 - val_accuracy: 0.7850\n",
      "Epoch 499/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4325 - accuracy: 0.7959 - val_loss: 0.4459 - val_accuracy: 0.7926\n",
      "Epoch 500/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4324 - accuracy: 0.7957 - val_loss: 0.4483 - val_accuracy: 0.7879\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(shuffle(pd.DataFrame(x_train_resampled),random_state=1), shuffle(pd.DataFrame(y_train_resampled),random_state=1), epochs=500,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train_resampled)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_7.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 8\n",
    "-Standard Scaler & Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 362\n",
      "Trainable params: 362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92096 samples, validate on 23024 samples\n",
      "Epoch 1/500\n",
      "91904/92096 [============================>.] - ETA: 0s - loss: 0.5854 - accuracy: 0.6808"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/Ä°ÅŸBankasÄ± ML Challenge TR 3/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5854 - accuracy: 0.6809 - val_loss: 0.5697 - val_accuracy: 0.7009\n",
      "Epoch 2/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5664 - accuracy: 0.7016 - val_loss: 0.5639 - val_accuracy: 0.7032\n",
      "Epoch 3/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5615 - accuracy: 0.7057 - val_loss: 0.5584 - val_accuracy: 0.7078\n",
      "Epoch 4/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5584 - accuracy: 0.7080 - val_loss: 0.5579 - val_accuracy: 0.7057\n",
      "Epoch 5/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5561 - accuracy: 0.7096 - val_loss: 0.5548 - val_accuracy: 0.7080\n",
      "Epoch 6/500\n",
      "92096/92096 [==============================] - 2s 23us/sample - loss: 0.5541 - accuracy: 0.7100 - val_loss: 0.5530 - val_accuracy: 0.7083\n",
      "Epoch 7/500\n",
      "92096/92096 [==============================] - 2s 23us/sample - loss: 0.5524 - accuracy: 0.7124 - val_loss: 0.5514 - val_accuracy: 0.7101\n",
      "Epoch 8/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5511 - accuracy: 0.7136 - val_loss: 0.5493 - val_accuracy: 0.7124\n",
      "Epoch 9/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5497 - accuracy: 0.7142 - val_loss: 0.5492 - val_accuracy: 0.7178\n",
      "Epoch 10/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5489 - accuracy: 0.7151 - val_loss: 0.5473 - val_accuracy: 0.7157\n",
      "Epoch 11/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5479 - accuracy: 0.7146 - val_loss: 0.5464 - val_accuracy: 0.7184\n",
      "Epoch 12/500\n",
      "92096/92096 [==============================] - 2s 23us/sample - loss: 0.5471 - accuracy: 0.7166 - val_loss: 0.5456 - val_accuracy: 0.7191\n",
      "Epoch 13/500\n",
      "92096/92096 [==============================] - 2s 23us/sample - loss: 0.5462 - accuracy: 0.7177 - val_loss: 0.5448 - val_accuracy: 0.7163\n",
      "Epoch 14/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5453 - accuracy: 0.7173 - val_loss: 0.5444 - val_accuracy: 0.7208\n",
      "Epoch 15/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5447 - accuracy: 0.7185 - val_loss: 0.5456 - val_accuracy: 0.7162\n",
      "Epoch 16/500\n",
      "92096/92096 [==============================] - 2s 23us/sample - loss: 0.5439 - accuracy: 0.7176 - val_loss: 0.5421 - val_accuracy: 0.7219\n",
      "Epoch 17/500\n",
      "92096/92096 [==============================] - 2s 23us/sample - loss: 0.5432 - accuracy: 0.7191 - val_loss: 0.5422 - val_accuracy: 0.7200\n",
      "Epoch 18/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5424 - accuracy: 0.7192 - val_loss: 0.5426 - val_accuracy: 0.7209\n",
      "Epoch 19/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5418 - accuracy: 0.7197 - val_loss: 0.5411 - val_accuracy: 0.7188\n",
      "Epoch 20/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5411 - accuracy: 0.7188 - val_loss: 0.5388 - val_accuracy: 0.7229\n",
      "Epoch 21/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5398 - accuracy: 0.7201 - val_loss: 0.5387 - val_accuracy: 0.7220\n",
      "Epoch 22/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5382 - accuracy: 0.7222 - val_loss: 0.5366 - val_accuracy: 0.7272\n",
      "Epoch 23/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5360 - accuracy: 0.7233 - val_loss: 0.5354 - val_accuracy: 0.7262\n",
      "Epoch 24/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5353 - accuracy: 0.7237 - val_loss: 0.5354 - val_accuracy: 0.7256\n",
      "Epoch 25/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5340 - accuracy: 0.7259 - val_loss: 0.5312 - val_accuracy: 0.7302\n",
      "Epoch 26/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5331 - accuracy: 0.7264 - val_loss: 0.5330 - val_accuracy: 0.7248\n",
      "Epoch 27/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5321 - accuracy: 0.7256 - val_loss: 0.5295 - val_accuracy: 0.7295\n",
      "Epoch 28/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5315 - accuracy: 0.7270 - val_loss: 0.5291 - val_accuracy: 0.7269\n",
      "Epoch 29/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5309 - accuracy: 0.7278 - val_loss: 0.5287 - val_accuracy: 0.7319\n",
      "Epoch 30/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5302 - accuracy: 0.7276 - val_loss: 0.5258 - val_accuracy: 0.7319\n",
      "Epoch 31/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5300 - accuracy: 0.7282 - val_loss: 0.5255 - val_accuracy: 0.7326\n",
      "Epoch 32/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5292 - accuracy: 0.7276 - val_loss: 0.5256 - val_accuracy: 0.7347\n",
      "Epoch 33/500\n",
      "92096/92096 [==============================] - 4s 41us/sample - loss: 0.5287 - accuracy: 0.7284 - val_loss: 0.5272 - val_accuracy: 0.7311\n",
      "Epoch 34/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5286 - accuracy: 0.7280 - val_loss: 0.5260 - val_accuracy: 0.7325\n",
      "Epoch 35/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5282 - accuracy: 0.7286 - val_loss: 0.5250 - val_accuracy: 0.7336\n",
      "Epoch 36/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5277 - accuracy: 0.7295 - val_loss: 0.5241 - val_accuracy: 0.7364\n",
      "Epoch 37/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5277 - accuracy: 0.7296 - val_loss: 0.5257 - val_accuracy: 0.7339\n",
      "Epoch 38/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5274 - accuracy: 0.7306 - val_loss: 0.5249 - val_accuracy: 0.7337\n",
      "Epoch 39/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5271 - accuracy: 0.7299 - val_loss: 0.5265 - val_accuracy: 0.7328\n",
      "Epoch 40/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5270 - accuracy: 0.7294 - val_loss: 0.5258 - val_accuracy: 0.7318\n",
      "Epoch 41/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5265 - accuracy: 0.7308 - val_loss: 0.5252 - val_accuracy: 0.7343\n",
      "Epoch 42/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5264 - accuracy: 0.7316 - val_loss: 0.5291 - val_accuracy: 0.7312\n",
      "Epoch 43/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5260 - accuracy: 0.7309 - val_loss: 0.5273 - val_accuracy: 0.7305\n",
      "Epoch 44/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5259 - accuracy: 0.7307 - val_loss: 0.5237 - val_accuracy: 0.7360\n",
      "Epoch 45/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5257 - accuracy: 0.7332 - val_loss: 0.5235 - val_accuracy: 0.7347\n",
      "Epoch 46/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5259 - accuracy: 0.7305 - val_loss: 0.5225 - val_accuracy: 0.7357\n",
      "Epoch 47/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5258 - accuracy: 0.7311 - val_loss: 0.5299 - val_accuracy: 0.7289\n",
      "Epoch 48/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5252 - accuracy: 0.7305 - val_loss: 0.5224 - val_accuracy: 0.7349\n",
      "Epoch 49/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5252 - accuracy: 0.7315 - val_loss: 0.5237 - val_accuracy: 0.7338\n",
      "Epoch 50/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5249 - accuracy: 0.7326 - val_loss: 0.5212 - val_accuracy: 0.7341\n",
      "Epoch 51/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5248 - accuracy: 0.7316 - val_loss: 0.5201 - val_accuracy: 0.7371\n",
      "Epoch 52/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5249 - accuracy: 0.7318 - val_loss: 0.5215 - val_accuracy: 0.7367\n",
      "Epoch 53/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5243 - accuracy: 0.7329 - val_loss: 0.5263 - val_accuracy: 0.7337\n",
      "Epoch 54/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5243 - accuracy: 0.7323 - val_loss: 0.5207 - val_accuracy: 0.7394\n",
      "Epoch 55/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5244 - accuracy: 0.7327 - val_loss: 0.5214 - val_accuracy: 0.7401\n",
      "Epoch 56/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5243 - accuracy: 0.7323 - val_loss: 0.5216 - val_accuracy: 0.7383\n",
      "Epoch 57/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5239 - accuracy: 0.7331 - val_loss: 0.5216 - val_accuracy: 0.7359\n",
      "Epoch 58/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5238 - accuracy: 0.7331 - val_loss: 0.5209 - val_accuracy: 0.7404\n",
      "Epoch 59/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5234 - accuracy: 0.7329 - val_loss: 0.5233 - val_accuracy: 0.7374\n",
      "Epoch 60/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5245 - accuracy: 0.7329 - val_loss: 0.5212 - val_accuracy: 0.7359\n",
      "Epoch 61/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5234 - accuracy: 0.7328 - val_loss: 0.5209 - val_accuracy: 0.7369\n",
      "Epoch 62/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5236 - accuracy: 0.7329 - val_loss: 0.5216 - val_accuracy: 0.7397\n",
      "Epoch 63/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5231 - accuracy: 0.7334 - val_loss: 0.5206 - val_accuracy: 0.7410\n",
      "Epoch 64/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5234 - accuracy: 0.7335 - val_loss: 0.5205 - val_accuracy: 0.7379\n",
      "Epoch 65/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5235 - accuracy: 0.7329 - val_loss: 0.5190 - val_accuracy: 0.7380\n",
      "Epoch 66/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5230 - accuracy: 0.7338 - val_loss: 0.5212 - val_accuracy: 0.7370\n",
      "Epoch 67/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5230 - accuracy: 0.7345 - val_loss: 0.5231 - val_accuracy: 0.7356\n",
      "Epoch 68/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5235 - accuracy: 0.7323 - val_loss: 0.5228 - val_accuracy: 0.7346\n",
      "Epoch 69/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5227 - accuracy: 0.7340 - val_loss: 0.5218 - val_accuracy: 0.7358\n",
      "Epoch 70/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5224 - accuracy: 0.7349 - val_loss: 0.5217 - val_accuracy: 0.7372\n",
      "Epoch 71/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5224 - accuracy: 0.7324 - val_loss: 0.5229 - val_accuracy: 0.7371\n",
      "Epoch 72/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5226 - accuracy: 0.7334 - val_loss: 0.5214 - val_accuracy: 0.7379\n",
      "Epoch 73/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5225 - accuracy: 0.7333 - val_loss: 0.5270 - val_accuracy: 0.7327\n",
      "Epoch 74/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5224 - accuracy: 0.7337 - val_loss: 0.5189 - val_accuracy: 0.7382\n",
      "Epoch 75/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5224 - accuracy: 0.7345 - val_loss: 0.5262 - val_accuracy: 0.7298\n",
      "Epoch 76/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5226 - accuracy: 0.7338 - val_loss: 0.5210 - val_accuracy: 0.7371\n",
      "Epoch 77/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5224 - accuracy: 0.7340 - val_loss: 0.5185 - val_accuracy: 0.7401\n",
      "Epoch 78/500\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.5222 - accuracy: 0.7353 - val_loss: 0.5223 - val_accuracy: 0.7371\n",
      "Epoch 79/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5223 - accuracy: 0.7345 - val_loss: 0.5201 - val_accuracy: 0.7380\n",
      "Epoch 80/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5220 - accuracy: 0.7340 - val_loss: 0.5176 - val_accuracy: 0.7406\n",
      "Epoch 81/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5222 - accuracy: 0.7350 - val_loss: 0.5197 - val_accuracy: 0.7397\n",
      "Epoch 82/500\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.5217 - accuracy: 0.7334 - val_loss: 0.5218 - val_accuracy: 0.7355\n",
      "Epoch 83/500\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.5219 - accuracy: 0.7345 - val_loss: 0.5179 - val_accuracy: 0.7414\n",
      "Epoch 84/500\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.5217 - accuracy: 0.7348 - val_loss: 0.5188 - val_accuracy: 0.7397\n",
      "Epoch 85/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5214 - accuracy: 0.7350 - val_loss: 0.5217 - val_accuracy: 0.7387\n",
      "Epoch 86/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5218 - accuracy: 0.7354 - val_loss: 0.5176 - val_accuracy: 0.7438\n",
      "Epoch 87/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5220 - accuracy: 0.7347 - val_loss: 0.5231 - val_accuracy: 0.7368\n",
      "Epoch 88/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5216 - accuracy: 0.7346 - val_loss: 0.5184 - val_accuracy: 0.7388\n",
      "Epoch 89/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5216 - accuracy: 0.7359 - val_loss: 0.5231 - val_accuracy: 0.7344\n",
      "Epoch 90/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5215 - accuracy: 0.7357 - val_loss: 0.5166 - val_accuracy: 0.7421\n",
      "Epoch 91/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5215 - accuracy: 0.7353 - val_loss: 0.5206 - val_accuracy: 0.7372\n",
      "Epoch 92/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5216 - accuracy: 0.7343 - val_loss: 0.5203 - val_accuracy: 0.7389\n",
      "Epoch 93/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5217 - accuracy: 0.7350 - val_loss: 0.5183 - val_accuracy: 0.7423\n",
      "Epoch 94/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5211 - accuracy: 0.7358 - val_loss: 0.5220 - val_accuracy: 0.7383\n",
      "Epoch 95/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5212 - accuracy: 0.7344 - val_loss: 0.5187 - val_accuracy: 0.7412\n",
      "Epoch 96/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5213 - accuracy: 0.7353 - val_loss: 0.5186 - val_accuracy: 0.7387\n",
      "Epoch 97/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5213 - accuracy: 0.7352 - val_loss: 0.5203 - val_accuracy: 0.7400\n",
      "Epoch 98/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5212 - accuracy: 0.7359 - val_loss: 0.5196 - val_accuracy: 0.7412\n",
      "Epoch 99/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5210 - accuracy: 0.7356 - val_loss: 0.5213 - val_accuracy: 0.7396\n",
      "Epoch 100/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5210 - accuracy: 0.7348 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 101/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5209 - accuracy: 0.7358 - val_loss: 0.5191 - val_accuracy: 0.7412\n",
      "Epoch 102/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5209 - accuracy: 0.7364 - val_loss: 0.5190 - val_accuracy: 0.7425\n",
      "Epoch 103/500\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.5209 - accuracy: 0.7363 - val_loss: 0.5223 - val_accuracy: 0.7348\n",
      "Epoch 104/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5209 - accuracy: 0.7358 - val_loss: 0.5174 - val_accuracy: 0.7383\n",
      "Epoch 105/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5205 - accuracy: 0.7351 - val_loss: 0.5164 - val_accuracy: 0.7442\n",
      "Epoch 106/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5204 - accuracy: 0.7353 - val_loss: 0.5167 - val_accuracy: 0.7429\n",
      "Epoch 107/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5206 - accuracy: 0.7362 - val_loss: 0.5233 - val_accuracy: 0.7365\n",
      "Epoch 108/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5206 - accuracy: 0.7349 - val_loss: 0.5188 - val_accuracy: 0.7410\n",
      "Epoch 109/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5207 - accuracy: 0.7354 - val_loss: 0.5171 - val_accuracy: 0.7419\n",
      "Epoch 110/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5205 - accuracy: 0.7352 - val_loss: 0.5170 - val_accuracy: 0.7416\n",
      "Epoch 111/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5201 - accuracy: 0.7356 - val_loss: 0.5195 - val_accuracy: 0.7400\n",
      "Epoch 112/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5204 - accuracy: 0.7349 - val_loss: 0.5198 - val_accuracy: 0.7371\n",
      "Epoch 113/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5201 - accuracy: 0.7363 - val_loss: 0.5238 - val_accuracy: 0.7379\n",
      "Epoch 114/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5205 - accuracy: 0.7359 - val_loss: 0.5189 - val_accuracy: 0.7404\n",
      "Epoch 115/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5197 - accuracy: 0.7361 - val_loss: 0.5198 - val_accuracy: 0.7389\n",
      "Epoch 116/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5200 - accuracy: 0.7369 - val_loss: 0.5177 - val_accuracy: 0.7391\n",
      "Epoch 117/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5200 - accuracy: 0.7354 - val_loss: 0.5193 - val_accuracy: 0.7407\n",
      "Epoch 118/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5202 - accuracy: 0.7368 - val_loss: 0.5179 - val_accuracy: 0.7434\n",
      "Epoch 119/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5201 - accuracy: 0.7357 - val_loss: 0.5210 - val_accuracy: 0.7363\n",
      "Epoch 120/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5202 - accuracy: 0.7351 - val_loss: 0.5207 - val_accuracy: 0.7375\n",
      "Epoch 121/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5200 - accuracy: 0.7368 - val_loss: 0.5190 - val_accuracy: 0.7417\n",
      "Epoch 122/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5202 - accuracy: 0.7362 - val_loss: 0.5163 - val_accuracy: 0.7416\n",
      "Epoch 123/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5195 - accuracy: 0.7362 - val_loss: 0.5194 - val_accuracy: 0.7427\n",
      "Epoch 124/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5199 - accuracy: 0.7370 - val_loss: 0.5175 - val_accuracy: 0.7427\n",
      "Epoch 125/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5195 - accuracy: 0.7364 - val_loss: 0.5201 - val_accuracy: 0.7403\n",
      "Epoch 126/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5195 - accuracy: 0.7362 - val_loss: 0.5159 - val_accuracy: 0.7412\n",
      "Epoch 127/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5196 - accuracy: 0.7373 - val_loss: 0.5207 - val_accuracy: 0.7394\n",
      "Epoch 128/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5198 - accuracy: 0.7359 - val_loss: 0.5198 - val_accuracy: 0.7390\n",
      "Epoch 129/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5197 - accuracy: 0.7352 - val_loss: 0.5216 - val_accuracy: 0.7380\n",
      "Epoch 130/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5197 - accuracy: 0.7369 - val_loss: 0.5164 - val_accuracy: 0.7447\n",
      "Epoch 131/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5195 - accuracy: 0.7371 - val_loss: 0.5181 - val_accuracy: 0.7414\n",
      "Epoch 132/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5193 - accuracy: 0.7365 - val_loss: 0.5186 - val_accuracy: 0.7421\n",
      "Epoch 133/500\n",
      "92096/92096 [==============================] - 3s 38us/sample - loss: 0.5193 - accuracy: 0.7365 - val_loss: 0.5212 - val_accuracy: 0.7417\n",
      "Epoch 134/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5194 - accuracy: 0.7360 - val_loss: 0.5197 - val_accuracy: 0.7401\n",
      "Epoch 135/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5195 - accuracy: 0.7363 - val_loss: 0.5182 - val_accuracy: 0.7422\n",
      "Epoch 136/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5192 - accuracy: 0.7368 - val_loss: 0.5189 - val_accuracy: 0.7408\n",
      "Epoch 137/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5195 - accuracy: 0.7363 - val_loss: 0.5164 - val_accuracy: 0.7417\n",
      "Epoch 138/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5197 - accuracy: 0.7364 - val_loss: 0.5165 - val_accuracy: 0.7450\n",
      "Epoch 139/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5197 - accuracy: 0.7359 - val_loss: 0.5162 - val_accuracy: 0.7414\n",
      "Epoch 140/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5194 - accuracy: 0.7374 - val_loss: 0.5162 - val_accuracy: 0.7414\n",
      "Epoch 141/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5193 - accuracy: 0.7375 - val_loss: 0.5203 - val_accuracy: 0.7403\n",
      "Epoch 142/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5195 - accuracy: 0.7359 - val_loss: 0.5179 - val_accuracy: 0.7381\n",
      "Epoch 143/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5197 - accuracy: 0.7369 - val_loss: 0.5199 - val_accuracy: 0.7349\n",
      "Epoch 144/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5193 - accuracy: 0.7364 - val_loss: 0.5177 - val_accuracy: 0.7414\n",
      "Epoch 145/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5193 - accuracy: 0.7378 - val_loss: 0.5187 - val_accuracy: 0.7431\n",
      "Epoch 146/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5191 - accuracy: 0.7370 - val_loss: 0.5213 - val_accuracy: 0.7415\n",
      "Epoch 147/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5192 - accuracy: 0.7369 - val_loss: 0.5169 - val_accuracy: 0.7428\n",
      "Epoch 148/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5191 - accuracy: 0.7369 - val_loss: 0.5158 - val_accuracy: 0.7435\n",
      "Epoch 149/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5192 - accuracy: 0.7363 - val_loss: 0.5169 - val_accuracy: 0.7418\n",
      "Epoch 150/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5188 - accuracy: 0.7369 - val_loss: 0.5161 - val_accuracy: 0.7400\n",
      "Epoch 151/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5192 - accuracy: 0.7368 - val_loss: 0.5221 - val_accuracy: 0.7388\n",
      "Epoch 152/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5194 - accuracy: 0.7362 - val_loss: 0.5177 - val_accuracy: 0.7434\n",
      "Epoch 153/500\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.5191 - accuracy: 0.7362 - val_loss: 0.5175 - val_accuracy: 0.7387\n",
      "Epoch 154/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5194 - accuracy: 0.7365 - val_loss: 0.5168 - val_accuracy: 0.7415\n",
      "Epoch 155/500\n",
      "92096/92096 [==============================] - 4s 42us/sample - loss: 0.5190 - accuracy: 0.7373 - val_loss: 0.5178 - val_accuracy: 0.7401\n",
      "Epoch 156/500\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.5190 - accuracy: 0.7365 - val_loss: 0.5200 - val_accuracy: 0.7368\n",
      "Epoch 157/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5188 - accuracy: 0.7377 - val_loss: 0.5158 - val_accuracy: 0.7417\n",
      "Epoch 158/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5192 - accuracy: 0.7372 - val_loss: 0.5159 - val_accuracy: 0.7410\n",
      "Epoch 159/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5188 - accuracy: 0.7377 - val_loss: 0.5166 - val_accuracy: 0.7414\n",
      "Epoch 160/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5193 - accuracy: 0.7371 - val_loss: 0.5184 - val_accuracy: 0.7389\n",
      "Epoch 161/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5192 - accuracy: 0.7371 - val_loss: 0.5190 - val_accuracy: 0.7397\n",
      "Epoch 162/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5185 - accuracy: 0.7373 - val_loss: 0.5182 - val_accuracy: 0.7379\n",
      "Epoch 163/500\n",
      "92096/92096 [==============================] - 4s 39us/sample - loss: 0.5190 - accuracy: 0.7368 - val_loss: 0.5159 - val_accuracy: 0.7424\n",
      "Epoch 164/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5190 - accuracy: 0.7368 - val_loss: 0.5205 - val_accuracy: 0.7406\n",
      "Epoch 165/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5185 - accuracy: 0.7361 - val_loss: 0.5218 - val_accuracy: 0.7393\n",
      "Epoch 166/500\n",
      "92096/92096 [==============================] - 4s 39us/sample - loss: 0.5192 - accuracy: 0.7366 - val_loss: 0.5169 - val_accuracy: 0.7417\n",
      "Epoch 167/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5191 - accuracy: 0.7366 - val_loss: 0.5145 - val_accuracy: 0.7396\n",
      "Epoch 168/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5188 - accuracy: 0.7377 - val_loss: 0.5158 - val_accuracy: 0.7432\n",
      "Epoch 169/500\n",
      "92096/92096 [==============================] - 4s 41us/sample - loss: 0.5187 - accuracy: 0.7371 - val_loss: 0.5224 - val_accuracy: 0.7377\n",
      "Epoch 170/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5189 - accuracy: 0.7368 - val_loss: 0.5146 - val_accuracy: 0.7431\n",
      "Epoch 171/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5189 - accuracy: 0.7373 - val_loss: 0.5165 - val_accuracy: 0.7411\n",
      "Epoch 172/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5188 - accuracy: 0.7371 - val_loss: 0.5165 - val_accuracy: 0.7411\n",
      "Epoch 173/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5188 - accuracy: 0.7366 - val_loss: 0.5151 - val_accuracy: 0.7458\n",
      "Epoch 174/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5186 - accuracy: 0.7375 - val_loss: 0.5170 - val_accuracy: 0.7409\n",
      "Epoch 175/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5189 - accuracy: 0.7372 - val_loss: 0.5171 - val_accuracy: 0.7424\n",
      "Epoch 176/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5184 - accuracy: 0.7382 - val_loss: 0.5186 - val_accuracy: 0.7394\n",
      "Epoch 177/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5186 - accuracy: 0.7365 - val_loss: 0.5176 - val_accuracy: 0.7401\n",
      "Epoch 178/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5183 - accuracy: 0.7383 - val_loss: 0.5174 - val_accuracy: 0.7378\n",
      "Epoch 179/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5183 - accuracy: 0.7375 - val_loss: 0.5161 - val_accuracy: 0.7407\n",
      "Epoch 180/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5182 - accuracy: 0.7377 - val_loss: 0.5177 - val_accuracy: 0.7427\n",
      "Epoch 181/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5188 - accuracy: 0.7380 - val_loss: 0.5155 - val_accuracy: 0.7417\n",
      "Epoch 182/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5189 - accuracy: 0.7383 - val_loss: 0.5153 - val_accuracy: 0.7412\n",
      "Epoch 183/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5188 - accuracy: 0.7371 - val_loss: 0.5134 - val_accuracy: 0.7455\n",
      "Epoch 184/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5183 - accuracy: 0.7365 - val_loss: 0.5174 - val_accuracy: 0.7397\n",
      "Epoch 185/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5187 - accuracy: 0.7365 - val_loss: 0.5139 - val_accuracy: 0.7423\n",
      "Epoch 186/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5186 - accuracy: 0.7378 - val_loss: 0.5150 - val_accuracy: 0.7433\n",
      "Epoch 187/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5187 - accuracy: 0.7378 - val_loss: 0.5159 - val_accuracy: 0.7416\n",
      "Epoch 188/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5184 - accuracy: 0.7375 - val_loss: 0.5163 - val_accuracy: 0.7454\n",
      "Epoch 189/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5186 - accuracy: 0.7389 - val_loss: 0.5156 - val_accuracy: 0.7416\n",
      "Epoch 190/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5186 - accuracy: 0.7373 - val_loss: 0.5162 - val_accuracy: 0.7421\n",
      "Epoch 191/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5184 - accuracy: 0.7376 - val_loss: 0.5160 - val_accuracy: 0.7430\n",
      "Epoch 192/500\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.5182 - accuracy: 0.7381 - val_loss: 0.5210 - val_accuracy: 0.7374\n",
      "Epoch 193/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5183 - accuracy: 0.7376 - val_loss: 0.5159 - val_accuracy: 0.7431\n",
      "Epoch 194/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5184 - accuracy: 0.7381 - val_loss: 0.5179 - val_accuracy: 0.7371\n",
      "Epoch 195/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5182 - accuracy: 0.7384 - val_loss: 0.5268 - val_accuracy: 0.7345\n",
      "Epoch 196/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5189 - accuracy: 0.7367 - val_loss: 0.5181 - val_accuracy: 0.7405\n",
      "Epoch 197/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5183 - accuracy: 0.7368 - val_loss: 0.5152 - val_accuracy: 0.7434\n",
      "Epoch 198/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5184 - accuracy: 0.7376 - val_loss: 0.5144 - val_accuracy: 0.7443\n",
      "Epoch 199/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5181 - accuracy: 0.7386 - val_loss: 0.5177 - val_accuracy: 0.7399\n",
      "Epoch 200/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5183 - accuracy: 0.7381 - val_loss: 0.5186 - val_accuracy: 0.7417\n",
      "Epoch 201/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5184 - accuracy: 0.7376 - val_loss: 0.5163 - val_accuracy: 0.7414\n",
      "Epoch 202/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5184 - accuracy: 0.7380 - val_loss: 0.5163 - val_accuracy: 0.7436\n",
      "Epoch 203/500\n",
      "92096/92096 [==============================] - 4s 41us/sample - loss: 0.5184 - accuracy: 0.7378 - val_loss: 0.5146 - val_accuracy: 0.7423\n",
      "Epoch 204/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5178 - accuracy: 0.7381 - val_loss: 0.5194 - val_accuracy: 0.7394\n",
      "Epoch 205/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5180 - accuracy: 0.7387 - val_loss: 0.5154 - val_accuracy: 0.7436\n",
      "Epoch 206/500\n",
      "92096/92096 [==============================] - 5s 58us/sample - loss: 0.5182 - accuracy: 0.7374 - val_loss: 0.5167 - val_accuracy: 0.7385\n",
      "Epoch 207/500\n",
      "92096/92096 [==============================] - 4s 39us/sample - loss: 0.5182 - accuracy: 0.7380 - val_loss: 0.5162 - val_accuracy: 0.7417\n",
      "Epoch 208/500\n",
      "92096/92096 [==============================] - 4s 40us/sample - loss: 0.5182 - accuracy: 0.7382 - val_loss: 0.5161 - val_accuracy: 0.7418\n",
      "Epoch 209/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5187 - accuracy: 0.7371 - val_loss: 0.5180 - val_accuracy: 0.7380\n",
      "Epoch 210/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5184 - accuracy: 0.7367 - val_loss: 0.5147 - val_accuracy: 0.7425\n",
      "Epoch 211/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5182 - accuracy: 0.7363 - val_loss: 0.5175 - val_accuracy: 0.7400\n",
      "Epoch 212/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5184 - accuracy: 0.7375 - val_loss: 0.5188 - val_accuracy: 0.7367\n",
      "Epoch 213/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5182 - accuracy: 0.7385 - val_loss: 0.5195 - val_accuracy: 0.7364\n",
      "Epoch 214/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5186 - accuracy: 0.7377 - val_loss: 0.5139 - val_accuracy: 0.7442\n",
      "Epoch 215/500\n",
      "92096/92096 [==============================] - 4s 42us/sample - loss: 0.5181 - accuracy: 0.7370 - val_loss: 0.5164 - val_accuracy: 0.7414\n",
      "Epoch 216/500\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.5179 - accuracy: 0.7376 - val_loss: 0.5178 - val_accuracy: 0.7444\n",
      "Epoch 217/500\n",
      "92096/92096 [==============================] - 3s 37us/sample - loss: 0.5176 - accuracy: 0.7377 - val_loss: 0.5145 - val_accuracy: 0.7447\n",
      "Epoch 218/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5179 - accuracy: 0.7378 - val_loss: 0.5157 - val_accuracy: 0.7436\n",
      "Epoch 219/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5179 - accuracy: 0.7374 - val_loss: 0.5219 - val_accuracy: 0.7352\n",
      "Epoch 220/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5181 - accuracy: 0.7367 - val_loss: 0.5179 - val_accuracy: 0.7391\n",
      "Epoch 221/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5176 - accuracy: 0.7383 - val_loss: 0.5175 - val_accuracy: 0.7375\n",
      "Epoch 222/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5180 - accuracy: 0.7381 - val_loss: 0.5147 - val_accuracy: 0.7432\n",
      "Epoch 223/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5180 - accuracy: 0.7372 - val_loss: 0.5163 - val_accuracy: 0.7410\n",
      "Epoch 224/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5180 - accuracy: 0.7383 - val_loss: 0.5184 - val_accuracy: 0.7421\n",
      "Epoch 225/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5175 - accuracy: 0.7381 - val_loss: 0.5164 - val_accuracy: 0.7423\n",
      "Epoch 226/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5181 - accuracy: 0.7376 - val_loss: 0.5150 - val_accuracy: 0.7431\n",
      "Epoch 227/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5177 - accuracy: 0.7377 - val_loss: 0.5188 - val_accuracy: 0.7406\n",
      "Epoch 228/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5183 - accuracy: 0.7374 - val_loss: 0.5128 - val_accuracy: 0.7457\n",
      "Epoch 229/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5180 - accuracy: 0.7380 - val_loss: 0.5135 - val_accuracy: 0.7434\n",
      "Epoch 230/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5175 - accuracy: 0.7373 - val_loss: 0.5140 - val_accuracy: 0.7451\n",
      "Epoch 231/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5179 - accuracy: 0.7384 - val_loss: 0.5173 - val_accuracy: 0.7397\n",
      "Epoch 232/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5179 - accuracy: 0.7385 - val_loss: 0.5150 - val_accuracy: 0.7436\n",
      "Epoch 233/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5177 - accuracy: 0.7387 - val_loss: 0.5145 - val_accuracy: 0.7436\n",
      "Epoch 234/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5177 - accuracy: 0.7374 - val_loss: 0.5179 - val_accuracy: 0.7407\n",
      "Epoch 235/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5177 - accuracy: 0.7381 - val_loss: 0.5183 - val_accuracy: 0.7420\n",
      "Epoch 236/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5183 - accuracy: 0.7391 - val_loss: 0.5152 - val_accuracy: 0.7440\n",
      "Epoch 237/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5176 - accuracy: 0.7390 - val_loss: 0.5191 - val_accuracy: 0.7376\n",
      "Epoch 238/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5177 - accuracy: 0.7386 - val_loss: 0.5181 - val_accuracy: 0.7371\n",
      "Epoch 239/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5179 - accuracy: 0.7386 - val_loss: 0.5149 - val_accuracy: 0.7422\n",
      "Epoch 240/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5175 - accuracy: 0.7388 - val_loss: 0.5156 - val_accuracy: 0.7435\n",
      "Epoch 241/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5173 - accuracy: 0.7385 - val_loss: 0.5182 - val_accuracy: 0.7412\n",
      "Epoch 242/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5180 - accuracy: 0.7392 - val_loss: 0.5160 - val_accuracy: 0.7401\n",
      "Epoch 243/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5179 - accuracy: 0.7395 - val_loss: 0.5143 - val_accuracy: 0.7434\n",
      "Epoch 244/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5174 - accuracy: 0.7388 - val_loss: 0.5206 - val_accuracy: 0.7385\n",
      "Epoch 245/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5181 - accuracy: 0.7384 - val_loss: 0.5169 - val_accuracy: 0.7406\n",
      "Epoch 246/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5175 - accuracy: 0.7389 - val_loss: 0.5168 - val_accuracy: 0.7423\n",
      "Epoch 247/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5176 - accuracy: 0.7383 - val_loss: 0.5244 - val_accuracy: 0.7315\n",
      "Epoch 248/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5179 - accuracy: 0.7391 - val_loss: 0.5151 - val_accuracy: 0.7434\n",
      "Epoch 249/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5171 - accuracy: 0.7394 - val_loss: 0.5148 - val_accuracy: 0.7463\n",
      "Epoch 250/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5179 - accuracy: 0.7394 - val_loss: 0.5143 - val_accuracy: 0.7444\n",
      "Epoch 251/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5170 - accuracy: 0.7407 - val_loss: 0.5166 - val_accuracy: 0.7401\n",
      "Epoch 252/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5178 - accuracy: 0.7399 - val_loss: 0.5161 - val_accuracy: 0.7419\n",
      "Epoch 253/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5175 - accuracy: 0.7390 - val_loss: 0.5165 - val_accuracy: 0.7459\n",
      "Epoch 254/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5177 - accuracy: 0.7393 - val_loss: 0.5212 - val_accuracy: 0.7369\n",
      "Epoch 255/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5169 - accuracy: 0.7392 - val_loss: 0.5158 - val_accuracy: 0.7432\n",
      "Epoch 256/500\n",
      "92096/92096 [==============================] - 4s 41us/sample - loss: 0.5172 - accuracy: 0.7395 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 257/500\n",
      "92096/92096 [==============================] - 4s 41us/sample - loss: 0.5171 - accuracy: 0.7395 - val_loss: 0.5156 - val_accuracy: 0.7418\n",
      "Epoch 258/500\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.5173 - accuracy: 0.7392 - val_loss: 0.5151 - val_accuracy: 0.7404\n",
      "Epoch 259/500\n",
      "92096/92096 [==============================] - 4s 38us/sample - loss: 0.5176 - accuracy: 0.7394 - val_loss: 0.5138 - val_accuracy: 0.7437\n",
      "Epoch 260/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5171 - accuracy: 0.7401 - val_loss: 0.5166 - val_accuracy: 0.7412\n",
      "Epoch 261/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5171 - accuracy: 0.7396 - val_loss: 0.5187 - val_accuracy: 0.7383\n",
      "Epoch 262/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5173 - accuracy: 0.7397 - val_loss: 0.5165 - val_accuracy: 0.7426\n",
      "Epoch 263/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5172 - accuracy: 0.7394 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 264/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5171 - accuracy: 0.7394 - val_loss: 0.5152 - val_accuracy: 0.7434\n",
      "Epoch 265/500\n",
      "92096/92096 [==============================] - 3s 37us/sample - loss: 0.5172 - accuracy: 0.7395 - val_loss: 0.5155 - val_accuracy: 0.7438\n",
      "Epoch 266/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5171 - accuracy: 0.7392 - val_loss: 0.5150 - val_accuracy: 0.7436\n",
      "Epoch 267/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5168 - accuracy: 0.7401 - val_loss: 0.5161 - val_accuracy: 0.7434\n",
      "Epoch 268/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5173 - accuracy: 0.7386 - val_loss: 0.5178 - val_accuracy: 0.7417\n",
      "Epoch 269/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5170 - accuracy: 0.7395 - val_loss: 0.5180 - val_accuracy: 0.7400\n",
      "Epoch 270/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5170 - accuracy: 0.7388 - val_loss: 0.5147 - val_accuracy: 0.7431\n",
      "Epoch 271/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5173 - accuracy: 0.7407 - val_loss: 0.5176 - val_accuracy: 0.7397\n",
      "Epoch 272/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5170 - accuracy: 0.7402 - val_loss: 0.5165 - val_accuracy: 0.7403\n",
      "Epoch 273/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5169 - accuracy: 0.7388 - val_loss: 0.5178 - val_accuracy: 0.7406\n",
      "Epoch 274/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5173 - accuracy: 0.7404 - val_loss: 0.5148 - val_accuracy: 0.7436\n",
      "Epoch 275/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5170 - accuracy: 0.7388 - val_loss: 0.5168 - val_accuracy: 0.7412\n",
      "Epoch 276/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5169 - accuracy: 0.7394 - val_loss: 0.5197 - val_accuracy: 0.7391\n",
      "Epoch 277/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5173 - accuracy: 0.7390 - val_loss: 0.5202 - val_accuracy: 0.7374\n",
      "Epoch 278/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5168 - accuracy: 0.7408 - val_loss: 0.5192 - val_accuracy: 0.7427\n",
      "Epoch 279/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5170 - accuracy: 0.7395 - val_loss: 0.5180 - val_accuracy: 0.7422\n",
      "Epoch 280/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5170 - accuracy: 0.7400 - val_loss: 0.5124 - val_accuracy: 0.7466\n",
      "Epoch 281/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5169 - accuracy: 0.7394 - val_loss: 0.5146 - val_accuracy: 0.7442\n",
      "Epoch 282/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5169 - accuracy: 0.7410 - val_loss: 0.5226 - val_accuracy: 0.7324\n",
      "Epoch 283/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5171 - accuracy: 0.7389 - val_loss: 0.5138 - val_accuracy: 0.7437\n",
      "Epoch 284/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5170 - accuracy: 0.7400 - val_loss: 0.5145 - val_accuracy: 0.7444\n",
      "Epoch 285/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5171 - accuracy: 0.7393 - val_loss: 0.5164 - val_accuracy: 0.7399\n",
      "Epoch 286/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5167 - accuracy: 0.7400 - val_loss: 0.5158 - val_accuracy: 0.7415\n",
      "Epoch 287/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5172 - accuracy: 0.7392 - val_loss: 0.5127 - val_accuracy: 0.7461\n",
      "Epoch 288/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5169 - accuracy: 0.7399 - val_loss: 0.5136 - val_accuracy: 0.7433\n",
      "Epoch 289/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5167 - accuracy: 0.7402 - val_loss: 0.5159 - val_accuracy: 0.7412\n",
      "Epoch 290/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5169 - accuracy: 0.7401 - val_loss: 0.5157 - val_accuracy: 0.7427\n",
      "Epoch 291/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5166 - accuracy: 0.7406 - val_loss: 0.5143 - val_accuracy: 0.7429\n",
      "Epoch 292/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5167 - accuracy: 0.7396 - val_loss: 0.5149 - val_accuracy: 0.7464\n",
      "Epoch 293/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5169 - accuracy: 0.7404 - val_loss: 0.5132 - val_accuracy: 0.7447\n",
      "Epoch 294/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5169 - accuracy: 0.7399 - val_loss: 0.5133 - val_accuracy: 0.7455\n",
      "Epoch 295/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5166 - accuracy: 0.7403 - val_loss: 0.5152 - val_accuracy: 0.7406\n",
      "Epoch 296/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5170 - accuracy: 0.7394 - val_loss: 0.5142 - val_accuracy: 0.7441\n",
      "Epoch 297/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5168 - accuracy: 0.7387 - val_loss: 0.5160 - val_accuracy: 0.7420\n",
      "Epoch 298/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5167 - accuracy: 0.7393 - val_loss: 0.5158 - val_accuracy: 0.7445\n",
      "Epoch 299/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5167 - accuracy: 0.7399 - val_loss: 0.5155 - val_accuracy: 0.7421\n",
      "Epoch 300/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5170 - accuracy: 0.7396 - val_loss: 0.5146 - val_accuracy: 0.7456\n",
      "Epoch 301/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5168 - accuracy: 0.7399 - val_loss: 0.5160 - val_accuracy: 0.7410\n",
      "Epoch 302/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5174 - accuracy: 0.7395 - val_loss: 0.5167 - val_accuracy: 0.7386\n",
      "Epoch 303/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5169 - accuracy: 0.7387 - val_loss: 0.5133 - val_accuracy: 0.7472\n",
      "Epoch 304/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5166 - accuracy: 0.7394 - val_loss: 0.5196 - val_accuracy: 0.7382\n",
      "Epoch 305/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5163 - accuracy: 0.7391 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 306/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5170 - accuracy: 0.7400 - val_loss: 0.5131 - val_accuracy: 0.7457\n",
      "Epoch 307/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5164 - accuracy: 0.7400 - val_loss: 0.5153 - val_accuracy: 0.7468\n",
      "Epoch 308/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5169 - accuracy: 0.7399 - val_loss: 0.5145 - val_accuracy: 0.7447\n",
      "Epoch 309/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5166 - accuracy: 0.7396 - val_loss: 0.5141 - val_accuracy: 0.7459\n",
      "Epoch 310/500\n",
      "92096/92096 [==============================] - 3s 37us/sample - loss: 0.5165 - accuracy: 0.7397 - val_loss: 0.5160 - val_accuracy: 0.7421\n",
      "Epoch 311/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5165 - accuracy: 0.7399 - val_loss: 0.5166 - val_accuracy: 0.7423\n",
      "Epoch 312/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5166 - accuracy: 0.7403 - val_loss: 0.5177 - val_accuracy: 0.7421\n",
      "Epoch 313/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5165 - accuracy: 0.7393 - val_loss: 0.5155 - val_accuracy: 0.7449\n",
      "Epoch 314/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5163 - accuracy: 0.7409 - val_loss: 0.5148 - val_accuracy: 0.7469\n",
      "Epoch 315/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5167 - accuracy: 0.7406 - val_loss: 0.5175 - val_accuracy: 0.7412\n",
      "Epoch 316/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5164 - accuracy: 0.7406 - val_loss: 0.5137 - val_accuracy: 0.7443\n",
      "Epoch 317/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5165 - accuracy: 0.7398 - val_loss: 0.5179 - val_accuracy: 0.7401\n",
      "Epoch 318/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5168 - accuracy: 0.7407 - val_loss: 0.5143 - val_accuracy: 0.7427\n",
      "Epoch 319/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5161 - accuracy: 0.7395 - val_loss: 0.5190 - val_accuracy: 0.7404\n",
      "Epoch 320/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5165 - accuracy: 0.7397 - val_loss: 0.5164 - val_accuracy: 0.7427\n",
      "Epoch 321/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5163 - accuracy: 0.7401 - val_loss: 0.5154 - val_accuracy: 0.7438\n",
      "Epoch 322/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5161 - accuracy: 0.7406 - val_loss: 0.5176 - val_accuracy: 0.7392\n",
      "Epoch 323/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5162 - accuracy: 0.7401 - val_loss: 0.5147 - val_accuracy: 0.7429\n",
      "Epoch 324/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5161 - accuracy: 0.7405 - val_loss: 0.5217 - val_accuracy: 0.7345\n",
      "Epoch 325/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5161 - accuracy: 0.7406 - val_loss: 0.5153 - val_accuracy: 0.7416\n",
      "Epoch 326/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5163 - accuracy: 0.7396 - val_loss: 0.5143 - val_accuracy: 0.7450\n",
      "Epoch 327/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5161 - accuracy: 0.7409 - val_loss: 0.5154 - val_accuracy: 0.7418\n",
      "Epoch 328/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5167 - accuracy: 0.7404 - val_loss: 0.5156 - val_accuracy: 0.7451\n",
      "Epoch 329/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5157 - accuracy: 0.7414 - val_loss: 0.5151 - val_accuracy: 0.7465\n",
      "Epoch 330/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5163 - accuracy: 0.7406 - val_loss: 0.5146 - val_accuracy: 0.7445\n",
      "Epoch 331/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5160 - accuracy: 0.7402 - val_loss: 0.5196 - val_accuracy: 0.7394\n",
      "Epoch 332/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5158 - accuracy: 0.7406 - val_loss: 0.5204 - val_accuracy: 0.7368\n",
      "Epoch 333/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5164 - accuracy: 0.7409 - val_loss: 0.5162 - val_accuracy: 0.7423\n",
      "Epoch 334/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5161 - accuracy: 0.7403 - val_loss: 0.5170 - val_accuracy: 0.7403\n",
      "Epoch 335/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5159 - accuracy: 0.7393 - val_loss: 0.5169 - val_accuracy: 0.7440\n",
      "Epoch 336/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5157 - accuracy: 0.7413 - val_loss: 0.5144 - val_accuracy: 0.7424\n",
      "Epoch 337/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5165 - accuracy: 0.7410 - val_loss: 0.5170 - val_accuracy: 0.7419\n",
      "Epoch 338/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5160 - accuracy: 0.7408 - val_loss: 0.5158 - val_accuracy: 0.7420\n",
      "Epoch 339/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5162 - accuracy: 0.7402 - val_loss: 0.5183 - val_accuracy: 0.7421\n",
      "Epoch 340/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5158 - accuracy: 0.7410 - val_loss: 0.5153 - val_accuracy: 0.7414\n",
      "Epoch 341/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5159 - accuracy: 0.7402 - val_loss: 0.5136 - val_accuracy: 0.7438\n",
      "Epoch 342/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5160 - accuracy: 0.7410 - val_loss: 0.5137 - val_accuracy: 0.7464\n",
      "Epoch 343/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5160 - accuracy: 0.7401 - val_loss: 0.5137 - val_accuracy: 0.7450\n",
      "Epoch 344/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5159 - accuracy: 0.7407 - val_loss: 0.5153 - val_accuracy: 0.7454\n",
      "Epoch 345/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5158 - accuracy: 0.7411 - val_loss: 0.5162 - val_accuracy: 0.7402\n",
      "Epoch 346/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5160 - accuracy: 0.7408 - val_loss: 0.5146 - val_accuracy: 0.7453\n",
      "Epoch 347/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5161 - accuracy: 0.7406 - val_loss: 0.5150 - val_accuracy: 0.7449\n",
      "Epoch 348/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5158 - accuracy: 0.7412 - val_loss: 0.5177 - val_accuracy: 0.7380\n",
      "Epoch 349/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5161 - accuracy: 0.7404 - val_loss: 0.5135 - val_accuracy: 0.7462\n",
      "Epoch 350/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5157 - accuracy: 0.7406 - val_loss: 0.5136 - val_accuracy: 0.7445\n",
      "Epoch 351/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5156 - accuracy: 0.7412 - val_loss: 0.5172 - val_accuracy: 0.7428\n",
      "Epoch 352/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5161 - accuracy: 0.7412 - val_loss: 0.5157 - val_accuracy: 0.7440\n",
      "Epoch 353/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5155 - accuracy: 0.7404 - val_loss: 0.5152 - val_accuracy: 0.7446\n",
      "Epoch 354/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5157 - accuracy: 0.7409 - val_loss: 0.5140 - val_accuracy: 0.7453\n",
      "Epoch 355/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5157 - accuracy: 0.7409 - val_loss: 0.5129 - val_accuracy: 0.7456\n",
      "Epoch 356/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5160 - accuracy: 0.7409 - val_loss: 0.5130 - val_accuracy: 0.7455\n",
      "Epoch 357/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5159 - accuracy: 0.7408 - val_loss: 0.5194 - val_accuracy: 0.7424\n",
      "Epoch 358/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5159 - accuracy: 0.7409 - val_loss: 0.5131 - val_accuracy: 0.7451\n",
      "Epoch 359/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5157 - accuracy: 0.7403 - val_loss: 0.5135 - val_accuracy: 0.7455\n",
      "Epoch 360/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5157 - accuracy: 0.7409 - val_loss: 0.5154 - val_accuracy: 0.7427\n",
      "Epoch 361/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5158 - accuracy: 0.7411 - val_loss: 0.5201 - val_accuracy: 0.7398\n",
      "Epoch 362/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5157 - accuracy: 0.7414 - val_loss: 0.5177 - val_accuracy: 0.7404\n",
      "Epoch 363/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5156 - accuracy: 0.7412 - val_loss: 0.5165 - val_accuracy: 0.7437\n",
      "Epoch 364/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5158 - accuracy: 0.7414 - val_loss: 0.5144 - val_accuracy: 0.7457\n",
      "Epoch 365/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5158 - accuracy: 0.7407 - val_loss: 0.5137 - val_accuracy: 0.7440\n",
      "Epoch 366/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5162 - accuracy: 0.7397 - val_loss: 0.5136 - val_accuracy: 0.7450\n",
      "Epoch 367/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5159 - accuracy: 0.7403 - val_loss: 0.5147 - val_accuracy: 0.7450\n",
      "Epoch 368/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5156 - accuracy: 0.7413 - val_loss: 0.5161 - val_accuracy: 0.7434\n",
      "Epoch 369/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5158 - accuracy: 0.7394 - val_loss: 0.5128 - val_accuracy: 0.7475\n",
      "Epoch 370/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5158 - accuracy: 0.7401 - val_loss: 0.5142 - val_accuracy: 0.7440\n",
      "Epoch 371/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5158 - accuracy: 0.7417 - val_loss: 0.5208 - val_accuracy: 0.7397\n",
      "Epoch 372/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5154 - accuracy: 0.7408 - val_loss: 0.5135 - val_accuracy: 0.7453\n",
      "Epoch 373/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5154 - accuracy: 0.7409 - val_loss: 0.5156 - val_accuracy: 0.7437\n",
      "Epoch 374/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5154 - accuracy: 0.7413 - val_loss: 0.5202 - val_accuracy: 0.7397\n",
      "Epoch 375/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5158 - accuracy: 0.7395 - val_loss: 0.5153 - val_accuracy: 0.7442\n",
      "Epoch 376/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5158 - accuracy: 0.7412 - val_loss: 0.5221 - val_accuracy: 0.7394\n",
      "Epoch 377/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5155 - accuracy: 0.7408 - val_loss: 0.5151 - val_accuracy: 0.7426\n",
      "Epoch 378/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5155 - accuracy: 0.7406 - val_loss: 0.5149 - val_accuracy: 0.7439\n",
      "Epoch 379/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5157 - accuracy: 0.7407 - val_loss: 0.5147 - val_accuracy: 0.7429\n",
      "Epoch 380/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5154 - accuracy: 0.7410 - val_loss: 0.5177 - val_accuracy: 0.7419\n",
      "Epoch 381/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5158 - accuracy: 0.7397 - val_loss: 0.5159 - val_accuracy: 0.7437\n",
      "Epoch 382/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5157 - accuracy: 0.7412 - val_loss: 0.5150 - val_accuracy: 0.7415\n",
      "Epoch 383/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5155 - accuracy: 0.7404 - val_loss: 0.5185 - val_accuracy: 0.7410\n",
      "Epoch 384/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5155 - accuracy: 0.7408 - val_loss: 0.5137 - val_accuracy: 0.7456\n",
      "Epoch 385/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5159 - accuracy: 0.7405 - val_loss: 0.5158 - val_accuracy: 0.7443\n",
      "Epoch 386/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5150 - accuracy: 0.7404 - val_loss: 0.5158 - val_accuracy: 0.7430\n",
      "Epoch 387/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5151 - accuracy: 0.7412 - val_loss: 0.5178 - val_accuracy: 0.7417\n",
      "Epoch 388/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5156 - accuracy: 0.7413 - val_loss: 0.5137 - val_accuracy: 0.7428\n",
      "Epoch 389/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5155 - accuracy: 0.7414 - val_loss: 0.5171 - val_accuracy: 0.7397\n",
      "Epoch 390/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5155 - accuracy: 0.7405 - val_loss: 0.5156 - val_accuracy: 0.7427\n",
      "Epoch 391/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5156 - accuracy: 0.7409 - val_loss: 0.5201 - val_accuracy: 0.7370\n",
      "Epoch 392/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5156 - accuracy: 0.7405 - val_loss: 0.5122 - val_accuracy: 0.7456\n",
      "Epoch 393/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5157 - accuracy: 0.7410 - val_loss: 0.5189 - val_accuracy: 0.7411\n",
      "Epoch 394/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5152 - accuracy: 0.7396 - val_loss: 0.5126 - val_accuracy: 0.7480\n",
      "Epoch 395/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5156 - accuracy: 0.7411 - val_loss: 0.5140 - val_accuracy: 0.7462\n",
      "Epoch 396/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5153 - accuracy: 0.7413 - val_loss: 0.5154 - val_accuracy: 0.7440\n",
      "Epoch 397/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5132 - val_accuracy: 0.7453\n",
      "Epoch 398/500\n",
      "92096/92096 [==============================] - 4s 38us/sample - loss: 0.5153 - accuracy: 0.7409 - val_loss: 0.5148 - val_accuracy: 0.7444\n",
      "Epoch 399/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5158 - accuracy: 0.7414 - val_loss: 0.5126 - val_accuracy: 0.7486\n",
      "Epoch 400/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5157 - accuracy: 0.7399 - val_loss: 0.5156 - val_accuracy: 0.7442\n",
      "Epoch 401/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5154 - accuracy: 0.7406 - val_loss: 0.5151 - val_accuracy: 0.7460\n",
      "Epoch 402/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5156 - accuracy: 0.7402 - val_loss: 0.5123 - val_accuracy: 0.7468\n",
      "Epoch 403/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5154 - accuracy: 0.7397 - val_loss: 0.5158 - val_accuracy: 0.7450\n",
      "Epoch 404/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5155 - accuracy: 0.7409 - val_loss: 0.5159 - val_accuracy: 0.7455\n",
      "Epoch 405/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5153 - accuracy: 0.7408 - val_loss: 0.5132 - val_accuracy: 0.7466\n",
      "Epoch 406/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5155 - accuracy: 0.7414 - val_loss: 0.5130 - val_accuracy: 0.7455\n",
      "Epoch 407/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5151 - accuracy: 0.7406 - val_loss: 0.5129 - val_accuracy: 0.7457\n",
      "Epoch 408/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5154 - accuracy: 0.7413 - val_loss: 0.5155 - val_accuracy: 0.7407\n",
      "Epoch 409/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5154 - accuracy: 0.7402 - val_loss: 0.5153 - val_accuracy: 0.7434\n",
      "Epoch 410/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5153 - accuracy: 0.7417 - val_loss: 0.5145 - val_accuracy: 0.7434\n",
      "Epoch 411/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5155 - accuracy: 0.7412 - val_loss: 0.5125 - val_accuracy: 0.7474\n",
      "Epoch 412/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5153 - accuracy: 0.7415 - val_loss: 0.5173 - val_accuracy: 0.7415\n",
      "Epoch 413/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5155 - accuracy: 0.7409 - val_loss: 0.5160 - val_accuracy: 0.7425\n",
      "Epoch 414/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.5149 - accuracy: 0.7412 - val_loss: 0.5136 - val_accuracy: 0.7440\n",
      "Epoch 415/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5155 - accuracy: 0.7410 - val_loss: 0.5186 - val_accuracy: 0.7368\n",
      "Epoch 416/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5153 - accuracy: 0.7406 - val_loss: 0.5127 - val_accuracy: 0.7445\n",
      "Epoch 417/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5151 - accuracy: 0.7407 - val_loss: 0.5118 - val_accuracy: 0.7484\n",
      "Epoch 418/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5147 - accuracy: 0.7409 - val_loss: 0.5168 - val_accuracy: 0.7421\n",
      "Epoch 419/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5155 - accuracy: 0.7397 - val_loss: 0.5148 - val_accuracy: 0.7431\n",
      "Epoch 420/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5153 - accuracy: 0.7412 - val_loss: 0.5121 - val_accuracy: 0.7479\n",
      "Epoch 421/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5153 - accuracy: 0.7405 - val_loss: 0.5121 - val_accuracy: 0.7475\n",
      "Epoch 422/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5146 - accuracy: 0.7419 - val_loss: 0.5205 - val_accuracy: 0.7358\n",
      "Epoch 423/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5152 - accuracy: 0.7417 - val_loss: 0.5145 - val_accuracy: 0.7455\n",
      "Epoch 424/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5157 - accuracy: 0.7405 - val_loss: 0.5141 - val_accuracy: 0.7441\n",
      "Epoch 425/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5150 - accuracy: 0.7416 - val_loss: 0.5139 - val_accuracy: 0.7461\n",
      "Epoch 426/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5153 - accuracy: 0.7407 - val_loss: 0.5145 - val_accuracy: 0.7456\n",
      "Epoch 427/500\n",
      "92096/92096 [==============================] - 3s 38us/sample - loss: 0.5151 - accuracy: 0.7424 - val_loss: 0.5135 - val_accuracy: 0.7438\n",
      "Epoch 428/500\n",
      "92096/92096 [==============================] - 4s 39us/sample - loss: 0.5151 - accuracy: 0.7412 - val_loss: 0.5113 - val_accuracy: 0.7478\n",
      "Epoch 429/500\n",
      "92096/92096 [==============================] - 3s 37us/sample - loss: 0.5152 - accuracy: 0.7412 - val_loss: 0.5135 - val_accuracy: 0.7427\n",
      "Epoch 430/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5152 - accuracy: 0.7418 - val_loss: 0.5153 - val_accuracy: 0.7427\n",
      "Epoch 431/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5155 - accuracy: 0.7401 - val_loss: 0.5145 - val_accuracy: 0.7454\n",
      "Epoch 432/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5154 - accuracy: 0.7407 - val_loss: 0.5144 - val_accuracy: 0.7434\n",
      "Epoch 433/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5152 - accuracy: 0.7401 - val_loss: 0.5139 - val_accuracy: 0.7459\n",
      "Epoch 434/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5150 - accuracy: 0.7417 - val_loss: 0.5132 - val_accuracy: 0.7470\n",
      "Epoch 435/500\n",
      "92096/92096 [==============================] - 4s 38us/sample - loss: 0.5152 - accuracy: 0.7409 - val_loss: 0.5142 - val_accuracy: 0.7467\n",
      "Epoch 436/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5148 - accuracy: 0.7416 - val_loss: 0.5127 - val_accuracy: 0.7435\n",
      "Epoch 437/500\n",
      "92096/92096 [==============================] - 3s 37us/sample - loss: 0.5150 - accuracy: 0.7412 - val_loss: 0.5127 - val_accuracy: 0.7487\n",
      "Epoch 438/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5149 - accuracy: 0.7408 - val_loss: 0.5113 - val_accuracy: 0.7487\n",
      "Epoch 439/500\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.5149 - accuracy: 0.7414 - val_loss: 0.5142 - val_accuracy: 0.7451\n",
      "Epoch 440/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5151 - accuracy: 0.7409 - val_loss: 0.5153 - val_accuracy: 0.7449\n",
      "Epoch 441/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5151 - accuracy: 0.7397 - val_loss: 0.5173 - val_accuracy: 0.7434\n",
      "Epoch 442/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5150 - accuracy: 0.7418 - val_loss: 0.5158 - val_accuracy: 0.7453\n",
      "Epoch 443/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5148 - accuracy: 0.7408 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 444/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5153 - accuracy: 0.7406 - val_loss: 0.5109 - val_accuracy: 0.7478\n",
      "Epoch 445/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5149 - accuracy: 0.7405 - val_loss: 0.5115 - val_accuracy: 0.7481\n",
      "Epoch 446/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5148 - accuracy: 0.7418 - val_loss: 0.5160 - val_accuracy: 0.7410\n",
      "Epoch 447/500\n",
      "92096/92096 [==============================] - 3s 37us/sample - loss: 0.5149 - accuracy: 0.7418 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 448/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5149 - accuracy: 0.7410 - val_loss: 0.5143 - val_accuracy: 0.7464\n",
      "Epoch 449/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5147 - accuracy: 0.7417 - val_loss: 0.5120 - val_accuracy: 0.7492\n",
      "Epoch 450/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5146 - accuracy: 0.7420 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 451/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5150 - accuracy: 0.7412 - val_loss: 0.5128 - val_accuracy: 0.7478\n",
      "Epoch 452/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5149 - accuracy: 0.7401 - val_loss: 0.5139 - val_accuracy: 0.7471\n",
      "Epoch 453/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5147 - accuracy: 0.7408 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 454/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5148 - accuracy: 0.7410 - val_loss: 0.5110 - val_accuracy: 0.7485\n",
      "Epoch 455/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5148 - accuracy: 0.7404 - val_loss: 0.5189 - val_accuracy: 0.7442\n",
      "Epoch 456/500\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.5146 - accuracy: 0.7423 - val_loss: 0.5138 - val_accuracy: 0.7455\n",
      "Epoch 457/500\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.5147 - accuracy: 0.7410 - val_loss: 0.5161 - val_accuracy: 0.7421\n",
      "Epoch 458/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5147 - accuracy: 0.7408 - val_loss: 0.5134 - val_accuracy: 0.7453\n",
      "Epoch 459/500\n",
      "92096/92096 [==============================] - 4s 38us/sample - loss: 0.5150 - accuracy: 0.7411 - val_loss: 0.5171 - val_accuracy: 0.7413\n",
      "Epoch 460/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5151 - accuracy: 0.7403 - val_loss: 0.5141 - val_accuracy: 0.7460\n",
      "Epoch 461/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5148 - accuracy: 0.7408 - val_loss: 0.5138 - val_accuracy: 0.7458\n",
      "Epoch 462/500\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5149 - accuracy: 0.7414 - val_loss: 0.5119 - val_accuracy: 0.7468\n",
      "Epoch 463/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5150 - accuracy: 0.7402 - val_loss: 0.5118 - val_accuracy: 0.7484\n",
      "Epoch 464/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5145 - accuracy: 0.7417 - val_loss: 0.5179 - val_accuracy: 0.7428\n",
      "Epoch 465/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5147 - accuracy: 0.7423 - val_loss: 0.5140 - val_accuracy: 0.7443\n",
      "Epoch 466/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5151 - accuracy: 0.7404 - val_loss: 0.5157 - val_accuracy: 0.7452\n",
      "Epoch 467/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5147 - accuracy: 0.7417 - val_loss: 0.5164 - val_accuracy: 0.7411\n",
      "Epoch 468/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5145 - accuracy: 0.7419 - val_loss: 0.5125 - val_accuracy: 0.7492\n",
      "Epoch 469/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5150 - accuracy: 0.7416 - val_loss: 0.5123 - val_accuracy: 0.7464\n",
      "Epoch 470/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5147 - accuracy: 0.7406 - val_loss: 0.5137 - val_accuracy: 0.7453\n",
      "Epoch 471/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5146 - accuracy: 0.7418 - val_loss: 0.5132 - val_accuracy: 0.7468\n",
      "Epoch 472/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5150 - accuracy: 0.7409 - val_loss: 0.5118 - val_accuracy: 0.7495\n",
      "Epoch 473/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5147 - accuracy: 0.7413 - val_loss: 0.5126 - val_accuracy: 0.7461\n",
      "Epoch 474/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5150 - accuracy: 0.7415 - val_loss: 0.5122 - val_accuracy: 0.7490\n",
      "Epoch 475/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5146 - accuracy: 0.7409 - val_loss: 0.5189 - val_accuracy: 0.7418\n",
      "Epoch 476/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5150 - accuracy: 0.7407 - val_loss: 0.5107 - val_accuracy: 0.7495\n",
      "Epoch 477/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5148 - accuracy: 0.7408 - val_loss: 0.5138 - val_accuracy: 0.7422\n",
      "Epoch 478/500\n",
      "92096/92096 [==============================] - 4s 38us/sample - loss: 0.5148 - accuracy: 0.7420 - val_loss: 0.5116 - val_accuracy: 0.7467\n",
      "Epoch 479/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5145 - accuracy: 0.7419 - val_loss: 0.5170 - val_accuracy: 0.7415\n",
      "Epoch 480/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5148 - accuracy: 0.7413 - val_loss: 0.5125 - val_accuracy: 0.7477\n",
      "Epoch 481/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5150 - accuracy: 0.7414 - val_loss: 0.5114 - val_accuracy: 0.7493\n",
      "Epoch 482/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5148 - accuracy: 0.7409 - val_loss: 0.5116 - val_accuracy: 0.7481\n",
      "Epoch 483/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5148 - accuracy: 0.7421 - val_loss: 0.5139 - val_accuracy: 0.7458\n",
      "Epoch 484/500\n",
      "92096/92096 [==============================] - 3s 37us/sample - loss: 0.5151 - accuracy: 0.7403 - val_loss: 0.5110 - val_accuracy: 0.7485\n",
      "Epoch 485/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5144 - accuracy: 0.7411 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 486/500\n",
      "92096/92096 [==============================] - 3s 34us/sample - loss: 0.5147 - accuracy: 0.7416 - val_loss: 0.5167 - val_accuracy: 0.7407\n",
      "Epoch 487/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5144 - accuracy: 0.7410 - val_loss: 0.5143 - val_accuracy: 0.7472\n",
      "Epoch 488/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5146 - accuracy: 0.7417 - val_loss: 0.5150 - val_accuracy: 0.7441\n",
      "Epoch 489/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5147 - accuracy: 0.7414 - val_loss: 0.5150 - val_accuracy: 0.7433\n",
      "Epoch 490/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5147 - accuracy: 0.7409 - val_loss: 0.5146 - val_accuracy: 0.7449\n",
      "Epoch 491/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5149 - accuracy: 0.7409 - val_loss: 0.5143 - val_accuracy: 0.7473\n",
      "Epoch 492/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5148 - accuracy: 0.7408 - val_loss: 0.5120 - val_accuracy: 0.7467\n",
      "Epoch 493/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5150 - accuracy: 0.7413 - val_loss: 0.5124 - val_accuracy: 0.7477\n",
      "Epoch 494/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.5144 - accuracy: 0.7420 - val_loss: 0.5155 - val_accuracy: 0.7437\n",
      "Epoch 495/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5148 - accuracy: 0.7414 - val_loss: 0.5122 - val_accuracy: 0.7481\n",
      "Epoch 496/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.5144 - accuracy: 0.7413 - val_loss: 0.5139 - val_accuracy: 0.7427\n",
      "Epoch 497/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5147 - accuracy: 0.7405 - val_loss: 0.5133 - val_accuracy: 0.7461\n",
      "Epoch 498/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.5145 - accuracy: 0.7415 - val_loss: 0.5234 - val_accuracy: 0.7394\n",
      "Epoch 499/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.5147 - accuracy: 0.7415 - val_loss: 0.5127 - val_accuracy: 0.7453\n",
      "Epoch 500/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.5148 - accuracy: 0.7414 - val_loss: 0.5112 - val_accuracy: 0.7483\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(shuffle(pd.DataFrame(x_train_resampled),random_state=1), shuffle(pd.DataFrame(y_train_resampled),random_state=1), epochs=500,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train_resampled)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_8.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 9\n",
    "-Standard Scaler & Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(60, activation=tf.nn.relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 60)                600       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 122       \n",
      "=================================================================\n",
      "Total params: 722\n",
      "Trainable params: 722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2878/2878 [==============================] - 3s 819us/step - loss: 0.5945 - accuracy: 0.6749 - val_loss: 0.5649 - val_accuracy: 0.7050\n",
      "Epoch 2/500\n",
      "2878/2878 [==============================] - 2s 648us/step - loss: 0.5644 - accuracy: 0.7026 - val_loss: 0.5572 - val_accuracy: 0.7081\n",
      "Epoch 3/500\n",
      "2878/2878 [==============================] - 2s 623us/step - loss: 0.5588 - accuracy: 0.7036 - val_loss: 0.5533 - val_accuracy: 0.7108\n",
      "Epoch 4/500\n",
      "2878/2878 [==============================] - 2s 597us/step - loss: 0.5532 - accuracy: 0.7108 - val_loss: 0.5492 - val_accuracy: 0.7125\n",
      "Epoch 5/500\n",
      "2878/2878 [==============================] - 2s 665us/step - loss: 0.5506 - accuracy: 0.7116 - val_loss: 0.5461 - val_accuracy: 0.7163\n",
      "Epoch 6/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5488 - accuracy: 0.7135 - val_loss: 0.5491 - val_accuracy: 0.7156\n",
      "Epoch 7/500\n",
      "2878/2878 [==============================] - 2s 807us/step - loss: 0.5459 - accuracy: 0.7159 - val_loss: 0.5437 - val_accuracy: 0.7190\n",
      "Epoch 8/500\n",
      "2878/2878 [==============================] - 2s 664us/step - loss: 0.5434 - accuracy: 0.7179 - val_loss: 0.5432 - val_accuracy: 0.7175\n",
      "Epoch 9/500\n",
      "2878/2878 [==============================] - 2s 605us/step - loss: 0.5420 - accuracy: 0.7196 - val_loss: 0.5398 - val_accuracy: 0.7191\n",
      "Epoch 10/500\n",
      "2878/2878 [==============================] - 2s 599us/step - loss: 0.5363 - accuracy: 0.7220 - val_loss: 0.5374 - val_accuracy: 0.7247\n",
      "Epoch 11/500\n",
      "2878/2878 [==============================] - 2s 612us/step - loss: 0.5379 - accuracy: 0.7248 - val_loss: 0.5380 - val_accuracy: 0.7235\n",
      "Epoch 12/500\n",
      "2878/2878 [==============================] - 2s 613us/step - loss: 0.5373 - accuracy: 0.7236 - val_loss: 0.5341 - val_accuracy: 0.7256\n",
      "Epoch 13/500\n",
      "2878/2878 [==============================] - 2s 621us/step - loss: 0.5360 - accuracy: 0.7250 - val_loss: 0.5342 - val_accuracy: 0.7287\n",
      "Epoch 14/500\n",
      "2878/2878 [==============================] - 2s 609us/step - loss: 0.5363 - accuracy: 0.7248 - val_loss: 0.5336 - val_accuracy: 0.7306\n",
      "Epoch 15/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5330 - accuracy: 0.7286 - val_loss: 0.5321 - val_accuracy: 0.7309\n",
      "Epoch 16/500\n",
      "2878/2878 [==============================] - 2s 760us/step - loss: 0.5305 - accuracy: 0.7306 - val_loss: 0.5293 - val_accuracy: 0.7314\n",
      "Epoch 17/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.5275 - accuracy: 0.7334 - val_loss: 0.5242 - val_accuracy: 0.7383\n",
      "Epoch 18/500\n",
      "2878/2878 [==============================] - 2s 867us/step - loss: 0.5257 - accuracy: 0.7344 - val_loss: 0.5236 - val_accuracy: 0.7357\n",
      "Epoch 19/500\n",
      "2878/2878 [==============================] - 3s 889us/step - loss: 0.5251 - accuracy: 0.7349 - val_loss: 0.5216 - val_accuracy: 0.7381\n",
      "Epoch 20/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5231 - accuracy: 0.7353 - val_loss: 0.5190 - val_accuracy: 0.7384\n",
      "Epoch 21/500\n",
      "2878/2878 [==============================] - 2s 614us/step - loss: 0.5216 - accuracy: 0.7366 - val_loss: 0.5259 - val_accuracy: 0.7350\n",
      "Epoch 22/500\n",
      "2878/2878 [==============================] - 2s 620us/step - loss: 0.5198 - accuracy: 0.7388 - val_loss: 0.5230 - val_accuracy: 0.7372\n",
      "Epoch 23/500\n",
      "2878/2878 [==============================] - 2s 629us/step - loss: 0.5194 - accuracy: 0.7372 - val_loss: 0.5229 - val_accuracy: 0.7388\n",
      "Epoch 24/500\n",
      "2878/2878 [==============================] - 2s 632us/step - loss: 0.5210 - accuracy: 0.7384 - val_loss: 0.5156 - val_accuracy: 0.7401\n",
      "Epoch 25/500\n",
      "2878/2878 [==============================] - 2s 649us/step - loss: 0.5177 - accuracy: 0.7402 - val_loss: 0.5224 - val_accuracy: 0.7315\n",
      "Epoch 26/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5145 - accuracy: 0.7435 - val_loss: 0.5149 - val_accuracy: 0.7401\n",
      "Epoch 27/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5163 - accuracy: 0.7401 - val_loss: 0.5192 - val_accuracy: 0.7410\n",
      "Epoch 28/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.5141 - accuracy: 0.7426 - val_loss: 0.5151 - val_accuracy: 0.7427\n",
      "Epoch 29/500\n",
      "2878/2878 [==============================] - 2s 815us/step - loss: 0.5124 - accuracy: 0.7432 - val_loss: 0.5176 - val_accuracy: 0.7377\n",
      "Epoch 30/500\n",
      "2878/2878 [==============================] - 2s 780us/step - loss: 0.5114 - accuracy: 0.7428 - val_loss: 0.5139 - val_accuracy: 0.7440\n",
      "Epoch 31/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5111 - accuracy: 0.7440 - val_loss: 0.5124 - val_accuracy: 0.7443\n",
      "Epoch 32/500\n",
      "2878/2878 [==============================] - 3s 932us/step - loss: 0.5086 - accuracy: 0.7459 - val_loss: 0.5150 - val_accuracy: 0.7429\n",
      "Epoch 33/500\n",
      "2878/2878 [==============================] - 2s 825us/step - loss: 0.5104 - accuracy: 0.7464 - val_loss: 0.5097 - val_accuracy: 0.7458\n",
      "Epoch 34/500\n",
      "2878/2878 [==============================] - 2s 764us/step - loss: 0.5079 - accuracy: 0.7454 - val_loss: 0.5119 - val_accuracy: 0.7463\n",
      "Epoch 35/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.5130 - accuracy: 0.7462 - val_loss: 0.5125 - val_accuracy: 0.7451\n",
      "Epoch 36/500\n",
      "2878/2878 [==============================] - 2s 755us/step - loss: 0.5086 - accuracy: 0.7449 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 37/500\n",
      "2878/2878 [==============================] - 2s 807us/step - loss: 0.5063 - accuracy: 0.7482 - val_loss: 0.5062 - val_accuracy: 0.7483\n",
      "Epoch 38/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5090 - accuracy: 0.7457 - val_loss: 0.5064 - val_accuracy: 0.7484\n",
      "Epoch 39/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5093 - accuracy: 0.7462 - val_loss: 0.5056 - val_accuracy: 0.7473\n",
      "Epoch 40/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5079 - accuracy: 0.7487 - val_loss: 0.5120 - val_accuracy: 0.7458\n",
      "Epoch 41/500\n",
      "2878/2878 [==============================] - 2s 664us/step - loss: 0.5049 - accuracy: 0.7497 - val_loss: 0.5083 - val_accuracy: 0.7459\n",
      "Epoch 42/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5084 - accuracy: 0.7489 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 43/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5071 - accuracy: 0.7472 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 44/500\n",
      "2878/2878 [==============================] - 2s 666us/step - loss: 0.5090 - accuracy: 0.7446 - val_loss: 0.5079 - val_accuracy: 0.7498\n",
      "Epoch 45/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.5037 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7471\n",
      "Epoch 46/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5061 - accuracy: 0.7477 - val_loss: 0.5085 - val_accuracy: 0.7466\n",
      "Epoch 47/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5056 - accuracy: 0.7490 - val_loss: 0.5047 - val_accuracy: 0.7514\n",
      "Epoch 48/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5068 - accuracy: 0.7483 - val_loss: 0.5036 - val_accuracy: 0.7506\n",
      "Epoch 49/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.5047 - accuracy: 0.7484 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 50/500\n",
      "2878/2878 [==============================] - 2s 752us/step - loss: 0.5042 - accuracy: 0.7501 - val_loss: 0.5045 - val_accuracy: 0.7498\n",
      "Epoch 51/500\n",
      "2878/2878 [==============================] - 2s 787us/step - loss: 0.5050 - accuracy: 0.7480 - val_loss: 0.5060 - val_accuracy: 0.7474\n",
      "Epoch 52/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.5031 - accuracy: 0.7511 - val_loss: 0.5063 - val_accuracy: 0.7506\n",
      "Epoch 53/500\n",
      "2878/2878 [==============================] - 2s 761us/step - loss: 0.5033 - accuracy: 0.7502 - val_loss: 0.5083 - val_accuracy: 0.7488\n",
      "Epoch 54/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5044 - accuracy: 0.7489 - val_loss: 0.5025 - val_accuracy: 0.7530\n",
      "Epoch 55/500\n",
      "2878/2878 [==============================] - 3s 915us/step - loss: 0.5043 - accuracy: 0.7493 - val_loss: 0.5111 - val_accuracy: 0.7459\n",
      "Epoch 56/500\n",
      "2878/2878 [==============================] - 2s 770us/step - loss: 0.5031 - accuracy: 0.7501 - val_loss: 0.5051 - val_accuracy: 0.7522\n",
      "Epoch 57/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5029 - accuracy: 0.7502 - val_loss: 0.5004 - val_accuracy: 0.7523\n",
      "Epoch 58/500\n",
      "2878/2878 [==============================] - 2s 654us/step - loss: 0.5014 - accuracy: 0.7531 - val_loss: 0.5015 - val_accuracy: 0.7517\n",
      "Epoch 59/500\n",
      "2878/2878 [==============================] - 2s 615us/step - loss: 0.5047 - accuracy: 0.7470 - val_loss: 0.5016 - val_accuracy: 0.7506\n",
      "Epoch 60/500\n",
      "2878/2878 [==============================] - 2s 661us/step - loss: 0.4998 - accuracy: 0.7521 - val_loss: 0.5067 - val_accuracy: 0.7495\n",
      "Epoch 61/500\n",
      "2878/2878 [==============================] - 2s 750us/step - loss: 0.5014 - accuracy: 0.7512 - val_loss: 0.5053 - val_accuracy: 0.7483\n",
      "Epoch 62/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5017 - accuracy: 0.7527 - val_loss: 0.5033 - val_accuracy: 0.7484\n",
      "Epoch 63/500\n",
      "2878/2878 [==============================] - 2s 640us/step - loss: 0.5065 - accuracy: 0.7476 - val_loss: 0.5086 - val_accuracy: 0.7476\n",
      "Epoch 64/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5015 - accuracy: 0.7505 - val_loss: 0.5081 - val_accuracy: 0.7422\n",
      "Epoch 65/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.5006 - accuracy: 0.7522 - val_loss: 0.5026 - val_accuracy: 0.7512\n",
      "Epoch 66/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.5027 - accuracy: 0.7489 - val_loss: 0.5038 - val_accuracy: 0.7532\n",
      "Epoch 67/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5021 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 68/500\n",
      "2878/2878 [==============================] - 2s 661us/step - loss: 0.4999 - accuracy: 0.7505 - val_loss: 0.5010 - val_accuracy: 0.7507\n",
      "Epoch 69/500\n",
      "2878/2878 [==============================] - 2s 609us/step - loss: 0.4999 - accuracy: 0.7522 - val_loss: 0.5001 - val_accuracy: 0.7507\n",
      "Epoch 70/500\n",
      "2878/2878 [==============================] - 2s 639us/step - loss: 0.5005 - accuracy: 0.7512 - val_loss: 0.5219 - val_accuracy: 0.7391\n",
      "Epoch 71/500\n",
      "2878/2878 [==============================] - 2s 655us/step - loss: 0.5008 - accuracy: 0.7532 - val_loss: 0.5009 - val_accuracy: 0.7501\n",
      "Epoch 72/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4975 - accuracy: 0.7531 - val_loss: 0.4990 - val_accuracy: 0.7524\n",
      "Epoch 73/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.5003 - accuracy: 0.7523 - val_loss: 0.4976 - val_accuracy: 0.7547\n",
      "Epoch 74/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5012 - accuracy: 0.7501 - val_loss: 0.5002 - val_accuracy: 0.7527\n",
      "Epoch 75/500\n",
      "2878/2878 [==============================] - 2s 756us/step - loss: 0.4994 - accuracy: 0.7515 - val_loss: 0.4991 - val_accuracy: 0.7489\n",
      "Epoch 76/500\n",
      "2878/2878 [==============================] - 2s 667us/step - loss: 0.4978 - accuracy: 0.7526 - val_loss: 0.4987 - val_accuracy: 0.7558\n",
      "Epoch 77/500\n",
      "2878/2878 [==============================] - 2s 652us/step - loss: 0.4993 - accuracy: 0.7537 - val_loss: 0.5010 - val_accuracy: 0.7507\n",
      "Epoch 78/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5014 - accuracy: 0.7492 - val_loss: 0.5049 - val_accuracy: 0.7483\n",
      "Epoch 79/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.5020 - accuracy: 0.7500 - val_loss: 0.5028 - val_accuracy: 0.7540\n",
      "Epoch 80/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.4986 - accuracy: 0.7520 - val_loss: 0.5110 - val_accuracy: 0.7457\n",
      "Epoch 81/500\n",
      "2878/2878 [==============================] - 2s 824us/step - loss: 0.5001 - accuracy: 0.7519 - val_loss: 0.5006 - val_accuracy: 0.7515\n",
      "Epoch 82/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.4982 - accuracy: 0.7535 - val_loss: 0.5003 - val_accuracy: 0.7518\n",
      "Epoch 83/500\n",
      "2878/2878 [==============================] - 2s 665us/step - loss: 0.4980 - accuracy: 0.7530 - val_loss: 0.5044 - val_accuracy: 0.7514\n",
      "Epoch 84/500\n",
      "2878/2878 [==============================] - 2s 671us/step - loss: 0.5011 - accuracy: 0.7503 - val_loss: 0.5000 - val_accuracy: 0.7487\n",
      "Epoch 85/500\n",
      "2878/2878 [==============================] - 2s 832us/step - loss: 0.5012 - accuracy: 0.7518 - val_loss: 0.5129 - val_accuracy: 0.7406\n",
      "Epoch 86/500\n",
      "2878/2878 [==============================] - 3s 987us/step - loss: 0.4983 - accuracy: 0.7551 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 87/500\n",
      "2878/2878 [==============================] - 2s 823us/step - loss: 0.4996 - accuracy: 0.7505 - val_loss: 0.5061 - val_accuracy: 0.7436\n",
      "Epoch 88/500\n",
      "2878/2878 [==============================] - 2s 795us/step - loss: 0.4990 - accuracy: 0.7529 - val_loss: 0.4999 - val_accuracy: 0.7533\n",
      "Epoch 89/500\n",
      "2878/2878 [==============================] - 2s 805us/step - loss: 0.4977 - accuracy: 0.7530 - val_loss: 0.4960 - val_accuracy: 0.7572\n",
      "Epoch 90/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4987 - accuracy: 0.7515 - val_loss: 0.4997 - val_accuracy: 0.7544\n",
      "Epoch 91/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4987 - accuracy: 0.7529 - val_loss: 0.4983 - val_accuracy: 0.7515\n",
      "Epoch 92/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4982 - accuracy: 0.7554 - val_loss: 0.4968 - val_accuracy: 0.7560\n",
      "Epoch 93/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4964 - accuracy: 0.7569 - val_loss: 0.5043 - val_accuracy: 0.7453\n",
      "Epoch 94/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4991 - accuracy: 0.7529 - val_loss: 0.5010 - val_accuracy: 0.7525\n",
      "Epoch 95/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4966 - accuracy: 0.7534 - val_loss: 0.4961 - val_accuracy: 0.7564\n",
      "Epoch 96/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.4976 - accuracy: 0.7532 - val_loss: 0.4976 - val_accuracy: 0.7538\n",
      "Epoch 97/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4969 - accuracy: 0.7544 - val_loss: 0.5041 - val_accuracy: 0.7489\n",
      "Epoch 98/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4996 - accuracy: 0.7536 - val_loss: 0.4991 - val_accuracy: 0.7510\n",
      "Epoch 99/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4982 - accuracy: 0.7554 - val_loss: 0.4992 - val_accuracy: 0.7540\n",
      "Epoch 100/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4995 - accuracy: 0.7522 - val_loss: 0.4969 - val_accuracy: 0.7538\n",
      "Epoch 101/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4966 - accuracy: 0.7546 - val_loss: 0.5009 - val_accuracy: 0.7523\n",
      "Epoch 102/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4998 - accuracy: 0.7534 - val_loss: 0.4965 - val_accuracy: 0.7561\n",
      "Epoch 103/500\n",
      "2878/2878 [==============================] - 2s 755us/step - loss: 0.4957 - accuracy: 0.7549 - val_loss: 0.4992 - val_accuracy: 0.7536\n",
      "Epoch 104/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4964 - accuracy: 0.7548 - val_loss: 0.4998 - val_accuracy: 0.7521\n",
      "Epoch 105/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4976 - accuracy: 0.7542 - val_loss: 0.4954 - val_accuracy: 0.7556\n",
      "Epoch 106/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4962 - accuracy: 0.7550 - val_loss: 0.5014 - val_accuracy: 0.7507\n",
      "Epoch 107/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4967 - accuracy: 0.7546 - val_loss: 0.5007 - val_accuracy: 0.7526\n",
      "Epoch 108/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4968 - accuracy: 0.7564 - val_loss: 0.5020 - val_accuracy: 0.7535\n",
      "Epoch 109/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4960 - accuracy: 0.7544 - val_loss: 0.4936 - val_accuracy: 0.7573\n",
      "Epoch 110/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4942 - accuracy: 0.7562 - val_loss: 0.5040 - val_accuracy: 0.7520\n",
      "Epoch 111/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4927 - accuracy: 0.7575 - val_loss: 0.4974 - val_accuracy: 0.7536\n",
      "Epoch 112/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.4958 - accuracy: 0.7551 - val_loss: 0.4982 - val_accuracy: 0.7511\n",
      "Epoch 113/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.4975 - accuracy: 0.7524 - val_loss: 0.4987 - val_accuracy: 0.7579\n",
      "Epoch 114/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.4931 - accuracy: 0.7568 - val_loss: 0.4988 - val_accuracy: 0.7540\n",
      "Epoch 115/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.4970 - accuracy: 0.7552 - val_loss: 0.4969 - val_accuracy: 0.7560\n",
      "Epoch 116/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4968 - accuracy: 0.7544 - val_loss: 0.4943 - val_accuracy: 0.7602\n",
      "Epoch 117/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.4953 - accuracy: 0.7530 - val_loss: 0.4934 - val_accuracy: 0.7599\n",
      "Epoch 118/500\n",
      "2878/2878 [==============================] - 2s 865us/step - loss: 0.4947 - accuracy: 0.7543 - val_loss: 0.5007 - val_accuracy: 0.7533\n",
      "Epoch 119/500\n",
      "2878/2878 [==============================] - 2s 857us/step - loss: 0.4947 - accuracy: 0.7562 - val_loss: 0.4984 - val_accuracy: 0.7526\n",
      "Epoch 120/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4947 - accuracy: 0.7571 - val_loss: 0.4977 - val_accuracy: 0.7567\n",
      "Epoch 121/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4955 - accuracy: 0.7571 - val_loss: 0.4959 - val_accuracy: 0.7532\n",
      "Epoch 122/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.4935 - accuracy: 0.7569 - val_loss: 0.4966 - val_accuracy: 0.7556\n",
      "Epoch 123/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.4925 - accuracy: 0.7558 - val_loss: 0.4966 - val_accuracy: 0.7555\n",
      "Epoch 124/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.4934 - accuracy: 0.7561 - val_loss: 0.4962 - val_accuracy: 0.7556\n",
      "Epoch 125/500\n",
      "2878/2878 [==============================] - 2s 672us/step - loss: 0.4924 - accuracy: 0.7572 - val_loss: 0.4993 - val_accuracy: 0.7543\n",
      "Epoch 126/500\n",
      "2878/2878 [==============================] - 2s 671us/step - loss: 0.4939 - accuracy: 0.7573 - val_loss: 0.4949 - val_accuracy: 0.7601\n",
      "Epoch 127/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.4954 - accuracy: 0.7577 - val_loss: 0.5025 - val_accuracy: 0.7561\n",
      "Epoch 128/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.4938 - accuracy: 0.7571 - val_loss: 0.4969 - val_accuracy: 0.7570\n",
      "Epoch 129/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.4928 - accuracy: 0.7583 - val_loss: 0.4960 - val_accuracy: 0.7578\n",
      "Epoch 130/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.4945 - accuracy: 0.7556 - val_loss: 0.4997 - val_accuracy: 0.7529\n",
      "Epoch 131/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.4938 - accuracy: 0.7565 - val_loss: 0.4945 - val_accuracy: 0.7577\n",
      "Epoch 132/500\n",
      "2878/2878 [==============================] - 2s 812us/step - loss: 0.4960 - accuracy: 0.7545 - val_loss: 0.4945 - val_accuracy: 0.7576\n",
      "Epoch 133/500\n",
      "2878/2878 [==============================] - 2s 800us/step - loss: 0.4930 - accuracy: 0.7576 - val_loss: 0.4991 - val_accuracy: 0.7539\n",
      "Epoch 134/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4942 - accuracy: 0.7555 - val_loss: 0.4928 - val_accuracy: 0.7560\n",
      "Epoch 135/500\n",
      "2878/2878 [==============================] - 2s 768us/step - loss: 0.4936 - accuracy: 0.7557 - val_loss: 0.4993 - val_accuracy: 0.7539\n",
      "Epoch 136/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4910 - accuracy: 0.7577 - val_loss: 0.4970 - val_accuracy: 0.7530\n",
      "Epoch 137/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.4941 - accuracy: 0.7552 - val_loss: 0.5017 - val_accuracy: 0.7499\n",
      "Epoch 138/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4948 - accuracy: 0.7555 - val_loss: 0.4944 - val_accuracy: 0.7587\n",
      "Epoch 139/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.4938 - accuracy: 0.7586 - val_loss: 0.5013 - val_accuracy: 0.7515\n",
      "Epoch 140/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.4929 - accuracy: 0.7580 - val_loss: 0.4920 - val_accuracy: 0.7588\n",
      "Epoch 141/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.4940 - accuracy: 0.7581 - val_loss: 0.4989 - val_accuracy: 0.7523\n",
      "Epoch 142/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.4927 - accuracy: 0.7579 - val_loss: 0.4922 - val_accuracy: 0.7588\n",
      "Epoch 143/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4955 - accuracy: 0.7561 - val_loss: 0.4942 - val_accuracy: 0.7556\n",
      "Epoch 144/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.4949 - accuracy: 0.7557 - val_loss: 0.4969 - val_accuracy: 0.7550\n",
      "Epoch 145/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4936 - accuracy: 0.7553 - val_loss: 0.4987 - val_accuracy: 0.7536\n",
      "Epoch 146/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.4921 - accuracy: 0.7585 - val_loss: 0.4990 - val_accuracy: 0.7545\n",
      "Epoch 147/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.4920 - accuracy: 0.7586 - val_loss: 0.4933 - val_accuracy: 0.7605\n",
      "Epoch 148/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.4923 - accuracy: 0.7589 - val_loss: 0.4921 - val_accuracy: 0.7610\n",
      "Epoch 149/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.4971 - accuracy: 0.7532 - val_loss: 0.4937 - val_accuracy: 0.7574\n",
      "Epoch 150/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4922 - accuracy: 0.7579 - val_loss: 0.4966 - val_accuracy: 0.7536\n",
      "Epoch 151/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4934 - accuracy: 0.7575 - val_loss: 0.4928 - val_accuracy: 0.7568\n",
      "Epoch 152/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.4911 - accuracy: 0.7593 - val_loss: 0.4965 - val_accuracy: 0.7550\n",
      "Epoch 153/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4940 - accuracy: 0.7595 - val_loss: 0.4956 - val_accuracy: 0.7553\n",
      "Epoch 154/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4934 - accuracy: 0.7558 - val_loss: 0.4972 - val_accuracy: 0.7552\n",
      "Epoch 155/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4944 - accuracy: 0.7575 - val_loss: 0.4922 - val_accuracy: 0.7599\n",
      "Epoch 156/500\n",
      "2878/2878 [==============================] - 2s 791us/step - loss: 0.4947 - accuracy: 0.7581 - val_loss: 0.4912 - val_accuracy: 0.7591\n",
      "Epoch 157/500\n",
      "2878/2878 [==============================] - 2s 776us/step - loss: 0.4927 - accuracy: 0.7575 - val_loss: 0.4940 - val_accuracy: 0.7576\n",
      "Epoch 158/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.4912 - accuracy: 0.7591 - val_loss: 0.4992 - val_accuracy: 0.7537\n",
      "Epoch 159/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4910 - accuracy: 0.7600 - val_loss: 0.4979 - val_accuracy: 0.7541\n",
      "Epoch 160/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.4922 - accuracy: 0.7596 - val_loss: 0.4902 - val_accuracy: 0.7612\n",
      "Epoch 161/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4949 - accuracy: 0.7560 - val_loss: 0.4921 - val_accuracy: 0.7585\n",
      "Epoch 162/500\n",
      "2878/2878 [==============================] - 2s 762us/step - loss: 0.4899 - accuracy: 0.7594 - val_loss: 0.4946 - val_accuracy: 0.7579\n",
      "Epoch 163/500\n",
      "2878/2878 [==============================] - 2s 780us/step - loss: 0.4951 - accuracy: 0.7548 - val_loss: 0.4935 - val_accuracy: 0.7593\n",
      "Epoch 164/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4936 - accuracy: 0.7581 - val_loss: 0.4940 - val_accuracy: 0.7579\n",
      "Epoch 165/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.4939 - accuracy: 0.7565 - val_loss: 0.4932 - val_accuracy: 0.7569\n",
      "Epoch 166/500\n",
      "2878/2878 [==============================] - 2s 766us/step - loss: 0.4919 - accuracy: 0.7587 - val_loss: 0.4955 - val_accuracy: 0.7572\n",
      "Epoch 167/500\n",
      "2878/2878 [==============================] - 2s 754us/step - loss: 0.4935 - accuracy: 0.7576 - val_loss: 0.4919 - val_accuracy: 0.7606\n",
      "Epoch 168/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.4966 - accuracy: 0.7558 - val_loss: 0.4920 - val_accuracy: 0.7592\n",
      "Epoch 169/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4935 - accuracy: 0.7588 - val_loss: 0.4941 - val_accuracy: 0.7550\n",
      "Epoch 170/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4922 - accuracy: 0.7582 - val_loss: 0.4974 - val_accuracy: 0.7535\n",
      "Epoch 171/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4930 - accuracy: 0.7590 - val_loss: 0.4959 - val_accuracy: 0.7557\n",
      "Epoch 172/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4908 - accuracy: 0.7592 - val_loss: 0.4953 - val_accuracy: 0.7572\n",
      "Epoch 173/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4923 - accuracy: 0.7583 - val_loss: 0.4932 - val_accuracy: 0.7595\n",
      "Epoch 174/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4953 - accuracy: 0.7549 - val_loss: 0.4935 - val_accuracy: 0.7569\n",
      "Epoch 175/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4913 - accuracy: 0.7582 - val_loss: 0.4893 - val_accuracy: 0.7613\n",
      "Epoch 176/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4935 - accuracy: 0.7570 - val_loss: 0.4915 - val_accuracy: 0.7586\n",
      "Epoch 177/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4890 - accuracy: 0.7620 - val_loss: 0.4953 - val_accuracy: 0.7556\n",
      "Epoch 178/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4904 - accuracy: 0.7603 - val_loss: 0.4926 - val_accuracy: 0.7599\n",
      "Epoch 179/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4931 - accuracy: 0.7589 - val_loss: 0.4954 - val_accuracy: 0.7611\n",
      "Epoch 180/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4922 - accuracy: 0.7576 - val_loss: 0.4918 - val_accuracy: 0.7579\n",
      "Epoch 181/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4929 - accuracy: 0.7581 - val_loss: 0.4897 - val_accuracy: 0.7636\n",
      "Epoch 182/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4914 - accuracy: 0.7591 - val_loss: 0.4930 - val_accuracy: 0.7579\n",
      "Epoch 183/500\n",
      "2878/2878 [==============================] - 2s 816us/step - loss: 0.4883 - accuracy: 0.7614 - val_loss: 0.4893 - val_accuracy: 0.7618\n",
      "Epoch 184/500\n",
      "2878/2878 [==============================] - 2s 756us/step - loss: 0.4933 - accuracy: 0.7561 - val_loss: 0.4926 - val_accuracy: 0.7563\n",
      "Epoch 185/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4906 - accuracy: 0.7605 - val_loss: 0.4911 - val_accuracy: 0.7588\n",
      "Epoch 186/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4926 - accuracy: 0.7586 - val_loss: 0.4938 - val_accuracy: 0.7573\n",
      "Epoch 187/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4907 - accuracy: 0.7597 - val_loss: 0.4894 - val_accuracy: 0.7616\n",
      "Epoch 188/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4930 - accuracy: 0.7576 - val_loss: 0.5004 - val_accuracy: 0.7537\n",
      "Epoch 189/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4909 - accuracy: 0.7580 - val_loss: 0.4966 - val_accuracy: 0.7572\n",
      "Epoch 190/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4913 - accuracy: 0.7590 - val_loss: 0.4892 - val_accuracy: 0.7608\n",
      "Epoch 191/500\n",
      "2878/2878 [==============================] - 2s 770us/step - loss: 0.4936 - accuracy: 0.7569 - val_loss: 0.4964 - val_accuracy: 0.7583\n",
      "Epoch 192/500\n",
      "2878/2878 [==============================] - 2s 765us/step - loss: 0.4915 - accuracy: 0.7602 - val_loss: 0.4894 - val_accuracy: 0.7602\n",
      "Epoch 193/500\n",
      "2878/2878 [==============================] - 2s 747us/step - loss: 0.4908 - accuracy: 0.7602 - val_loss: 0.4907 - val_accuracy: 0.7582\n",
      "Epoch 194/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4915 - accuracy: 0.7594 - val_loss: 0.4924 - val_accuracy: 0.7599\n",
      "Epoch 195/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.4908 - accuracy: 0.7597 - val_loss: 0.4957 - val_accuracy: 0.7545\n",
      "Epoch 196/500\n",
      "2878/2878 [==============================] - 2s 791us/step - loss: 0.4915 - accuracy: 0.7582 - val_loss: 0.4912 - val_accuracy: 0.7596\n",
      "Epoch 197/500\n",
      "2878/2878 [==============================] - 2s 770us/step - loss: 0.4927 - accuracy: 0.7568 - val_loss: 0.4955 - val_accuracy: 0.7598\n",
      "Epoch 198/500\n",
      "2878/2878 [==============================] - 3s 902us/step - loss: 0.4911 - accuracy: 0.7566 - val_loss: 0.4909 - val_accuracy: 0.7611\n",
      "Epoch 199/500\n",
      "2878/2878 [==============================] - 2s 774us/step - loss: 0.4898 - accuracy: 0.7610 - val_loss: 0.4933 - val_accuracy: 0.7573\n",
      "Epoch 200/500\n",
      "2878/2878 [==============================] - 2s 762us/step - loss: 0.4879 - accuracy: 0.7590 - val_loss: 0.4988 - val_accuracy: 0.7583\n",
      "Epoch 201/500\n",
      "2878/2878 [==============================] - 2s 778us/step - loss: 0.4950 - accuracy: 0.7561 - val_loss: 0.4974 - val_accuracy: 0.7577\n",
      "Epoch 202/500\n",
      "2878/2878 [==============================] - 2s 789us/step - loss: 0.4894 - accuracy: 0.7620 - val_loss: 0.4918 - val_accuracy: 0.7570\n",
      "Epoch 203/500\n",
      "2878/2878 [==============================] - 2s 860us/step - loss: 0.4912 - accuracy: 0.7608 - val_loss: 0.4952 - val_accuracy: 0.7576\n",
      "Epoch 204/500\n",
      "2878/2878 [==============================] - 2s 850us/step - loss: 0.4897 - accuracy: 0.7595 - val_loss: 0.4905 - val_accuracy: 0.7603\n",
      "Epoch 205/500\n",
      "2878/2878 [==============================] - 2s 789us/step - loss: 0.4941 - accuracy: 0.7569 - val_loss: 0.4913 - val_accuracy: 0.7598\n",
      "Epoch 206/500\n",
      "2878/2878 [==============================] - 2s 765us/step - loss: 0.4922 - accuracy: 0.7593 - val_loss: 0.4917 - val_accuracy: 0.7595\n",
      "Epoch 207/500\n",
      "2878/2878 [==============================] - 2s 761us/step - loss: 0.4913 - accuracy: 0.7597 - val_loss: 0.4951 - val_accuracy: 0.7546\n",
      "Epoch 208/500\n",
      "2878/2878 [==============================] - 2s 786us/step - loss: 0.4904 - accuracy: 0.7604 - val_loss: 0.4951 - val_accuracy: 0.7593\n",
      "Epoch 209/500\n",
      "2878/2878 [==============================] - 2s 785us/step - loss: 0.4912 - accuracy: 0.7594 - val_loss: 0.4916 - val_accuracy: 0.7571\n",
      "Epoch 210/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.4889 - accuracy: 0.7588 - val_loss: 0.4935 - val_accuracy: 0.7579\n",
      "Epoch 211/500\n",
      "2878/2878 [==============================] - 2s 759us/step - loss: 0.4919 - accuracy: 0.7592 - val_loss: 0.4907 - val_accuracy: 0.7603\n",
      "Epoch 212/500\n",
      "2878/2878 [==============================] - 2s 768us/step - loss: 0.4909 - accuracy: 0.7594 - val_loss: 0.4899 - val_accuracy: 0.7606\n",
      "Epoch 213/500\n",
      "2878/2878 [==============================] - 2s 834us/step - loss: 0.4883 - accuracy: 0.7596 - val_loss: 0.4907 - val_accuracy: 0.7609\n",
      "Epoch 214/500\n",
      "2878/2878 [==============================] - 3s 919us/step - loss: 0.4851 - accuracy: 0.7631 - val_loss: 0.4910 - val_accuracy: 0.7585\n",
      "Epoch 215/500\n",
      "2878/2878 [==============================] - 3s 883us/step - loss: 0.4894 - accuracy: 0.7592 - val_loss: 0.4902 - val_accuracy: 0.7654\n",
      "Epoch 216/500\n",
      "2878/2878 [==============================] - 2s 809us/step - loss: 0.4878 - accuracy: 0.7611 - val_loss: 0.4920 - val_accuracy: 0.7626\n",
      "Epoch 217/500\n",
      "2878/2878 [==============================] - 2s 789us/step - loss: 0.4924 - accuracy: 0.7592 - val_loss: 0.4905 - val_accuracy: 0.7585\n",
      "Epoch 218/500\n",
      "2878/2878 [==============================] - 2s 785us/step - loss: 0.4907 - accuracy: 0.7587 - val_loss: 0.4893 - val_accuracy: 0.7625\n",
      "Epoch 219/500\n",
      "2878/2878 [==============================] - 2s 766us/step - loss: 0.4906 - accuracy: 0.7598 - val_loss: 0.5042 - val_accuracy: 0.7527\n",
      "Epoch 220/500\n",
      "2878/2878 [==============================] - 2s 797us/step - loss: 0.4889 - accuracy: 0.7609 - val_loss: 0.4878 - val_accuracy: 0.7621\n",
      "Epoch 221/500\n",
      "2878/2878 [==============================] - 2s 773us/step - loss: 0.4905 - accuracy: 0.7592 - val_loss: 0.5043 - val_accuracy: 0.7533\n",
      "Epoch 222/500\n",
      "2878/2878 [==============================] - 2s 781us/step - loss: 0.4890 - accuracy: 0.7617 - val_loss: 0.4931 - val_accuracy: 0.7574\n",
      "Epoch 223/500\n",
      "2878/2878 [==============================] - 2s 775us/step - loss: 0.4909 - accuracy: 0.7612 - val_loss: 0.4924 - val_accuracy: 0.7595\n",
      "Epoch 224/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.4907 - accuracy: 0.7610 - val_loss: 0.4906 - val_accuracy: 0.7586\n",
      "Epoch 225/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.4907 - accuracy: 0.7606 - val_loss: 0.4898 - val_accuracy: 0.7612\n",
      "Epoch 226/500\n",
      "2878/2878 [==============================] - 2s 765us/step - loss: 0.4905 - accuracy: 0.7587 - val_loss: 0.4894 - val_accuracy: 0.7652\n",
      "Epoch 227/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.4900 - accuracy: 0.7599 - val_loss: 0.4948 - val_accuracy: 0.7553\n",
      "Epoch 228/500\n",
      "2878/2878 [==============================] - 2s 781us/step - loss: 0.4880 - accuracy: 0.7586 - val_loss: 0.4944 - val_accuracy: 0.7589\n",
      "Epoch 229/500\n",
      "2878/2878 [==============================] - 2s 790us/step - loss: 0.4872 - accuracy: 0.7604 - val_loss: 0.4970 - val_accuracy: 0.7574\n",
      "Epoch 230/500\n",
      "2878/2878 [==============================] - 2s 786us/step - loss: 0.4934 - accuracy: 0.7575 - val_loss: 0.4968 - val_accuracy: 0.7547\n",
      "Epoch 231/500\n",
      "2878/2878 [==============================] - 2s 793us/step - loss: 0.4893 - accuracy: 0.7601 - val_loss: 0.4908 - val_accuracy: 0.7607\n",
      "Epoch 232/500\n",
      "2878/2878 [==============================] - 2s 777us/step - loss: 0.4889 - accuracy: 0.7614 - val_loss: 0.4904 - val_accuracy: 0.7608\n",
      "Epoch 233/500\n",
      "2878/2878 [==============================] - 2s 760us/step - loss: 0.4874 - accuracy: 0.7597 - val_loss: 0.4909 - val_accuracy: 0.7616\n",
      "Epoch 234/500\n",
      "2878/2878 [==============================] - 2s 769us/step - loss: 0.4901 - accuracy: 0.7599 - val_loss: 0.4980 - val_accuracy: 0.7536\n",
      "Epoch 235/500\n",
      "2878/2878 [==============================] - 2s 770us/step - loss: 0.4911 - accuracy: 0.7594 - val_loss: 0.4917 - val_accuracy: 0.7583\n",
      "Epoch 236/500\n",
      "2878/2878 [==============================] - 2s 770us/step - loss: 0.4893 - accuracy: 0.7607 - val_loss: 0.4984 - val_accuracy: 0.7566\n",
      "Epoch 237/500\n",
      "2878/2878 [==============================] - 2s 814us/step - loss: 0.4871 - accuracy: 0.7632 - val_loss: 0.5002 - val_accuracy: 0.7565\n",
      "Epoch 238/500\n",
      "2878/2878 [==============================] - 3s 993us/step - loss: 0.4901 - accuracy: 0.7594 - val_loss: 0.4897 - val_accuracy: 0.7612\n",
      "Epoch 239/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.4866 - accuracy: 0.7632 - val_loss: 0.4887 - val_accuracy: 0.7626\n",
      "Epoch 240/500\n",
      "2878/2878 [==============================] - 3s 921us/step - loss: 0.4909 - accuracy: 0.7582 - val_loss: 0.4940 - val_accuracy: 0.7559\n",
      "Epoch 241/500\n",
      "2878/2878 [==============================] - 3s 935us/step - loss: 0.4902 - accuracy: 0.7620 - val_loss: 0.4891 - val_accuracy: 0.7621\n",
      "Epoch 242/500\n",
      "2878/2878 [==============================] - 3s 912us/step - loss: 0.4886 - accuracy: 0.7600 - val_loss: 0.4915 - val_accuracy: 0.7612\n",
      "Epoch 243/500\n",
      "2878/2878 [==============================] - 2s 868us/step - loss: 0.4894 - accuracy: 0.7615 - val_loss: 0.4937 - val_accuracy: 0.7551\n",
      "Epoch 244/500\n",
      "2878/2878 [==============================] - 2s 825us/step - loss: 0.4911 - accuracy: 0.7607 - val_loss: 0.4896 - val_accuracy: 0.7623\n",
      "Epoch 245/500\n",
      "2878/2878 [==============================] - 3s 935us/step - loss: 0.4890 - accuracy: 0.7623 - val_loss: 0.4890 - val_accuracy: 0.7612\n",
      "Epoch 246/500\n",
      "2878/2878 [==============================] - 3s 935us/step - loss: 0.4908 - accuracy: 0.7595 - val_loss: 0.4888 - val_accuracy: 0.7638\n",
      "Epoch 247/500\n",
      "2878/2878 [==============================] - 2s 855us/step - loss: 0.4894 - accuracy: 0.7612 - val_loss: 0.4907 - val_accuracy: 0.7638\n",
      "Epoch 248/500\n",
      "2878/2878 [==============================] - 3s 886us/step - loss: 0.4913 - accuracy: 0.7599 - val_loss: 0.4946 - val_accuracy: 0.7604\n",
      "Epoch 249/500\n",
      "2878/2878 [==============================] - 2s 863us/step - loss: 0.4874 - accuracy: 0.7625 - val_loss: 0.4882 - val_accuracy: 0.7647\n",
      "Epoch 250/500\n",
      "2878/2878 [==============================] - 2s 839us/step - loss: 0.4900 - accuracy: 0.7587 - val_loss: 0.4894 - val_accuracy: 0.7636\n",
      "Epoch 251/500\n",
      "2878/2878 [==============================] - 2s 793us/step - loss: 0.4902 - accuracy: 0.7587 - val_loss: 0.4906 - val_accuracy: 0.7625\n",
      "Epoch 252/500\n",
      "2878/2878 [==============================] - 2s 796us/step - loss: 0.4844 - accuracy: 0.7613 - val_loss: 0.4900 - val_accuracy: 0.7621\n",
      "Epoch 253/500\n",
      "2878/2878 [==============================] - 2s 797us/step - loss: 0.4902 - accuracy: 0.7598 - val_loss: 0.4895 - val_accuracy: 0.7624\n",
      "Epoch 254/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4870 - accuracy: 0.7612 - val_loss: 0.4932 - val_accuracy: 0.7598\n",
      "Epoch 255/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.4857 - accuracy: 0.7628 - val_loss: 0.4894 - val_accuracy: 0.7622\n",
      "Epoch 256/500\n",
      "2878/2878 [==============================] - 2s 786us/step - loss: 0.4916 - accuracy: 0.7585 - val_loss: 0.4927 - val_accuracy: 0.7584\n",
      "Epoch 257/500\n",
      "2878/2878 [==============================] - 2s 745us/step - loss: 0.4875 - accuracy: 0.7599 - val_loss: 0.4899 - val_accuracy: 0.7626\n",
      "Epoch 258/500\n",
      "2878/2878 [==============================] - 2s 768us/step - loss: 0.4865 - accuracy: 0.7638 - val_loss: 0.4923 - val_accuracy: 0.7581\n",
      "Epoch 259/500\n",
      "2878/2878 [==============================] - 2s 853us/step - loss: 0.4922 - accuracy: 0.7593 - val_loss: 0.4897 - val_accuracy: 0.7619\n",
      "Epoch 260/500\n",
      "2878/2878 [==============================] - 2s 791us/step - loss: 0.4866 - accuracy: 0.7624 - val_loss: 0.4948 - val_accuracy: 0.7589\n",
      "Epoch 261/500\n",
      "2878/2878 [==============================] - 2s 819us/step - loss: 0.4910 - accuracy: 0.7604 - val_loss: 0.4882 - val_accuracy: 0.7609\n",
      "Epoch 262/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.4889 - accuracy: 0.7601 - val_loss: 0.4901 - val_accuracy: 0.7615\n",
      "Epoch 263/500\n",
      "2878/2878 [==============================] - 2s 846us/step - loss: 0.4918 - accuracy: 0.7601 - val_loss: 0.4921 - val_accuracy: 0.7582\n",
      "Epoch 264/500\n",
      "2878/2878 [==============================] - 2s 867us/step - loss: 0.4890 - accuracy: 0.7619 - val_loss: 0.4884 - val_accuracy: 0.7623\n",
      "Epoch 265/500\n",
      "2878/2878 [==============================] - 2s 853us/step - loss: 0.4873 - accuracy: 0.7617 - val_loss: 0.4895 - val_accuracy: 0.7596\n",
      "Epoch 266/500\n",
      "2878/2878 [==============================] - 3s 963us/step - loss: 0.4946 - accuracy: 0.7580 - val_loss: 0.4970 - val_accuracy: 0.7545\n",
      "Epoch 267/500\n",
      "2878/2878 [==============================] - 3s 908us/step - loss: 0.4862 - accuracy: 0.7633 - val_loss: 0.4910 - val_accuracy: 0.7624\n",
      "Epoch 268/500\n",
      "2878/2878 [==============================] - 2s 828us/step - loss: 0.4905 - accuracy: 0.7604 - val_loss: 0.4917 - val_accuracy: 0.7606\n",
      "Epoch 269/500\n",
      "2878/2878 [==============================] - 3s 879us/step - loss: 0.4891 - accuracy: 0.7610 - val_loss: 0.4935 - val_accuracy: 0.7587\n",
      "Epoch 270/500\n",
      "2878/2878 [==============================] - 3s 929us/step - loss: 0.4875 - accuracy: 0.7611 - val_loss: 0.4987 - val_accuracy: 0.7571\n",
      "Epoch 271/500\n",
      "2878/2878 [==============================] - 2s 845us/step - loss: 0.4868 - accuracy: 0.7619 - val_loss: 0.4946 - val_accuracy: 0.7573\n",
      "Epoch 272/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4878 - accuracy: 0.7613 - val_loss: 0.4900 - val_accuracy: 0.7624\n",
      "Epoch 273/500\n",
      "2878/2878 [==============================] - 2s 779us/step - loss: 0.4899 - accuracy: 0.7597 - val_loss: 0.4885 - val_accuracy: 0.7644\n",
      "Epoch 274/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.4883 - accuracy: 0.7623 - val_loss: 0.4860 - val_accuracy: 0.7622\n",
      "Epoch 275/500\n",
      "2878/2878 [==============================] - 2s 803us/step - loss: 0.4882 - accuracy: 0.7609 - val_loss: 0.4883 - val_accuracy: 0.7621\n",
      "Epoch 276/500\n",
      "2878/2878 [==============================] - 2s 836us/step - loss: 0.4894 - accuracy: 0.7617 - val_loss: 0.4873 - val_accuracy: 0.7637\n",
      "Epoch 277/500\n",
      "2878/2878 [==============================] - 2s 829us/step - loss: 0.4895 - accuracy: 0.7600 - val_loss: 0.5018 - val_accuracy: 0.7551\n",
      "Epoch 278/500\n",
      "2878/2878 [==============================] - 2s 860us/step - loss: 0.4894 - accuracy: 0.7612 - val_loss: 0.4911 - val_accuracy: 0.7613\n",
      "Epoch 279/500\n",
      "2878/2878 [==============================] - 3s 910us/step - loss: 0.4888 - accuracy: 0.7610 - val_loss: 0.4891 - val_accuracy: 0.7618\n",
      "Epoch 280/500\n",
      "2878/2878 [==============================] - 2s 834us/step - loss: 0.4859 - accuracy: 0.7620 - val_loss: 0.5042 - val_accuracy: 0.7497\n",
      "Epoch 281/500\n",
      "2878/2878 [==============================] - 2s 775us/step - loss: 0.4877 - accuracy: 0.7619 - val_loss: 0.4939 - val_accuracy: 0.7589\n",
      "Epoch 282/500\n",
      "2878/2878 [==============================] - 2s 803us/step - loss: 0.4890 - accuracy: 0.7623 - val_loss: 0.4933 - val_accuracy: 0.7581\n",
      "Epoch 283/500\n",
      "2878/2878 [==============================] - 3s 898us/step - loss: 0.4892 - accuracy: 0.7618 - val_loss: 0.4926 - val_accuracy: 0.7610\n",
      "Epoch 284/500\n",
      "2878/2878 [==============================] - 2s 862us/step - loss: 0.4914 - accuracy: 0.7614 - val_loss: 0.4918 - val_accuracy: 0.7602\n",
      "Epoch 285/500\n",
      "2878/2878 [==============================] - 3s 919us/step - loss: 0.4856 - accuracy: 0.7631 - val_loss: 0.4953 - val_accuracy: 0.7548\n",
      "Epoch 286/500\n",
      "2878/2878 [==============================] - 2s 788us/step - loss: 0.4864 - accuracy: 0.7622 - val_loss: 0.4900 - val_accuracy: 0.7628\n",
      "Epoch 287/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4907 - accuracy: 0.7602 - val_loss: 0.4909 - val_accuracy: 0.7591\n",
      "Epoch 288/500\n",
      "2878/2878 [==============================] - 2s 760us/step - loss: 0.4902 - accuracy: 0.7612 - val_loss: 0.4889 - val_accuracy: 0.7618\n",
      "Epoch 289/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.4896 - accuracy: 0.7597 - val_loss: 0.4936 - val_accuracy: 0.7543\n",
      "Epoch 290/500\n",
      "2878/2878 [==============================] - 2s 806us/step - loss: 0.4896 - accuracy: 0.7595 - val_loss: 0.4946 - val_accuracy: 0.7591\n",
      "Epoch 291/500\n",
      "2878/2878 [==============================] - 2s 794us/step - loss: 0.4899 - accuracy: 0.7612 - val_loss: 0.4931 - val_accuracy: 0.7578\n",
      "Epoch 292/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.4880 - accuracy: 0.7627 - val_loss: 0.4894 - val_accuracy: 0.7593\n",
      "Epoch 293/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4877 - accuracy: 0.7611 - val_loss: 0.4859 - val_accuracy: 0.7627\n",
      "Epoch 294/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.4894 - accuracy: 0.7619 - val_loss: 0.5043 - val_accuracy: 0.7488\n",
      "Epoch 295/500\n",
      "2878/2878 [==============================] - 2s 763us/step - loss: 0.4864 - accuracy: 0.7629 - val_loss: 0.4925 - val_accuracy: 0.7603\n",
      "Epoch 296/500\n",
      "2878/2878 [==============================] - 2s 824us/step - loss: 0.4848 - accuracy: 0.7624 - val_loss: 0.4903 - val_accuracy: 0.7591\n",
      "Epoch 297/500\n",
      "2878/2878 [==============================] - 2s 825us/step - loss: 0.4878 - accuracy: 0.7598 - val_loss: 0.4891 - val_accuracy: 0.7630\n",
      "Epoch 298/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4895 - accuracy: 0.7601 - val_loss: 0.4876 - val_accuracy: 0.7623\n",
      "Epoch 299/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4897 - accuracy: 0.7610 - val_loss: 0.4918 - val_accuracy: 0.7588\n",
      "Epoch 300/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4915 - accuracy: 0.7576 - val_loss: 0.4894 - val_accuracy: 0.7627\n",
      "Epoch 301/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.4881 - accuracy: 0.7624 - val_loss: 0.4878 - val_accuracy: 0.7612\n",
      "Epoch 302/500\n",
      "2878/2878 [==============================] - 2s 785us/step - loss: 0.4909 - accuracy: 0.7593 - val_loss: 0.4960 - val_accuracy: 0.7586\n",
      "Epoch 303/500\n",
      "2878/2878 [==============================] - 3s 891us/step - loss: 0.4862 - accuracy: 0.7635 - val_loss: 0.4913 - val_accuracy: 0.7602\n",
      "Epoch 304/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.4882 - accuracy: 0.7593 - val_loss: 0.4870 - val_accuracy: 0.7619\n",
      "Epoch 305/500\n",
      "2878/2878 [==============================] - 3s 962us/step - loss: 0.4881 - accuracy: 0.7614 - val_loss: 0.4931 - val_accuracy: 0.7626\n",
      "Epoch 306/500\n",
      "2878/2878 [==============================] - 2s 819us/step - loss: 0.4884 - accuracy: 0.7615 - val_loss: 0.4892 - val_accuracy: 0.7634\n",
      "Epoch 307/500\n",
      "2878/2878 [==============================] - 2s 788us/step - loss: 0.4871 - accuracy: 0.7635 - val_loss: 0.4920 - val_accuracy: 0.7577\n",
      "Epoch 308/500\n",
      "2878/2878 [==============================] - 2s 767us/step - loss: 0.4885 - accuracy: 0.7608 - val_loss: 0.4846 - val_accuracy: 0.7643\n",
      "Epoch 309/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.4904 - accuracy: 0.7610 - val_loss: 0.4970 - val_accuracy: 0.7572\n",
      "Epoch 310/500\n",
      "2878/2878 [==============================] - 2s 803us/step - loss: 0.4874 - accuracy: 0.7606 - val_loss: 0.4893 - val_accuracy: 0.7635\n",
      "Epoch 311/500\n",
      "2878/2878 [==============================] - 2s 801us/step - loss: 0.4885 - accuracy: 0.7610 - val_loss: 0.4883 - val_accuracy: 0.7629\n",
      "Epoch 312/500\n",
      "2878/2878 [==============================] - 2s 766us/step - loss: 0.4883 - accuracy: 0.7626 - val_loss: 0.4856 - val_accuracy: 0.7621\n",
      "Epoch 313/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.4869 - accuracy: 0.7605 - val_loss: 0.4873 - val_accuracy: 0.7646\n",
      "Epoch 314/500\n",
      "2878/2878 [==============================] - 2s 769us/step - loss: 0.4873 - accuracy: 0.7627 - val_loss: 0.4871 - val_accuracy: 0.7637\n",
      "Epoch 315/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4877 - accuracy: 0.7625 - val_loss: 0.4864 - val_accuracy: 0.7664\n",
      "Epoch 316/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4872 - accuracy: 0.7622 - val_loss: 0.4875 - val_accuracy: 0.7649\n",
      "Epoch 317/500\n",
      "2878/2878 [==============================] - 2s 747us/step - loss: 0.4855 - accuracy: 0.7647 - val_loss: 0.4865 - val_accuracy: 0.7649\n",
      "Epoch 318/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.4859 - accuracy: 0.7621 - val_loss: 0.4882 - val_accuracy: 0.7628\n",
      "Epoch 319/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4875 - accuracy: 0.7613 - val_loss: 0.4894 - val_accuracy: 0.7618\n",
      "Epoch 320/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4899 - accuracy: 0.7598 - val_loss: 0.4884 - val_accuracy: 0.7596\n",
      "Epoch 321/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.4884 - accuracy: 0.7616 - val_loss: 0.4856 - val_accuracy: 0.7662\n",
      "Epoch 322/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.4870 - accuracy: 0.7627 - val_loss: 0.4885 - val_accuracy: 0.7616\n",
      "Epoch 323/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4863 - accuracy: 0.7618 - val_loss: 0.4862 - val_accuracy: 0.7629\n",
      "Epoch 324/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.4854 - accuracy: 0.7636 - val_loss: 0.4887 - val_accuracy: 0.7629\n",
      "Epoch 325/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.4866 - accuracy: 0.7640 - val_loss: 0.4882 - val_accuracy: 0.7626\n",
      "Epoch 326/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4884 - accuracy: 0.7615 - val_loss: 0.4900 - val_accuracy: 0.7616\n",
      "Epoch 327/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.4899 - accuracy: 0.7604 - val_loss: 0.4871 - val_accuracy: 0.7623\n",
      "Epoch 328/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4891 - accuracy: 0.7617 - val_loss: 0.4891 - val_accuracy: 0.7619\n",
      "Epoch 329/500\n",
      "2878/2878 [==============================] - 2s 791us/step - loss: 0.4858 - accuracy: 0.7651 - val_loss: 0.4945 - val_accuracy: 0.7556\n",
      "Epoch 330/500\n",
      "2878/2878 [==============================] - 2s 782us/step - loss: 0.4884 - accuracy: 0.7609 - val_loss: 0.4882 - val_accuracy: 0.7639\n",
      "Epoch 331/500\n",
      "2878/2878 [==============================] - 2s 834us/step - loss: 0.4889 - accuracy: 0.7620 - val_loss: 0.4918 - val_accuracy: 0.7609\n",
      "Epoch 332/500\n",
      "2878/2878 [==============================] - 2s 803us/step - loss: 0.4884 - accuracy: 0.7615 - val_loss: 0.4892 - val_accuracy: 0.7607\n",
      "Epoch 333/500\n",
      "2878/2878 [==============================] - 2s 803us/step - loss: 0.4907 - accuracy: 0.7604 - val_loss: 0.4884 - val_accuracy: 0.7594\n",
      "Epoch 334/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4884 - accuracy: 0.7607 - val_loss: 0.4930 - val_accuracy: 0.7589\n",
      "Epoch 335/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.4852 - accuracy: 0.7642 - val_loss: 0.4875 - val_accuracy: 0.7624\n",
      "Epoch 336/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.4881 - accuracy: 0.7611 - val_loss: 0.4879 - val_accuracy: 0.7593\n",
      "Epoch 337/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.4855 - accuracy: 0.7631 - val_loss: 0.4892 - val_accuracy: 0.7632\n",
      "Epoch 338/500\n",
      "2878/2878 [==============================] - 2s 765us/step - loss: 0.4870 - accuracy: 0.7612 - val_loss: 0.4881 - val_accuracy: 0.7670\n",
      "Epoch 339/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.4862 - accuracy: 0.7634 - val_loss: 0.4884 - val_accuracy: 0.7652\n",
      "Epoch 340/500\n",
      "2878/2878 [==============================] - 2s 765us/step - loss: 0.4883 - accuracy: 0.7625 - val_loss: 0.4927 - val_accuracy: 0.7581\n",
      "Epoch 341/500\n",
      "2878/2878 [==============================] - 2s 856us/step - loss: 0.4880 - accuracy: 0.7601 - val_loss: 0.4852 - val_accuracy: 0.7652\n",
      "Epoch 342/500\n",
      "2878/2878 [==============================] - 2s 804us/step - loss: 0.4850 - accuracy: 0.7644 - val_loss: 0.4957 - val_accuracy: 0.7569\n",
      "Epoch 343/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4869 - accuracy: 0.7646 - val_loss: 0.4884 - val_accuracy: 0.7626\n",
      "Epoch 344/500\n",
      "2878/2878 [==============================] - 2s 767us/step - loss: 0.4865 - accuracy: 0.7636 - val_loss: 0.4930 - val_accuracy: 0.7559\n",
      "Epoch 345/500\n",
      "2878/2878 [==============================] - 2s 769us/step - loss: 0.4864 - accuracy: 0.7623 - val_loss: 0.4868 - val_accuracy: 0.7639\n",
      "Epoch 346/500\n",
      "2878/2878 [==============================] - 2s 754us/step - loss: 0.4877 - accuracy: 0.7629 - val_loss: 0.4887 - val_accuracy: 0.7613\n",
      "Epoch 347/500\n",
      "2878/2878 [==============================] - 2s 754us/step - loss: 0.4890 - accuracy: 0.7615 - val_loss: 0.4908 - val_accuracy: 0.7626\n",
      "Epoch 348/500\n",
      "2878/2878 [==============================] - 2s 786us/step - loss: 0.4851 - accuracy: 0.7633 - val_loss: 0.4861 - val_accuracy: 0.7663\n",
      "Epoch 349/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4839 - accuracy: 0.7637 - val_loss: 0.4917 - val_accuracy: 0.7576\n",
      "Epoch 350/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4870 - accuracy: 0.7602 - val_loss: 0.4886 - val_accuracy: 0.7616\n",
      "Epoch 351/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4845 - accuracy: 0.7653 - val_loss: 0.4932 - val_accuracy: 0.7603\n",
      "Epoch 352/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4877 - accuracy: 0.7613 - val_loss: 0.4891 - val_accuracy: 0.7594\n",
      "Epoch 353/500\n",
      "2878/2878 [==============================] - 2s 753us/step - loss: 0.4855 - accuracy: 0.7631 - val_loss: 0.4863 - val_accuracy: 0.7652\n",
      "Epoch 354/500\n",
      "2878/2878 [==============================] - 2s 772us/step - loss: 0.4842 - accuracy: 0.7641 - val_loss: 0.4889 - val_accuracy: 0.7630\n",
      "Epoch 355/500\n",
      "2878/2878 [==============================] - 2s 806us/step - loss: 0.4871 - accuracy: 0.7622 - val_loss: 0.4851 - val_accuracy: 0.7649\n",
      "Epoch 356/500\n",
      "2878/2878 [==============================] - 2s 745us/step - loss: 0.4867 - accuracy: 0.7635 - val_loss: 0.4871 - val_accuracy: 0.7645\n",
      "Epoch 357/500\n",
      "2878/2878 [==============================] - 2s 763us/step - loss: 0.4879 - accuracy: 0.7643 - val_loss: 0.4907 - val_accuracy: 0.7616\n",
      "Epoch 358/500\n",
      "2878/2878 [==============================] - 2s 811us/step - loss: 0.4870 - accuracy: 0.7644 - val_loss: 0.4893 - val_accuracy: 0.7607\n",
      "Epoch 359/500\n",
      "2878/2878 [==============================] - 2s 755us/step - loss: 0.4886 - accuracy: 0.7629 - val_loss: 0.4897 - val_accuracy: 0.7626\n",
      "Epoch 360/500\n",
      "2878/2878 [==============================] - 2s 765us/step - loss: 0.4865 - accuracy: 0.7639 - val_loss: 0.4932 - val_accuracy: 0.7586\n",
      "Epoch 361/500\n",
      "2878/2878 [==============================] - 2s 812us/step - loss: 0.4864 - accuracy: 0.7610 - val_loss: 0.4895 - val_accuracy: 0.7602\n",
      "Epoch 362/500\n",
      "2878/2878 [==============================] - 2s 796us/step - loss: 0.4848 - accuracy: 0.7651 - val_loss: 0.4877 - val_accuracy: 0.7647\n",
      "Epoch 363/500\n",
      "2878/2878 [==============================] - 2s 772us/step - loss: 0.4879 - accuracy: 0.7618 - val_loss: 0.4894 - val_accuracy: 0.7622\n",
      "Epoch 364/500\n",
      "2878/2878 [==============================] - 2s 781us/step - loss: 0.4870 - accuracy: 0.7617 - val_loss: 0.4920 - val_accuracy: 0.7605\n",
      "Epoch 365/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.4914 - accuracy: 0.7585 - val_loss: 0.4904 - val_accuracy: 0.7579\n",
      "Epoch 366/500\n",
      "2878/2878 [==============================] - 2s 786us/step - loss: 0.4860 - accuracy: 0.7634 - val_loss: 0.4880 - val_accuracy: 0.7634\n",
      "Epoch 367/500\n",
      "2878/2878 [==============================] - 2s 791us/step - loss: 0.4847 - accuracy: 0.7650 - val_loss: 0.4859 - val_accuracy: 0.7629\n",
      "Epoch 368/500\n",
      "2878/2878 [==============================] - 3s 876us/step - loss: 0.4870 - accuracy: 0.7618 - val_loss: 0.4929 - val_accuracy: 0.7615\n",
      "Epoch 369/500\n",
      "2878/2878 [==============================] - 2s 840us/step - loss: 0.4876 - accuracy: 0.7602 - val_loss: 0.4915 - val_accuracy: 0.7568\n",
      "Epoch 370/500\n",
      "2878/2878 [==============================] - 2s 838us/step - loss: 0.4861 - accuracy: 0.7641 - val_loss: 0.4903 - val_accuracy: 0.7606\n",
      "Epoch 371/500\n",
      "2878/2878 [==============================] - 2s 783us/step - loss: 0.4890 - accuracy: 0.7598 - val_loss: 0.4860 - val_accuracy: 0.7623\n",
      "Epoch 372/500\n",
      "2878/2878 [==============================] - 2s 828us/step - loss: 0.4874 - accuracy: 0.7636 - val_loss: 0.4930 - val_accuracy: 0.7591\n",
      "Epoch 373/500\n",
      "2878/2878 [==============================] - 3s 870us/step - loss: 0.4876 - accuracy: 0.7618 - val_loss: 0.4873 - val_accuracy: 0.7652\n",
      "Epoch 374/500\n",
      "2878/2878 [==============================] - 2s 833us/step - loss: 0.4883 - accuracy: 0.7606 - val_loss: 0.4842 - val_accuracy: 0.7638\n",
      "Epoch 375/500\n",
      "2878/2878 [==============================] - 2s 814us/step - loss: 0.4857 - accuracy: 0.7639 - val_loss: 0.4878 - val_accuracy: 0.7629\n",
      "Epoch 376/500\n",
      "2878/2878 [==============================] - 2s 787us/step - loss: 0.4847 - accuracy: 0.7632 - val_loss: 0.4861 - val_accuracy: 0.7657\n",
      "Epoch 377/500\n",
      "2878/2878 [==============================] - 2s 823us/step - loss: 0.4861 - accuracy: 0.7630 - val_loss: 0.4917 - val_accuracy: 0.7588\n",
      "Epoch 378/500\n",
      "2878/2878 [==============================] - 2s 821us/step - loss: 0.4859 - accuracy: 0.7645 - val_loss: 0.4873 - val_accuracy: 0.7609\n",
      "Epoch 379/500\n",
      "2878/2878 [==============================] - 2s 761us/step - loss: 0.4817 - accuracy: 0.7667 - val_loss: 0.4900 - val_accuracy: 0.7609\n",
      "Epoch 380/500\n",
      "2878/2878 [==============================] - 2s 745us/step - loss: 0.4876 - accuracy: 0.7631 - val_loss: 0.4946 - val_accuracy: 0.7586\n",
      "Epoch 381/500\n",
      "2878/2878 [==============================] - 2s 753us/step - loss: 0.4861 - accuracy: 0.7622 - val_loss: 0.4897 - val_accuracy: 0.7586\n",
      "Epoch 382/500\n",
      "2878/2878 [==============================] - 2s 778us/step - loss: 0.4854 - accuracy: 0.7639 - val_loss: 0.4873 - val_accuracy: 0.7619\n",
      "Epoch 383/500\n",
      "2878/2878 [==============================] - 3s 916us/step - loss: 0.4853 - accuracy: 0.7634 - val_loss: 0.4872 - val_accuracy: 0.7651\n",
      "Epoch 384/500\n",
      "2878/2878 [==============================] - 2s 756us/step - loss: 0.4854 - accuracy: 0.7638 - val_loss: 0.4938 - val_accuracy: 0.7557\n",
      "Epoch 385/500\n",
      "2878/2878 [==============================] - 2s 773us/step - loss: 0.4886 - accuracy: 0.7620 - val_loss: 0.4880 - val_accuracy: 0.7624\n",
      "Epoch 386/500\n",
      "2878/2878 [==============================] - 2s 773us/step - loss: 0.4872 - accuracy: 0.7616 - val_loss: 0.4883 - val_accuracy: 0.7631\n",
      "Epoch 387/500\n",
      "2878/2878 [==============================] - 2s 777us/step - loss: 0.4862 - accuracy: 0.7639 - val_loss: 0.4854 - val_accuracy: 0.7639\n",
      "Epoch 388/500\n",
      "2878/2878 [==============================] - 2s 776us/step - loss: 0.4868 - accuracy: 0.7612 - val_loss: 0.4870 - val_accuracy: 0.7639\n",
      "Epoch 389/500\n",
      "2878/2878 [==============================] - 2s 764us/step - loss: 0.4887 - accuracy: 0.7605 - val_loss: 0.4892 - val_accuracy: 0.7651\n",
      "Epoch 390/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4864 - accuracy: 0.7647 - val_loss: 0.4930 - val_accuracy: 0.7559\n",
      "Epoch 391/500\n",
      "2878/2878 [==============================] - 2s 803us/step - loss: 0.4854 - accuracy: 0.7652 - val_loss: 0.4911 - val_accuracy: 0.7619\n",
      "Epoch 392/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4854 - accuracy: 0.7638 - val_loss: 0.4851 - val_accuracy: 0.7659\n",
      "Epoch 393/500\n",
      "2878/2878 [==============================] - 2s 857us/step - loss: 0.4878 - accuracy: 0.7610 - val_loss: 0.4890 - val_accuracy: 0.7629\n",
      "Epoch 394/500\n",
      "2878/2878 [==============================] - 2s 840us/step - loss: 0.4897 - accuracy: 0.7604 - val_loss: 0.4902 - val_accuracy: 0.7606\n",
      "Epoch 395/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.4840 - accuracy: 0.7647 - val_loss: 0.5003 - val_accuracy: 0.7579\n",
      "Epoch 396/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.4869 - accuracy: 0.7636 - val_loss: 0.4870 - val_accuracy: 0.7669\n",
      "Epoch 397/500\n",
      "2878/2878 [==============================] - 2s 811us/step - loss: 0.4847 - accuracy: 0.7641 - val_loss: 0.4912 - val_accuracy: 0.7573\n",
      "Epoch 398/500\n",
      "2878/2878 [==============================] - 2s 830us/step - loss: 0.4869 - accuracy: 0.7630 - val_loss: 0.4971 - val_accuracy: 0.7556\n",
      "Epoch 399/500\n",
      "2878/2878 [==============================] - 2s 797us/step - loss: 0.4887 - accuracy: 0.7623 - val_loss: 0.4866 - val_accuracy: 0.7662\n",
      "Epoch 400/500\n",
      "2878/2878 [==============================] - 2s 770us/step - loss: 0.4883 - accuracy: 0.7615 - val_loss: 0.4871 - val_accuracy: 0.7617\n",
      "Epoch 401/500\n",
      "2878/2878 [==============================] - 2s 804us/step - loss: 0.4857 - accuracy: 0.7643 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 402/500\n",
      "2878/2878 [==============================] - 2s 810us/step - loss: 0.4843 - accuracy: 0.7641 - val_loss: 0.4935 - val_accuracy: 0.7632\n",
      "Epoch 403/500\n",
      "2878/2878 [==============================] - 2s 808us/step - loss: 0.4878 - accuracy: 0.7610 - val_loss: 0.4855 - val_accuracy: 0.7649\n",
      "Epoch 404/500\n",
      "2878/2878 [==============================] - 2s 824us/step - loss: 0.4862 - accuracy: 0.7635 - val_loss: 0.4882 - val_accuracy: 0.7651\n",
      "Epoch 405/500\n",
      "2878/2878 [==============================] - 2s 849us/step - loss: 0.4887 - accuracy: 0.7621 - val_loss: 0.4839 - val_accuracy: 0.7655\n",
      "Epoch 406/500\n",
      "2878/2878 [==============================] - 3s 877us/step - loss: 0.4874 - accuracy: 0.7616 - val_loss: 0.4862 - val_accuracy: 0.7638\n",
      "Epoch 407/500\n",
      "2878/2878 [==============================] - 2s 796us/step - loss: 0.4840 - accuracy: 0.7638 - val_loss: 0.4878 - val_accuracy: 0.7637\n",
      "Epoch 408/500\n",
      "2878/2878 [==============================] - 2s 770us/step - loss: 0.4871 - accuracy: 0.7640 - val_loss: 0.4864 - val_accuracy: 0.7624\n",
      "Epoch 409/500\n",
      "2878/2878 [==============================] - 2s 816us/step - loss: 0.4867 - accuracy: 0.7623 - val_loss: 0.4874 - val_accuracy: 0.7633\n",
      "Epoch 410/500\n",
      "2878/2878 [==============================] - 3s 924us/step - loss: 0.4868 - accuracy: 0.7617 - val_loss: 0.4831 - val_accuracy: 0.7663\n",
      "Epoch 411/500\n",
      "2878/2878 [==============================] - 2s 817us/step - loss: 0.4870 - accuracy: 0.7636 - val_loss: 0.4856 - val_accuracy: 0.7630\n",
      "Epoch 412/500\n",
      "2878/2878 [==============================] - 2s 814us/step - loss: 0.4834 - accuracy: 0.7654 - val_loss: 0.4937 - val_accuracy: 0.7569\n",
      "Epoch 413/500\n",
      "2878/2878 [==============================] - 2s 815us/step - loss: 0.4852 - accuracy: 0.7630 - val_loss: 0.4854 - val_accuracy: 0.7652\n",
      "Epoch 414/500\n",
      "2878/2878 [==============================] - 2s 839us/step - loss: 0.4848 - accuracy: 0.7657 - val_loss: 0.4902 - val_accuracy: 0.7616\n",
      "Epoch 415/500\n",
      "2878/2878 [==============================] - 2s 799us/step - loss: 0.4870 - accuracy: 0.7606 - val_loss: 0.4882 - val_accuracy: 0.7640\n",
      "Epoch 416/500\n",
      "2878/2878 [==============================] - 2s 782us/step - loss: 0.4867 - accuracy: 0.7616 - val_loss: 0.4893 - val_accuracy: 0.7616\n",
      "Epoch 417/500\n",
      "2878/2878 [==============================] - 2s 820us/step - loss: 0.4868 - accuracy: 0.7634 - val_loss: 0.4887 - val_accuracy: 0.7606\n",
      "Epoch 418/500\n",
      "2878/2878 [==============================] - 2s 835us/step - loss: 0.4858 - accuracy: 0.7628 - val_loss: 0.4846 - val_accuracy: 0.7648\n",
      "Epoch 419/500\n",
      "2878/2878 [==============================] - 2s 843us/step - loss: 0.4874 - accuracy: 0.7634 - val_loss: 0.4894 - val_accuracy: 0.7621\n",
      "Epoch 420/500\n",
      "2878/2878 [==============================] - 2s 850us/step - loss: 0.4848 - accuracy: 0.7636 - val_loss: 0.4900 - val_accuracy: 0.7626\n",
      "Epoch 421/500\n",
      "2878/2878 [==============================] - 3s 958us/step - loss: 0.4868 - accuracy: 0.7625 - val_loss: 0.4870 - val_accuracy: 0.7621\n",
      "Epoch 422/500\n",
      "2878/2878 [==============================] - 4s 1ms/step - loss: 0.4865 - accuracy: 0.7647 - val_loss: 0.4926 - val_accuracy: 0.7625\n",
      "Epoch 423/500\n",
      "2878/2878 [==============================] - 4s 1ms/step - loss: 0.4842 - accuracy: 0.7650 - val_loss: 0.4868 - val_accuracy: 0.7633\n",
      "Epoch 424/500\n",
      "2878/2878 [==============================] - 2s 818us/step - loss: 0.4856 - accuracy: 0.7653 - val_loss: 0.4967 - val_accuracy: 0.7577\n",
      "Epoch 425/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.4860 - accuracy: 0.7624 - val_loss: 0.4912 - val_accuracy: 0.7593\n",
      "Epoch 426/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.4891 - accuracy: 0.7610 - val_loss: 0.4891 - val_accuracy: 0.7595\n",
      "Epoch 427/500\n",
      "2878/2878 [==============================] - 2s 795us/step - loss: 0.4876 - accuracy: 0.7629 - val_loss: 0.4921 - val_accuracy: 0.7593\n",
      "Epoch 428/500\n",
      "2878/2878 [==============================] - 2s 868us/step - loss: 0.4878 - accuracy: 0.7612 - val_loss: 0.4886 - val_accuracy: 0.7595\n",
      "Epoch 429/500\n",
      "2878/2878 [==============================] - 2s 857us/step - loss: 0.4875 - accuracy: 0.7617 - val_loss: 0.4853 - val_accuracy: 0.7624\n",
      "Epoch 430/500\n",
      "2878/2878 [==============================] - 2s 842us/step - loss: 0.4838 - accuracy: 0.7640 - val_loss: 0.4861 - val_accuracy: 0.7652\n",
      "Epoch 431/500\n",
      "2878/2878 [==============================] - 2s 849us/step - loss: 0.4864 - accuracy: 0.7618 - val_loss: 0.4836 - val_accuracy: 0.7645\n",
      "Epoch 432/500\n",
      "2878/2878 [==============================] - 3s 870us/step - loss: 0.4870 - accuracy: 0.7630 - val_loss: 0.4879 - val_accuracy: 0.7627\n",
      "Epoch 433/500\n",
      "2878/2878 [==============================] - 2s 864us/step - loss: 0.4827 - accuracy: 0.7644 - val_loss: 0.4933 - val_accuracy: 0.7590\n",
      "Epoch 434/500\n",
      "2878/2878 [==============================] - 3s 872us/step - loss: 0.4866 - accuracy: 0.7600 - val_loss: 0.4901 - val_accuracy: 0.7598\n",
      "Epoch 435/500\n",
      "2878/2878 [==============================] - 3s 882us/step - loss: 0.4876 - accuracy: 0.7610 - val_loss: 0.4893 - val_accuracy: 0.7640\n",
      "Epoch 436/500\n",
      "2878/2878 [==============================] - 2s 815us/step - loss: 0.4834 - accuracy: 0.7650 - val_loss: 0.4871 - val_accuracy: 0.7631\n",
      "Epoch 437/500\n",
      "2878/2878 [==============================] - 2s 814us/step - loss: 0.4876 - accuracy: 0.7622 - val_loss: 0.4883 - val_accuracy: 0.7623\n",
      "Epoch 438/500\n",
      "2878/2878 [==============================] - 3s 886us/step - loss: 0.4848 - accuracy: 0.7637 - val_loss: 0.4883 - val_accuracy: 0.7617\n",
      "Epoch 439/500\n",
      "2878/2878 [==============================] - 2s 839us/step - loss: 0.4842 - accuracy: 0.7645 - val_loss: 0.4951 - val_accuracy: 0.7544\n",
      "Epoch 440/500\n",
      "2878/2878 [==============================] - 3s 957us/step - loss: 0.4844 - accuracy: 0.7653 - val_loss: 0.4926 - val_accuracy: 0.7619\n",
      "Epoch 441/500\n",
      "2878/2878 [==============================] - 3s 886us/step - loss: 0.4852 - accuracy: 0.7634 - val_loss: 0.4921 - val_accuracy: 0.7602\n",
      "Epoch 442/500\n",
      "2878/2878 [==============================] - 2s 852us/step - loss: 0.4894 - accuracy: 0.7615 - val_loss: 0.4904 - val_accuracy: 0.7589\n",
      "Epoch 443/500\n",
      "2878/2878 [==============================] - 3s 883us/step - loss: 0.4873 - accuracy: 0.7617 - val_loss: 0.4853 - val_accuracy: 0.7655\n",
      "Epoch 444/500\n",
      "2878/2878 [==============================] - 2s 803us/step - loss: 0.4863 - accuracy: 0.7625 - val_loss: 0.4902 - val_accuracy: 0.7606\n",
      "Epoch 445/500\n",
      "2878/2878 [==============================] - 3s 896us/step - loss: 0.4841 - accuracy: 0.7631 - val_loss: 0.4853 - val_accuracy: 0.7646\n",
      "Epoch 446/500\n",
      "2878/2878 [==============================] - 3s 958us/step - loss: 0.4877 - accuracy: 0.7630 - val_loss: 0.4894 - val_accuracy: 0.7616\n",
      "Epoch 447/500\n",
      "2878/2878 [==============================] - 3s 883us/step - loss: 0.4844 - accuracy: 0.7651 - val_loss: 0.4907 - val_accuracy: 0.7609\n",
      "Epoch 448/500\n",
      "2878/2878 [==============================] - 2s 799us/step - loss: 0.4879 - accuracy: 0.7631 - val_loss: 0.4895 - val_accuracy: 0.7615\n",
      "Epoch 449/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.4868 - accuracy: 0.7621 - val_loss: 0.4915 - val_accuracy: 0.7574\n",
      "Epoch 450/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4903 - accuracy: 0.7593 - val_loss: 0.4874 - val_accuracy: 0.7663\n",
      "Epoch 451/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.4860 - accuracy: 0.7629 - val_loss: 0.4862 - val_accuracy: 0.7657\n",
      "Epoch 452/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4843 - accuracy: 0.7619 - val_loss: 0.4843 - val_accuracy: 0.7660\n",
      "Epoch 453/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4864 - accuracy: 0.7654 - val_loss: 0.4856 - val_accuracy: 0.7665\n",
      "Epoch 454/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.4833 - accuracy: 0.7656 - val_loss: 0.4890 - val_accuracy: 0.7623\n",
      "Epoch 455/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.4853 - accuracy: 0.7638 - val_loss: 0.4880 - val_accuracy: 0.7624\n",
      "Epoch 456/500\n",
      "2878/2878 [==============================] - 2s 759us/step - loss: 0.4870 - accuracy: 0.7620 - val_loss: 0.4910 - val_accuracy: 0.7620\n",
      "Epoch 457/500\n",
      "2878/2878 [==============================] - 2s 757us/step - loss: 0.4862 - accuracy: 0.7629 - val_loss: 0.4865 - val_accuracy: 0.7643\n",
      "Epoch 458/500\n",
      "2878/2878 [==============================] - 2s 788us/step - loss: 0.4845 - accuracy: 0.7640 - val_loss: 0.4879 - val_accuracy: 0.7614\n",
      "Epoch 459/500\n",
      "2878/2878 [==============================] - 4s 1ms/step - loss: 0.4847 - accuracy: 0.7636 - val_loss: 0.4931 - val_accuracy: 0.7577\n",
      "Epoch 460/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.4837 - accuracy: 0.7662 - val_loss: 0.4849 - val_accuracy: 0.7646\n",
      "Epoch 461/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.4831 - accuracy: 0.7647 - val_loss: 0.4884 - val_accuracy: 0.7635\n",
      "Epoch 462/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.4859 - accuracy: 0.7625 - val_loss: 0.4905 - val_accuracy: 0.7611\n",
      "Epoch 463/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.4884 - accuracy: 0.7610 - val_loss: 0.4882 - val_accuracy: 0.7635\n",
      "Epoch 464/500\n",
      "2878/2878 [==============================] - 3s 875us/step - loss: 0.4849 - accuracy: 0.7628 - val_loss: 0.4873 - val_accuracy: 0.7642\n",
      "Epoch 465/500\n",
      "2878/2878 [==============================] - 2s 835us/step - loss: 0.4840 - accuracy: 0.7641 - val_loss: 0.4868 - val_accuracy: 0.7645\n",
      "Epoch 466/500\n",
      "2878/2878 [==============================] - 2s 779us/step - loss: 0.4825 - accuracy: 0.7648 - val_loss: 0.4885 - val_accuracy: 0.7647\n",
      "Epoch 467/500\n",
      "2878/2878 [==============================] - 2s 805us/step - loss: 0.4837 - accuracy: 0.7645 - val_loss: 0.4955 - val_accuracy: 0.7616\n",
      "Epoch 468/500\n",
      "2878/2878 [==============================] - 2s 864us/step - loss: 0.4885 - accuracy: 0.7626 - val_loss: 0.4902 - val_accuracy: 0.7597\n",
      "Epoch 469/500\n",
      "2878/2878 [==============================] - 3s 992us/step - loss: 0.4890 - accuracy: 0.7613 - val_loss: 0.4989 - val_accuracy: 0.7556\n",
      "Epoch 470/500\n",
      "2878/2878 [==============================] - 3s 980us/step - loss: 0.4858 - accuracy: 0.7635 - val_loss: 0.4850 - val_accuracy: 0.7636\n",
      "Epoch 471/500\n",
      "2878/2878 [==============================] - 3s 947us/step - loss: 0.4893 - accuracy: 0.7608 - val_loss: 0.4902 - val_accuracy: 0.7588\n",
      "Epoch 472/500\n",
      "2878/2878 [==============================] - 3s 990us/step - loss: 0.4881 - accuracy: 0.7619 - val_loss: 0.4902 - val_accuracy: 0.7605\n",
      "Epoch 473/500\n",
      "2878/2878 [==============================] - 3s 950us/step - loss: 0.4835 - accuracy: 0.7660 - val_loss: 0.4900 - val_accuracy: 0.7574\n",
      "Epoch 474/500\n",
      "2878/2878 [==============================] - 3s 972us/step - loss: 0.4870 - accuracy: 0.7620 - val_loss: 0.4865 - val_accuracy: 0.7636\n",
      "Epoch 475/500\n",
      "2878/2878 [==============================] - 3s 996us/step - loss: 0.4853 - accuracy: 0.7633 - val_loss: 0.4895 - val_accuracy: 0.7632\n",
      "Epoch 476/500\n",
      "2878/2878 [==============================] - 3s 949us/step - loss: 0.4854 - accuracy: 0.7649 - val_loss: 0.4929 - val_accuracy: 0.7579\n",
      "Epoch 477/500\n",
      "2878/2878 [==============================] - 3s 936us/step - loss: 0.4875 - accuracy: 0.7626 - val_loss: 0.4832 - val_accuracy: 0.7664\n",
      "Epoch 478/500\n",
      "2878/2878 [==============================] - 3s 947us/step - loss: 0.4877 - accuracy: 0.7611 - val_loss: 0.4875 - val_accuracy: 0.7641\n",
      "Epoch 479/500\n",
      "2878/2878 [==============================] - 3s 952us/step - loss: 0.4851 - accuracy: 0.7637 - val_loss: 0.4889 - val_accuracy: 0.7614\n",
      "Epoch 480/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.4875 - accuracy: 0.7620 - val_loss: 0.4841 - val_accuracy: 0.7647\n",
      "Epoch 481/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.4827 - accuracy: 0.7638 - val_loss: 0.4935 - val_accuracy: 0.7603\n",
      "Epoch 482/500\n",
      "2878/2878 [==============================] - 3s 918us/step - loss: 0.4879 - accuracy: 0.7634 - val_loss: 0.4942 - val_accuracy: 0.7579\n",
      "Epoch 483/500\n",
      "2878/2878 [==============================] - 3s 896us/step - loss: 0.4870 - accuracy: 0.7628 - val_loss: 0.4918 - val_accuracy: 0.7609\n",
      "Epoch 484/500\n",
      "2878/2878 [==============================] - 2s 854us/step - loss: 0.4858 - accuracy: 0.7626 - val_loss: 0.4934 - val_accuracy: 0.7571\n",
      "Epoch 485/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.4862 - accuracy: 0.7650 - val_loss: 0.4876 - val_accuracy: 0.7633\n",
      "Epoch 486/500\n",
      "2878/2878 [==============================] - 3s 984us/step - loss: 0.4849 - accuracy: 0.7636 - val_loss: 0.4871 - val_accuracy: 0.7629\n",
      "Epoch 487/500\n",
      "2878/2878 [==============================] - 2s 841us/step - loss: 0.4863 - accuracy: 0.7619 - val_loss: 0.4870 - val_accuracy: 0.7638\n",
      "Epoch 488/500\n",
      "2878/2878 [==============================] - 2s 860us/step - loss: 0.4837 - accuracy: 0.7640 - val_loss: 0.4965 - val_accuracy: 0.7614\n",
      "Epoch 489/500\n",
      "2878/2878 [==============================] - 2s 791us/step - loss: 0.4875 - accuracy: 0.7619 - val_loss: 0.4896 - val_accuracy: 0.7640\n",
      "Epoch 490/500\n",
      "2878/2878 [==============================] - 2s 794us/step - loss: 0.4825 - accuracy: 0.7665 - val_loss: 0.4904 - val_accuracy: 0.7629\n",
      "Epoch 491/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4838 - accuracy: 0.7657 - val_loss: 0.4838 - val_accuracy: 0.7682\n",
      "Epoch 492/500\n",
      "2878/2878 [==============================] - 2s 811us/step - loss: 0.4846 - accuracy: 0.7647 - val_loss: 0.4825 - val_accuracy: 0.7660\n",
      "Epoch 493/500\n",
      "2878/2878 [==============================] - 2s 769us/step - loss: 0.4839 - accuracy: 0.7640 - val_loss: 0.4831 - val_accuracy: 0.7647\n",
      "Epoch 494/500\n",
      "2878/2878 [==============================] - 2s 867us/step - loss: 0.4861 - accuracy: 0.7636 - val_loss: 0.4901 - val_accuracy: 0.7630\n",
      "Epoch 495/500\n",
      "2878/2878 [==============================] - 3s 950us/step - loss: 0.4857 - accuracy: 0.7648 - val_loss: 0.4864 - val_accuracy: 0.7636\n",
      "Epoch 496/500\n",
      "2878/2878 [==============================] - 2s 820us/step - loss: 0.4856 - accuracy: 0.7624 - val_loss: 0.4929 - val_accuracy: 0.7587\n",
      "Epoch 497/500\n",
      "2878/2878 [==============================] - 2s 851us/step - loss: 0.4898 - accuracy: 0.7588 - val_loss: 0.4873 - val_accuracy: 0.7626\n",
      "Epoch 498/500\n",
      "2878/2878 [==============================] - 2s 851us/step - loss: 0.4876 - accuracy: 0.7622 - val_loss: 0.4877 - val_accuracy: 0.7663\n",
      "Epoch 499/500\n",
      "2878/2878 [==============================] - 2s 785us/step - loss: 0.4844 - accuracy: 0.7619 - val_loss: 0.4974 - val_accuracy: 0.7573\n",
      "Epoch 500/500\n",
      "2878/2878 [==============================] - 2s 813us/step - loss: 0.4884 - accuracy: 0.7624 - val_loss: 0.4884 - val_accuracy: 0.7616\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(shuffle(pd.DataFrame(x_train_resampled),random_state=1), shuffle(pd.DataFrame(y_train_resampled),random_state=1), epochs=500,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train_resampled)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_9.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 10\n",
    "-MinMax Scaler & Oversampling & Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 362\n",
      "Trainable params: 362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2878/2878 [==============================] - 3s 791us/step - loss: 0.6485 - accuracy: 0.6151 - val_loss: 0.5898 - val_accuracy: 0.6803\n",
      "Epoch 2/500\n",
      "2878/2878 [==============================] - 2s 627us/step - loss: 0.5866 - accuracy: 0.6801 - val_loss: 0.5819 - val_accuracy: 0.6847\n",
      "Epoch 3/500\n",
      "2878/2878 [==============================] - 2s 585us/step - loss: 0.5800 - accuracy: 0.6852 - val_loss: 0.5791 - val_accuracy: 0.6886\n",
      "Epoch 4/500\n",
      "2878/2878 [==============================] - 2s 631us/step - loss: 0.5774 - accuracy: 0.6877 - val_loss: 0.5762 - val_accuracy: 0.6915\n",
      "Epoch 5/500\n",
      "2878/2878 [==============================] - 2s 631us/step - loss: 0.5760 - accuracy: 0.6887 - val_loss: 0.5742 - val_accuracy: 0.6947\n",
      "Epoch 6/500\n",
      "2878/2878 [==============================] - 2s 591us/step - loss: 0.5732 - accuracy: 0.6906 - val_loss: 0.5720 - val_accuracy: 0.6961\n",
      "Epoch 7/500\n",
      "2878/2878 [==============================] - 2s 590us/step - loss: 0.5722 - accuracy: 0.6918 - val_loss: 0.5758 - val_accuracy: 0.6927\n",
      "Epoch 8/500\n",
      "2878/2878 [==============================] - 2s 619us/step - loss: 0.5696 - accuracy: 0.6951 - val_loss: 0.5713 - val_accuracy: 0.6953\n",
      "Epoch 9/500\n",
      "2878/2878 [==============================] - 2s 613us/step - loss: 0.5713 - accuracy: 0.6912 - val_loss: 0.5689 - val_accuracy: 0.6996\n",
      "Epoch 10/500\n",
      "2878/2878 [==============================] - 2s 605us/step - loss: 0.5709 - accuracy: 0.6958 - val_loss: 0.5690 - val_accuracy: 0.6964\n",
      "Epoch 11/500\n",
      "2878/2878 [==============================] - 2s 616us/step - loss: 0.5695 - accuracy: 0.6935 - val_loss: 0.5670 - val_accuracy: 0.6985\n",
      "Epoch 12/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5672 - accuracy: 0.6970 - val_loss: 0.5655 - val_accuracy: 0.6991\n",
      "Epoch 13/500\n",
      "2878/2878 [==============================] - 2s 669us/step - loss: 0.5646 - accuracy: 0.6970 - val_loss: 0.5676 - val_accuracy: 0.6970\n",
      "Epoch 14/500\n",
      "2878/2878 [==============================] - 2s 664us/step - loss: 0.5627 - accuracy: 0.7019 - val_loss: 0.5641 - val_accuracy: 0.7012\n",
      "Epoch 15/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.5637 - accuracy: 0.6995 - val_loss: 0.5639 - val_accuracy: 0.7015\n",
      "Epoch 16/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.5629 - accuracy: 0.7008 - val_loss: 0.5646 - val_accuracy: 0.7006\n",
      "Epoch 17/500\n",
      "2878/2878 [==============================] - 2s 654us/step - loss: 0.5648 - accuracy: 0.6974 - val_loss: 0.5613 - val_accuracy: 0.7031\n",
      "Epoch 18/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.5599 - accuracy: 0.7035 - val_loss: 0.5614 - val_accuracy: 0.7011\n",
      "Epoch 19/500\n",
      "2878/2878 [==============================] - 3s 974us/step - loss: 0.5587 - accuracy: 0.7036 - val_loss: 0.5601 - val_accuracy: 0.7037\n",
      "Epoch 20/500\n",
      "2878/2878 [==============================] - 2s 655us/step - loss: 0.5614 - accuracy: 0.7018 - val_loss: 0.5600 - val_accuracy: 0.7042\n",
      "Epoch 21/500\n",
      "2878/2878 [==============================] - 2s 650us/step - loss: 0.5630 - accuracy: 0.6979 - val_loss: 0.5600 - val_accuracy: 0.7028\n",
      "Epoch 22/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.5618 - accuracy: 0.7016 - val_loss: 0.5591 - val_accuracy: 0.7040\n",
      "Epoch 23/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5609 - accuracy: 0.6999 - val_loss: 0.5584 - val_accuracy: 0.7044\n",
      "Epoch 24/500\n",
      "2878/2878 [==============================] - 2s 648us/step - loss: 0.5592 - accuracy: 0.7023 - val_loss: 0.5578 - val_accuracy: 0.7051\n",
      "Epoch 25/500\n",
      "2878/2878 [==============================] - 2s 645us/step - loss: 0.5621 - accuracy: 0.6982 - val_loss: 0.5573 - val_accuracy: 0.7043\n",
      "Epoch 26/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5589 - accuracy: 0.7027 - val_loss: 0.5584 - val_accuracy: 0.7044\n",
      "Epoch 27/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.5558 - accuracy: 0.7029 - val_loss: 0.5557 - val_accuracy: 0.7067\n",
      "Epoch 28/500\n",
      "2878/2878 [==============================] - 2s 657us/step - loss: 0.5557 - accuracy: 0.7060 - val_loss: 0.5558 - val_accuracy: 0.7056\n",
      "Epoch 29/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5551 - accuracy: 0.7072 - val_loss: 0.5542 - val_accuracy: 0.7057\n",
      "Epoch 30/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.5534 - accuracy: 0.7067 - val_loss: 0.5542 - val_accuracy: 0.7059\n",
      "Epoch 31/500\n",
      "2878/2878 [==============================] - 2s 632us/step - loss: 0.5557 - accuracy: 0.7066 - val_loss: 0.5530 - val_accuracy: 0.7072\n",
      "Epoch 32/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5504 - accuracy: 0.7106 - val_loss: 0.5546 - val_accuracy: 0.7032\n",
      "Epoch 33/500\n",
      "2878/2878 [==============================] - 2s 658us/step - loss: 0.5534 - accuracy: 0.7095 - val_loss: 0.5521 - val_accuracy: 0.7065\n",
      "Epoch 34/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5526 - accuracy: 0.7090 - val_loss: 0.5517 - val_accuracy: 0.7066\n",
      "Epoch 35/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5535 - accuracy: 0.7054 - val_loss: 0.5500 - val_accuracy: 0.7083\n",
      "Epoch 36/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5495 - accuracy: 0.7130 - val_loss: 0.5502 - val_accuracy: 0.7096\n",
      "Epoch 37/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.5508 - accuracy: 0.7107 - val_loss: 0.5520 - val_accuracy: 0.7061\n",
      "Epoch 38/500\n",
      "2878/2878 [==============================] - 2s 826us/step - loss: 0.5494 - accuracy: 0.7116 - val_loss: 0.5488 - val_accuracy: 0.7115\n",
      "Epoch 39/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.5490 - accuracy: 0.7136 - val_loss: 0.5483 - val_accuracy: 0.7117\n",
      "Epoch 40/500\n",
      "2878/2878 [==============================] - 2s 794us/step - loss: 0.5475 - accuracy: 0.7142 - val_loss: 0.5486 - val_accuracy: 0.7105\n",
      "Epoch 41/500\n",
      "2878/2878 [==============================] - 2s 785us/step - loss: 0.5507 - accuracy: 0.7137 - val_loss: 0.5483 - val_accuracy: 0.7128\n",
      "Epoch 42/500\n",
      "2878/2878 [==============================] - 2s 828us/step - loss: 0.5488 - accuracy: 0.7135 - val_loss: 0.5478 - val_accuracy: 0.7128\n",
      "Epoch 43/500\n",
      "2878/2878 [==============================] - 2s 833us/step - loss: 0.5474 - accuracy: 0.7164 - val_loss: 0.5466 - val_accuracy: 0.7132\n",
      "Epoch 44/500\n",
      "2878/2878 [==============================] - 2s 834us/step - loss: 0.5473 - accuracy: 0.7183 - val_loss: 0.5456 - val_accuracy: 0.7179\n",
      "Epoch 45/500\n",
      "2878/2878 [==============================] - 2s 820us/step - loss: 0.5461 - accuracy: 0.7189 - val_loss: 0.5443 - val_accuracy: 0.7186\n",
      "Epoch 46/500\n",
      "2878/2878 [==============================] - 2s 767us/step - loss: 0.5464 - accuracy: 0.7182 - val_loss: 0.5436 - val_accuracy: 0.7181\n",
      "Epoch 47/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.5471 - accuracy: 0.7181 - val_loss: 0.5464 - val_accuracy: 0.7183\n",
      "Epoch 48/500\n",
      "2878/2878 [==============================] - 2s 750us/step - loss: 0.5437 - accuracy: 0.7199 - val_loss: 0.5433 - val_accuracy: 0.7196\n",
      "Epoch 49/500\n",
      "2878/2878 [==============================] - 2s 753us/step - loss: 0.5425 - accuracy: 0.7201 - val_loss: 0.5436 - val_accuracy: 0.7181\n",
      "Epoch 50/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5465 - accuracy: 0.7192 - val_loss: 0.5432 - val_accuracy: 0.7199\n",
      "Epoch 51/500\n",
      "2878/2878 [==============================] - 2s 672us/step - loss: 0.5435 - accuracy: 0.7227 - val_loss: 0.5432 - val_accuracy: 0.7200\n",
      "Epoch 52/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5455 - accuracy: 0.7197 - val_loss: 0.5433 - val_accuracy: 0.7196\n",
      "Epoch 53/500\n",
      "2878/2878 [==============================] - 2s 658us/step - loss: 0.5424 - accuracy: 0.7230 - val_loss: 0.5432 - val_accuracy: 0.7207\n",
      "Epoch 54/500\n",
      "2878/2878 [==============================] - 2s 656us/step - loss: 0.5440 - accuracy: 0.7205 - val_loss: 0.5416 - val_accuracy: 0.7199\n",
      "Epoch 55/500\n",
      "2878/2878 [==============================] - 2s 655us/step - loss: 0.5414 - accuracy: 0.7221 - val_loss: 0.5449 - val_accuracy: 0.7169\n",
      "Epoch 56/500\n",
      "2878/2878 [==============================] - 2s 660us/step - loss: 0.5415 - accuracy: 0.7217 - val_loss: 0.5439 - val_accuracy: 0.7198\n",
      "Epoch 57/500\n",
      "2878/2878 [==============================] - 2s 654us/step - loss: 0.5426 - accuracy: 0.7225 - val_loss: 0.5412 - val_accuracy: 0.7221\n",
      "Epoch 58/500\n",
      "2878/2878 [==============================] - 2s 642us/step - loss: 0.5423 - accuracy: 0.7204 - val_loss: 0.5407 - val_accuracy: 0.7234\n",
      "Epoch 59/500\n",
      "2878/2878 [==============================] - 2s 643us/step - loss: 0.5401 - accuracy: 0.7234 - val_loss: 0.5400 - val_accuracy: 0.7232\n",
      "Epoch 60/500\n",
      "2878/2878 [==============================] - 2s 644us/step - loss: 0.5421 - accuracy: 0.7232 - val_loss: 0.5411 - val_accuracy: 0.7215\n",
      "Epoch 61/500\n",
      "2878/2878 [==============================] - 2s 662us/step - loss: 0.5411 - accuracy: 0.7219 - val_loss: 0.5391 - val_accuracy: 0.7257\n",
      "Epoch 62/500\n",
      "2878/2878 [==============================] - 2s 661us/step - loss: 0.5398 - accuracy: 0.7268 - val_loss: 0.5418 - val_accuracy: 0.7207\n",
      "Epoch 63/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.5411 - accuracy: 0.7220 - val_loss: 0.5398 - val_accuracy: 0.7240\n",
      "Epoch 64/500\n",
      "2878/2878 [==============================] - 2s 672us/step - loss: 0.5405 - accuracy: 0.7244 - val_loss: 0.5408 - val_accuracy: 0.7212\n",
      "Epoch 65/500\n",
      "2878/2878 [==============================] - 2s 657us/step - loss: 0.5413 - accuracy: 0.7236 - val_loss: 0.5443 - val_accuracy: 0.7161\n",
      "Epoch 66/500\n",
      "2878/2878 [==============================] - 2s 642us/step - loss: 0.5368 - accuracy: 0.7263 - val_loss: 0.5386 - val_accuracy: 0.7219\n",
      "Epoch 67/500\n",
      "2878/2878 [==============================] - 2s 628us/step - loss: 0.5364 - accuracy: 0.7261 - val_loss: 0.5412 - val_accuracy: 0.7229\n",
      "Epoch 68/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5408 - accuracy: 0.7242 - val_loss: 0.5427 - val_accuracy: 0.7204\n",
      "Epoch 69/500\n",
      "2878/2878 [==============================] - 2s 646us/step - loss: 0.5411 - accuracy: 0.7215 - val_loss: 0.5391 - val_accuracy: 0.7238\n",
      "Epoch 70/500\n",
      "2878/2878 [==============================] - 2s 643us/step - loss: 0.5406 - accuracy: 0.7256 - val_loss: 0.5392 - val_accuracy: 0.7232\n",
      "Epoch 71/500\n",
      "2878/2878 [==============================] - 2s 642us/step - loss: 0.5420 - accuracy: 0.7230 - val_loss: 0.5418 - val_accuracy: 0.7190\n",
      "Epoch 72/500\n",
      "2878/2878 [==============================] - 2s 644us/step - loss: 0.5404 - accuracy: 0.7238 - val_loss: 0.5387 - val_accuracy: 0.7231\n",
      "Epoch 73/500\n",
      "2878/2878 [==============================] - 2s 649us/step - loss: 0.5422 - accuracy: 0.7229 - val_loss: 0.5387 - val_accuracy: 0.7249\n",
      "Epoch 74/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5403 - accuracy: 0.7225 - val_loss: 0.5389 - val_accuracy: 0.7233\n",
      "Epoch 75/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5403 - accuracy: 0.7242 - val_loss: 0.5428 - val_accuracy: 0.7197\n",
      "Epoch 76/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5394 - accuracy: 0.7251 - val_loss: 0.5428 - val_accuracy: 0.7192\n",
      "Epoch 77/500\n",
      "2878/2878 [==============================] - 2s 653us/step - loss: 0.5406 - accuracy: 0.7226 - val_loss: 0.5437 - val_accuracy: 0.7197\n",
      "Epoch 78/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5374 - accuracy: 0.7253 - val_loss: 0.5387 - val_accuracy: 0.7234\n",
      "Epoch 79/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5366 - accuracy: 0.7275 - val_loss: 0.5376 - val_accuracy: 0.7258\n",
      "Epoch 80/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.5409 - accuracy: 0.7215 - val_loss: 0.5411 - val_accuracy: 0.7221\n",
      "Epoch 81/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5399 - accuracy: 0.7241 - val_loss: 0.5372 - val_accuracy: 0.7243\n",
      "Epoch 82/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5394 - accuracy: 0.7241 - val_loss: 0.5446 - val_accuracy: 0.7176\n",
      "Epoch 83/500\n",
      "2878/2878 [==============================] - 2s 761us/step - loss: 0.5392 - accuracy: 0.7247 - val_loss: 0.5378 - val_accuracy: 0.7234\n",
      "Epoch 84/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5399 - accuracy: 0.7228 - val_loss: 0.5380 - val_accuracy: 0.7259\n",
      "Epoch 85/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.5377 - accuracy: 0.7246 - val_loss: 0.5397 - val_accuracy: 0.7228\n",
      "Epoch 86/500\n",
      "2878/2878 [==============================] - 2s 662us/step - loss: 0.5345 - accuracy: 0.7288 - val_loss: 0.5370 - val_accuracy: 0.7234\n",
      "Epoch 87/500\n",
      "2878/2878 [==============================] - 2s 655us/step - loss: 0.5369 - accuracy: 0.7256 - val_loss: 0.5373 - val_accuracy: 0.7245\n",
      "Epoch 88/500\n",
      "2878/2878 [==============================] - 2s 653us/step - loss: 0.5376 - accuracy: 0.7268 - val_loss: 0.5406 - val_accuracy: 0.7189\n",
      "Epoch 89/500\n",
      "2878/2878 [==============================] - 2s 668us/step - loss: 0.5386 - accuracy: 0.7279 - val_loss: 0.5389 - val_accuracy: 0.7243\n",
      "Epoch 90/500\n",
      "2878/2878 [==============================] - 2s 648us/step - loss: 0.5384 - accuracy: 0.7251 - val_loss: 0.5365 - val_accuracy: 0.7260\n",
      "Epoch 91/500\n",
      "2878/2878 [==============================] - 2s 643us/step - loss: 0.5374 - accuracy: 0.7251 - val_loss: 0.5374 - val_accuracy: 0.7256\n",
      "Epoch 92/500\n",
      "2878/2878 [==============================] - 2s 644us/step - loss: 0.5374 - accuracy: 0.7261 - val_loss: 0.5423 - val_accuracy: 0.7244\n",
      "Epoch 93/500\n",
      "2878/2878 [==============================] - 2s 760us/step - loss: 0.5367 - accuracy: 0.7266 - val_loss: 0.5378 - val_accuracy: 0.7262\n",
      "Epoch 94/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5387 - accuracy: 0.7274 - val_loss: 0.5391 - val_accuracy: 0.7254\n",
      "Epoch 95/500\n",
      "2878/2878 [==============================] - 2s 831us/step - loss: 0.5376 - accuracy: 0.7261 - val_loss: 0.5377 - val_accuracy: 0.7234\n",
      "Epoch 96/500\n",
      "2878/2878 [==============================] - 2s 757us/step - loss: 0.5362 - accuracy: 0.7283 - val_loss: 0.5354 - val_accuracy: 0.7263\n",
      "Epoch 97/500\n",
      "2878/2878 [==============================] - 2s 819us/step - loss: 0.5396 - accuracy: 0.7221 - val_loss: 0.5364 - val_accuracy: 0.7260\n",
      "Epoch 98/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.5364 - accuracy: 0.7271 - val_loss: 0.5375 - val_accuracy: 0.7250\n",
      "Epoch 99/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5372 - accuracy: 0.7269 - val_loss: 0.5419 - val_accuracy: 0.7224\n",
      "Epoch 100/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5360 - accuracy: 0.7268 - val_loss: 0.5358 - val_accuracy: 0.7279\n",
      "Epoch 101/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5358 - accuracy: 0.7270 - val_loss: 0.5379 - val_accuracy: 0.7254\n",
      "Epoch 102/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5383 - accuracy: 0.7248 - val_loss: 0.5360 - val_accuracy: 0.7255\n",
      "Epoch 103/500\n",
      "2878/2878 [==============================] - 2s 779us/step - loss: 0.5360 - accuracy: 0.7273 - val_loss: 0.5362 - val_accuracy: 0.7254\n",
      "Epoch 104/500\n",
      "2878/2878 [==============================] - 2s 792us/step - loss: 0.5379 - accuracy: 0.7253 - val_loss: 0.5368 - val_accuracy: 0.7255\n",
      "Epoch 105/500\n",
      "2878/2878 [==============================] - 2s 765us/step - loss: 0.5363 - accuracy: 0.7273 - val_loss: 0.5366 - val_accuracy: 0.7261\n",
      "Epoch 106/500\n",
      "2878/2878 [==============================] - 2s 808us/step - loss: 0.5402 - accuracy: 0.7254 - val_loss: 0.5350 - val_accuracy: 0.7265\n",
      "Epoch 107/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.5373 - accuracy: 0.7266 - val_loss: 0.5354 - val_accuracy: 0.7267\n",
      "Epoch 108/500\n",
      "2878/2878 [==============================] - 2s 810us/step - loss: 0.5365 - accuracy: 0.7258 - val_loss: 0.5363 - val_accuracy: 0.7270\n",
      "Epoch 109/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.5373 - accuracy: 0.7268 - val_loss: 0.5375 - val_accuracy: 0.7262\n",
      "Epoch 110/500\n",
      "2878/2878 [==============================] - 2s 791us/step - loss: 0.5374 - accuracy: 0.7265 - val_loss: 0.5368 - val_accuracy: 0.7258\n",
      "Epoch 111/500\n",
      "2878/2878 [==============================] - 2s 773us/step - loss: 0.5389 - accuracy: 0.7273 - val_loss: 0.5387 - val_accuracy: 0.7247\n",
      "Epoch 112/500\n",
      "2878/2878 [==============================] - 2s 768us/step - loss: 0.5353 - accuracy: 0.7281 - val_loss: 0.5382 - val_accuracy: 0.7243\n",
      "Epoch 113/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5352 - accuracy: 0.7278 - val_loss: 0.5405 - val_accuracy: 0.7237\n",
      "Epoch 114/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.5353 - accuracy: 0.7282 - val_loss: 0.5363 - val_accuracy: 0.7257\n",
      "Epoch 115/500\n",
      "2878/2878 [==============================] - 2s 753us/step - loss: 0.5372 - accuracy: 0.7279 - val_loss: 0.5375 - val_accuracy: 0.7246\n",
      "Epoch 116/500\n",
      "2878/2878 [==============================] - 2s 775us/step - loss: 0.5353 - accuracy: 0.7267 - val_loss: 0.5370 - val_accuracy: 0.7242\n",
      "Epoch 117/500\n",
      "2878/2878 [==============================] - 2s 769us/step - loss: 0.5368 - accuracy: 0.7272 - val_loss: 0.5382 - val_accuracy: 0.7246\n",
      "Epoch 118/500\n",
      "2878/2878 [==============================] - 2s 770us/step - loss: 0.5363 - accuracy: 0.7283 - val_loss: 0.5374 - val_accuracy: 0.7272\n",
      "Epoch 119/500\n",
      "2878/2878 [==============================] - 2s 780us/step - loss: 0.5366 - accuracy: 0.7279 - val_loss: 0.5350 - val_accuracy: 0.7271\n",
      "Epoch 120/500\n",
      "2878/2878 [==============================] - 2s 775us/step - loss: 0.5362 - accuracy: 0.7269 - val_loss: 0.5350 - val_accuracy: 0.7278\n",
      "Epoch 121/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.5350 - accuracy: 0.7280 - val_loss: 0.5346 - val_accuracy: 0.7280\n",
      "Epoch 122/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.5349 - accuracy: 0.7281 - val_loss: 0.5352 - val_accuracy: 0.7271\n",
      "Epoch 123/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5357 - accuracy: 0.7269 - val_loss: 0.5363 - val_accuracy: 0.7264\n",
      "Epoch 124/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5362 - accuracy: 0.7259 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 125/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5354 - accuracy: 0.7296 - val_loss: 0.5349 - val_accuracy: 0.7254\n",
      "Epoch 126/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5353 - accuracy: 0.7287 - val_loss: 0.5353 - val_accuracy: 0.7270\n",
      "Epoch 127/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5374 - accuracy: 0.7267 - val_loss: 0.5357 - val_accuracy: 0.7260\n",
      "Epoch 128/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5336 - accuracy: 0.7288 - val_loss: 0.5381 - val_accuracy: 0.7260\n",
      "Epoch 129/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5355 - accuracy: 0.7277 - val_loss: 0.5353 - val_accuracy: 0.7276\n",
      "Epoch 130/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.5351 - accuracy: 0.7286 - val_loss: 0.5359 - val_accuracy: 0.7278\n",
      "Epoch 131/500\n",
      "2878/2878 [==============================] - 2s 762us/step - loss: 0.5349 - accuracy: 0.7278 - val_loss: 0.5368 - val_accuracy: 0.7248\n",
      "Epoch 132/500\n",
      "2878/2878 [==============================] - 2s 795us/step - loss: 0.5342 - accuracy: 0.7291 - val_loss: 0.5368 - val_accuracy: 0.7252\n",
      "Epoch 133/500\n",
      "2878/2878 [==============================] - 2s 813us/step - loss: 0.5340 - accuracy: 0.7305 - val_loss: 0.5404 - val_accuracy: 0.7238\n",
      "Epoch 134/500\n",
      "2878/2878 [==============================] - 2s 762us/step - loss: 0.5374 - accuracy: 0.7267 - val_loss: 0.5353 - val_accuracy: 0.7259\n",
      "Epoch 135/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.5342 - accuracy: 0.7281 - val_loss: 0.5350 - val_accuracy: 0.7265\n",
      "Epoch 136/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.5333 - accuracy: 0.7293 - val_loss: 0.5359 - val_accuracy: 0.7270\n",
      "Epoch 137/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.5361 - accuracy: 0.7269 - val_loss: 0.5352 - val_accuracy: 0.7283\n",
      "Epoch 138/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5338 - accuracy: 0.7310 - val_loss: 0.5376 - val_accuracy: 0.7232\n",
      "Epoch 139/500\n",
      "2878/2878 [==============================] - 2s 779us/step - loss: 0.5358 - accuracy: 0.7261 - val_loss: 0.5353 - val_accuracy: 0.7257\n",
      "Epoch 140/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.5361 - accuracy: 0.7275 - val_loss: 0.5350 - val_accuracy: 0.7288\n",
      "Epoch 141/500\n",
      "2878/2878 [==============================] - 2s 810us/step - loss: 0.5338 - accuracy: 0.7295 - val_loss: 0.5390 - val_accuracy: 0.7229\n",
      "Epoch 142/500\n",
      "2878/2878 [==============================] - 3s 882us/step - loss: 0.5348 - accuracy: 0.7265 - val_loss: 0.5353 - val_accuracy: 0.7259\n",
      "Epoch 143/500\n",
      "2878/2878 [==============================] - 2s 841us/step - loss: 0.5328 - accuracy: 0.7323 - val_loss: 0.5357 - val_accuracy: 0.7238\n",
      "Epoch 144/500\n",
      "2878/2878 [==============================] - 2s 803us/step - loss: 0.5369 - accuracy: 0.7256 - val_loss: 0.5368 - val_accuracy: 0.7254\n",
      "Epoch 145/500\n",
      "2878/2878 [==============================] - 2s 845us/step - loss: 0.5337 - accuracy: 0.7296 - val_loss: 0.5347 - val_accuracy: 0.7301\n",
      "Epoch 146/500\n",
      "2878/2878 [==============================] - 2s 752us/step - loss: 0.5332 - accuracy: 0.7310 - val_loss: 0.5358 - val_accuracy: 0.7261\n",
      "Epoch 147/500\n",
      "2878/2878 [==============================] - 2s 755us/step - loss: 0.5310 - accuracy: 0.7320 - val_loss: 0.5337 - val_accuracy: 0.7297\n",
      "Epoch 148/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.5346 - accuracy: 0.7278 - val_loss: 0.5348 - val_accuracy: 0.7283\n",
      "Epoch 149/500\n",
      "2878/2878 [==============================] - 2s 857us/step - loss: 0.5340 - accuracy: 0.7283 - val_loss: 0.5359 - val_accuracy: 0.7251\n",
      "Epoch 150/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.5348 - accuracy: 0.7281 - val_loss: 0.5383 - val_accuracy: 0.7243\n",
      "Epoch 151/500\n",
      "2878/2878 [==============================] - 2s 838us/step - loss: 0.5375 - accuracy: 0.7272 - val_loss: 0.5354 - val_accuracy: 0.7260\n",
      "Epoch 152/500\n",
      "2878/2878 [==============================] - 2s 822us/step - loss: 0.5355 - accuracy: 0.7280 - val_loss: 0.5362 - val_accuracy: 0.7267\n",
      "Epoch 153/500\n",
      "2878/2878 [==============================] - 2s 785us/step - loss: 0.5358 - accuracy: 0.7276 - val_loss: 0.5338 - val_accuracy: 0.7289\n",
      "Epoch 154/500\n",
      "2878/2878 [==============================] - 2s 775us/step - loss: 0.5344 - accuracy: 0.7305 - val_loss: 0.5338 - val_accuracy: 0.7282\n",
      "Epoch 155/500\n",
      "2878/2878 [==============================] - 2s 799us/step - loss: 0.5343 - accuracy: 0.7286 - val_loss: 0.5345 - val_accuracy: 0.7278\n",
      "Epoch 156/500\n",
      "2878/2878 [==============================] - 2s 784us/step - loss: 0.5340 - accuracy: 0.7279 - val_loss: 0.5394 - val_accuracy: 0.7268\n",
      "Epoch 157/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.5349 - accuracy: 0.7302 - val_loss: 0.5356 - val_accuracy: 0.7268\n",
      "Epoch 158/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.5300 - accuracy: 0.7306 - val_loss: 0.5337 - val_accuracy: 0.7289\n",
      "Epoch 159/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.5332 - accuracy: 0.7311 - val_loss: 0.5366 - val_accuracy: 0.7276\n",
      "Epoch 160/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.5320 - accuracy: 0.7299 - val_loss: 0.5345 - val_accuracy: 0.7308\n",
      "Epoch 161/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5346 - accuracy: 0.7292 - val_loss: 0.5353 - val_accuracy: 0.7282\n",
      "Epoch 162/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.5337 - accuracy: 0.7290 - val_loss: 0.5343 - val_accuracy: 0.7295\n",
      "Epoch 163/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.5334 - accuracy: 0.7299 - val_loss: 0.5376 - val_accuracy: 0.7241\n",
      "Epoch 164/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5342 - accuracy: 0.7262 - val_loss: 0.5370 - val_accuracy: 0.7250\n",
      "Epoch 165/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.5341 - accuracy: 0.7270 - val_loss: 0.5368 - val_accuracy: 0.7272\n",
      "Epoch 166/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.5331 - accuracy: 0.7301 - val_loss: 0.5349 - val_accuracy: 0.7274\n",
      "Epoch 167/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.5344 - accuracy: 0.7279 - val_loss: 0.5372 - val_accuracy: 0.7256\n",
      "Epoch 168/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.5325 - accuracy: 0.7300 - val_loss: 0.5344 - val_accuracy: 0.7286\n",
      "Epoch 169/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5341 - accuracy: 0.7296 - val_loss: 0.5380 - val_accuracy: 0.7239\n",
      "Epoch 170/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5328 - accuracy: 0.7299 - val_loss: 0.5361 - val_accuracy: 0.7261\n",
      "Epoch 171/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5346 - accuracy: 0.7275 - val_loss: 0.5356 - val_accuracy: 0.7248\n",
      "Epoch 172/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5340 - accuracy: 0.7278 - val_loss: 0.5354 - val_accuracy: 0.7264\n",
      "Epoch 173/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5317 - accuracy: 0.7298 - val_loss: 0.5360 - val_accuracy: 0.7273\n",
      "Epoch 174/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5334 - accuracy: 0.7315 - val_loss: 0.5346 - val_accuracy: 0.7278\n",
      "Epoch 175/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5314 - accuracy: 0.7320 - val_loss: 0.5377 - val_accuracy: 0.7260\n",
      "Epoch 176/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.5333 - accuracy: 0.7303 - val_loss: 0.5351 - val_accuracy: 0.7284\n",
      "Epoch 177/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5326 - accuracy: 0.7300 - val_loss: 0.5358 - val_accuracy: 0.7301\n",
      "Epoch 178/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5358 - accuracy: 0.7253 - val_loss: 0.5337 - val_accuracy: 0.7277\n",
      "Epoch 179/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5330 - accuracy: 0.7295 - val_loss: 0.5374 - val_accuracy: 0.7261\n",
      "Epoch 180/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5330 - accuracy: 0.7310 - val_loss: 0.5353 - val_accuracy: 0.7304\n",
      "Epoch 181/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5363 - accuracy: 0.7288 - val_loss: 0.5351 - val_accuracy: 0.7263\n",
      "Epoch 182/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5335 - accuracy: 0.7286 - val_loss: 0.5368 - val_accuracy: 0.7279\n",
      "Epoch 183/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5324 - accuracy: 0.7316 - val_loss: 0.5347 - val_accuracy: 0.7261\n",
      "Epoch 184/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5335 - accuracy: 0.7284 - val_loss: 0.5451 - val_accuracy: 0.7206\n",
      "Epoch 185/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5350 - accuracy: 0.7261 - val_loss: 0.5350 - val_accuracy: 0.7268\n",
      "Epoch 186/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5330 - accuracy: 0.7303 - val_loss: 0.5348 - val_accuracy: 0.7272\n",
      "Epoch 187/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5343 - accuracy: 0.7285 - val_loss: 0.5366 - val_accuracy: 0.7246\n",
      "Epoch 188/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5334 - accuracy: 0.7282 - val_loss: 0.5349 - val_accuracy: 0.7271\n",
      "Epoch 189/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5355 - accuracy: 0.7281 - val_loss: 0.5339 - val_accuracy: 0.7285\n",
      "Epoch 190/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5334 - accuracy: 0.7288 - val_loss: 0.5332 - val_accuracy: 0.7304\n",
      "Epoch 191/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.5333 - accuracy: 0.7294 - val_loss: 0.5339 - val_accuracy: 0.7280\n",
      "Epoch 192/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5360 - accuracy: 0.7247 - val_loss: 0.5341 - val_accuracy: 0.7281\n",
      "Epoch 193/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5331 - accuracy: 0.7305 - val_loss: 0.5450 - val_accuracy: 0.7235\n",
      "Epoch 194/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.5322 - accuracy: 0.7298 - val_loss: 0.5385 - val_accuracy: 0.7216\n",
      "Epoch 195/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.5325 - accuracy: 0.7313 - val_loss: 0.5335 - val_accuracy: 0.7283\n",
      "Epoch 196/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.5346 - accuracy: 0.7280 - val_loss: 0.5341 - val_accuracy: 0.7278\n",
      "Epoch 197/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5304 - accuracy: 0.7321 - val_loss: 0.5350 - val_accuracy: 0.7259\n",
      "Epoch 198/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5375 - accuracy: 0.7268 - val_loss: 0.5353 - val_accuracy: 0.7256\n",
      "Epoch 199/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5326 - accuracy: 0.7313 - val_loss: 0.5336 - val_accuracy: 0.7281\n",
      "Epoch 200/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5344 - accuracy: 0.7273 - val_loss: 0.5383 - val_accuracy: 0.7254\n",
      "Epoch 201/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5342 - accuracy: 0.7276 - val_loss: 0.5385 - val_accuracy: 0.7252\n",
      "Epoch 202/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.5323 - accuracy: 0.7311 - val_loss: 0.5326 - val_accuracy: 0.7303\n",
      "Epoch 203/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5318 - accuracy: 0.7303 - val_loss: 0.5339 - val_accuracy: 0.7298\n",
      "Epoch 204/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5318 - accuracy: 0.7315 - val_loss: 0.5335 - val_accuracy: 0.7309\n",
      "Epoch 205/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5330 - accuracy: 0.7293 - val_loss: 0.5329 - val_accuracy: 0.7282\n",
      "Epoch 206/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5324 - accuracy: 0.7313 - val_loss: 0.5348 - val_accuracy: 0.7279\n",
      "Epoch 207/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5326 - accuracy: 0.7305 - val_loss: 0.5339 - val_accuracy: 0.7288\n",
      "Epoch 208/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5314 - accuracy: 0.7317 - val_loss: 0.5329 - val_accuracy: 0.7291\n",
      "Epoch 209/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5348 - accuracy: 0.7280 - val_loss: 0.5325 - val_accuracy: 0.7285\n",
      "Epoch 210/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5293 - accuracy: 0.7320 - val_loss: 0.5337 - val_accuracy: 0.7281\n",
      "Epoch 211/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5365 - accuracy: 0.7276 - val_loss: 0.5348 - val_accuracy: 0.7268\n",
      "Epoch 212/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5320 - accuracy: 0.7310 - val_loss: 0.5350 - val_accuracy: 0.7284\n",
      "Epoch 213/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5319 - accuracy: 0.7294 - val_loss: 0.5337 - val_accuracy: 0.7288\n",
      "Epoch 214/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5328 - accuracy: 0.7296 - val_loss: 0.5328 - val_accuracy: 0.7299\n",
      "Epoch 215/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.5312 - accuracy: 0.7297 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
      "Epoch 216/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5338 - accuracy: 0.7276 - val_loss: 0.5342 - val_accuracy: 0.7285\n",
      "Epoch 217/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5337 - accuracy: 0.7289 - val_loss: 0.5325 - val_accuracy: 0.7288\n",
      "Epoch 218/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.5335 - accuracy: 0.7289 - val_loss: 0.5333 - val_accuracy: 0.7295\n",
      "Epoch 219/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5348 - accuracy: 0.7279 - val_loss: 0.5328 - val_accuracy: 0.7305\n",
      "Epoch 220/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5344 - accuracy: 0.7280 - val_loss: 0.5344 - val_accuracy: 0.7268\n",
      "Epoch 221/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5353 - accuracy: 0.7279 - val_loss: 0.5338 - val_accuracy: 0.7295\n",
      "Epoch 222/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.5314 - accuracy: 0.7309 - val_loss: 0.5346 - val_accuracy: 0.7281\n",
      "Epoch 223/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.5330 - accuracy: 0.7303 - val_loss: 0.5364 - val_accuracy: 0.7246\n",
      "Epoch 224/500\n",
      "2878/2878 [==============================] - 2s 813us/step - loss: 0.5306 - accuracy: 0.7308 - val_loss: 0.5414 - val_accuracy: 0.7253\n",
      "Epoch 225/500\n",
      "2878/2878 [==============================] - 2s 829us/step - loss: 0.5338 - accuracy: 0.7287 - val_loss: 0.5324 - val_accuracy: 0.7311\n",
      "Epoch 226/500\n",
      "2878/2878 [==============================] - 2s 835us/step - loss: 0.5342 - accuracy: 0.7290 - val_loss: 0.5333 - val_accuracy: 0.7292\n",
      "Epoch 227/500\n",
      "2878/2878 [==============================] - 2s 768us/step - loss: 0.5310 - accuracy: 0.7303 - val_loss: 0.5341 - val_accuracy: 0.7271\n",
      "Epoch 228/500\n",
      "2878/2878 [==============================] - 2s 827us/step - loss: 0.5323 - accuracy: 0.7289 - val_loss: 0.5338 - val_accuracy: 0.7282\n",
      "Epoch 229/500\n",
      "2878/2878 [==============================] - 2s 777us/step - loss: 0.5333 - accuracy: 0.7299 - val_loss: 0.5363 - val_accuracy: 0.7265\n",
      "Epoch 230/500\n",
      "2878/2878 [==============================] - 2s 772us/step - loss: 0.5330 - accuracy: 0.7286 - val_loss: 0.5344 - val_accuracy: 0.7310\n",
      "Epoch 231/500\n",
      "2878/2878 [==============================] - 2s 759us/step - loss: 0.5327 - accuracy: 0.7317 - val_loss: 0.5349 - val_accuracy: 0.7277\n",
      "Epoch 232/500\n",
      "2878/2878 [==============================] - 2s 764us/step - loss: 0.5285 - accuracy: 0.7323 - val_loss: 0.5377 - val_accuracy: 0.7278\n",
      "Epoch 233/500\n",
      "2878/2878 [==============================] - 2s 747us/step - loss: 0.5304 - accuracy: 0.7302 - val_loss: 0.5347 - val_accuracy: 0.7265\n",
      "Epoch 234/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.5322 - accuracy: 0.7289 - val_loss: 0.5331 - val_accuracy: 0.7306\n",
      "Epoch 235/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.5306 - accuracy: 0.7315 - val_loss: 0.5325 - val_accuracy: 0.7295\n",
      "Epoch 236/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.5337 - accuracy: 0.7292 - val_loss: 0.5352 - val_accuracy: 0.7259\n",
      "Epoch 237/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.5293 - accuracy: 0.7322 - val_loss: 0.5350 - val_accuracy: 0.7271\n",
      "Epoch 238/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.5336 - accuracy: 0.7275 - val_loss: 0.5405 - val_accuracy: 0.7245\n",
      "Epoch 239/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5305 - accuracy: 0.7314 - val_loss: 0.5328 - val_accuracy: 0.7300\n",
      "Epoch 240/500\n",
      "2878/2878 [==============================] - 2s 793us/step - loss: 0.5319 - accuracy: 0.7311 - val_loss: 0.5351 - val_accuracy: 0.7288\n",
      "Epoch 241/500\n",
      "2878/2878 [==============================] - 2s 777us/step - loss: 0.5312 - accuracy: 0.7309 - val_loss: 0.5340 - val_accuracy: 0.7295\n",
      "Epoch 242/500\n",
      "2878/2878 [==============================] - 2s 808us/step - loss: 0.5314 - accuracy: 0.7321 - val_loss: 0.5333 - val_accuracy: 0.7308\n",
      "Epoch 243/500\n",
      "2878/2878 [==============================] - 3s 924us/step - loss: 0.5325 - accuracy: 0.7304 - val_loss: 0.5336 - val_accuracy: 0.7303\n",
      "Epoch 244/500\n",
      "2878/2878 [==============================] - 2s 849us/step - loss: 0.5329 - accuracy: 0.7309 - val_loss: 0.5345 - val_accuracy: 0.7270\n",
      "Epoch 245/500\n",
      "2878/2878 [==============================] - 2s 859us/step - loss: 0.5317 - accuracy: 0.7304 - val_loss: 0.5325 - val_accuracy: 0.7298\n",
      "Epoch 246/500\n",
      "2878/2878 [==============================] - 2s 774us/step - loss: 0.5310 - accuracy: 0.7316 - val_loss: 0.5338 - val_accuracy: 0.7284\n",
      "Epoch 247/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.5316 - accuracy: 0.7298 - val_loss: 0.5351 - val_accuracy: 0.7258\n",
      "Epoch 248/500\n",
      "2878/2878 [==============================] - 2s 766us/step - loss: 0.5326 - accuracy: 0.7301 - val_loss: 0.5348 - val_accuracy: 0.7283\n",
      "Epoch 249/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.5323 - accuracy: 0.7294 - val_loss: 0.5324 - val_accuracy: 0.7289\n",
      "Epoch 250/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5308 - accuracy: 0.7306 - val_loss: 0.5317 - val_accuracy: 0.7312\n",
      "Epoch 251/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5326 - accuracy: 0.7290 - val_loss: 0.5311 - val_accuracy: 0.7295\n",
      "Epoch 252/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5304 - accuracy: 0.7310 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
      "Epoch 253/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5346 - accuracy: 0.7282 - val_loss: 0.5325 - val_accuracy: 0.7294\n",
      "Epoch 254/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5306 - accuracy: 0.7312 - val_loss: 0.5339 - val_accuracy: 0.7282\n",
      "Epoch 255/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5322 - accuracy: 0.7303 - val_loss: 0.5315 - val_accuracy: 0.7297\n",
      "Epoch 256/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5268 - accuracy: 0.7354 - val_loss: 0.5326 - val_accuracy: 0.7297\n",
      "Epoch 257/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5307 - accuracy: 0.7313 - val_loss: 0.5338 - val_accuracy: 0.7292\n",
      "Epoch 258/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.5329 - accuracy: 0.7293 - val_loss: 0.5319 - val_accuracy: 0.7314\n",
      "Epoch 259/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.5314 - accuracy: 0.7319 - val_loss: 0.5323 - val_accuracy: 0.7287\n",
      "Epoch 260/500\n",
      "2878/2878 [==============================] - 2s 754us/step - loss: 0.5331 - accuracy: 0.7287 - val_loss: 0.5317 - val_accuracy: 0.7304\n",
      "Epoch 261/500\n",
      "2878/2878 [==============================] - 2s 782us/step - loss: 0.5312 - accuracy: 0.7301 - val_loss: 0.5333 - val_accuracy: 0.7288\n",
      "Epoch 262/500\n",
      "2878/2878 [==============================] - 2s 773us/step - loss: 0.5302 - accuracy: 0.7298 - val_loss: 0.5311 - val_accuracy: 0.7307\n",
      "Epoch 263/500\n",
      "2878/2878 [==============================] - 2s 777us/step - loss: 0.5311 - accuracy: 0.7292 - val_loss: 0.5312 - val_accuracy: 0.7310\n",
      "Epoch 264/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5340 - accuracy: 0.7300 - val_loss: 0.5325 - val_accuracy: 0.7285\n",
      "Epoch 265/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5318 - accuracy: 0.7315 - val_loss: 0.5320 - val_accuracy: 0.7296\n",
      "Epoch 266/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5304 - accuracy: 0.7320 - val_loss: 0.5317 - val_accuracy: 0.7295\n",
      "Epoch 267/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5302 - accuracy: 0.7322 - val_loss: 0.5344 - val_accuracy: 0.7259\n",
      "Epoch 268/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.5330 - accuracy: 0.7301 - val_loss: 0.5327 - val_accuracy: 0.7284\n",
      "Epoch 269/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5294 - accuracy: 0.7332 - val_loss: 0.5335 - val_accuracy: 0.7296\n",
      "Epoch 270/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.5306 - accuracy: 0.7302 - val_loss: 0.5327 - val_accuracy: 0.7305\n",
      "Epoch 271/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.5314 - accuracy: 0.7291 - val_loss: 0.5357 - val_accuracy: 0.7307\n",
      "Epoch 272/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.5311 - accuracy: 0.7306 - val_loss: 0.5332 - val_accuracy: 0.7292\n",
      "Epoch 273/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.5288 - accuracy: 0.7322 - val_loss: 0.5332 - val_accuracy: 0.7291\n",
      "Epoch 274/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.5337 - accuracy: 0.7304 - val_loss: 0.5332 - val_accuracy: 0.7313\n",
      "Epoch 275/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.5326 - accuracy: 0.7307 - val_loss: 0.5328 - val_accuracy: 0.7296\n",
      "Epoch 276/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5306 - accuracy: 0.7327 - val_loss: 0.5320 - val_accuracy: 0.7288\n",
      "Epoch 277/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5336 - accuracy: 0.7274 - val_loss: 0.5332 - val_accuracy: 0.7285\n",
      "Epoch 278/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.5316 - accuracy: 0.7312 - val_loss: 0.5328 - val_accuracy: 0.7273\n",
      "Epoch 279/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.5280 - accuracy: 0.7333 - val_loss: 0.5342 - val_accuracy: 0.7265\n",
      "Epoch 280/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5304 - accuracy: 0.7318 - val_loss: 0.5325 - val_accuracy: 0.7307\n",
      "Epoch 281/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5321 - accuracy: 0.7310 - val_loss: 0.5327 - val_accuracy: 0.7288\n",
      "Epoch 282/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5305 - accuracy: 0.7320 - val_loss: 0.5315 - val_accuracy: 0.7305\n",
      "Epoch 283/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.5296 - accuracy: 0.7318 - val_loss: 0.5329 - val_accuracy: 0.7292\n",
      "Epoch 284/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5327 - accuracy: 0.7305 - val_loss: 0.5337 - val_accuracy: 0.7273\n",
      "Epoch 285/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.5313 - accuracy: 0.7306 - val_loss: 0.5316 - val_accuracy: 0.7298\n",
      "Epoch 286/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.5324 - accuracy: 0.7286 - val_loss: 0.5319 - val_accuracy: 0.7311\n",
      "Epoch 287/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.5314 - accuracy: 0.7312 - val_loss: 0.5321 - val_accuracy: 0.7303\n",
      "Epoch 288/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.5309 - accuracy: 0.7314 - val_loss: 0.5373 - val_accuracy: 0.7259\n",
      "Epoch 289/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5310 - accuracy: 0.7295 - val_loss: 0.5318 - val_accuracy: 0.7301\n",
      "Epoch 290/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5326 - accuracy: 0.7291 - val_loss: 0.5311 - val_accuracy: 0.7313\n",
      "Epoch 291/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5299 - accuracy: 0.7320 - val_loss: 0.5320 - val_accuracy: 0.7297\n",
      "Epoch 292/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5300 - accuracy: 0.7328 - val_loss: 0.5334 - val_accuracy: 0.7285\n",
      "Epoch 293/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5276 - accuracy: 0.7342 - val_loss: 0.5335 - val_accuracy: 0.7290\n",
      "Epoch 294/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.5305 - accuracy: 0.7326 - val_loss: 0.5323 - val_accuracy: 0.7331\n",
      "Epoch 295/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.5311 - accuracy: 0.7323 - val_loss: 0.5321 - val_accuracy: 0.7295\n",
      "Epoch 296/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.5306 - accuracy: 0.7312 - val_loss: 0.5333 - val_accuracy: 0.7288\n",
      "Epoch 297/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.5329 - accuracy: 0.7307 - val_loss: 0.5325 - val_accuracy: 0.7299\n",
      "Epoch 298/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.5312 - accuracy: 0.7298 - val_loss: 0.5311 - val_accuracy: 0.7303\n",
      "Epoch 299/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.5331 - accuracy: 0.7301 - val_loss: 0.5317 - val_accuracy: 0.7288\n",
      "Epoch 300/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.5289 - accuracy: 0.7333 - val_loss: 0.5315 - val_accuracy: 0.7307\n",
      "Epoch 301/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.5286 - accuracy: 0.7328 - val_loss: 0.5315 - val_accuracy: 0.7304\n",
      "Epoch 302/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.5299 - accuracy: 0.7335 - val_loss: 0.5315 - val_accuracy: 0.7292\n",
      "Epoch 303/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.5294 - accuracy: 0.7338 - val_loss: 0.5313 - val_accuracy: 0.7316\n",
      "Epoch 304/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.5303 - accuracy: 0.7296 - val_loss: 0.5309 - val_accuracy: 0.7305\n",
      "Epoch 305/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5325 - accuracy: 0.7315 - val_loss: 0.5312 - val_accuracy: 0.7312\n",
      "Epoch 306/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5341 - accuracy: 0.7282 - val_loss: 0.5342 - val_accuracy: 0.7272\n",
      "Epoch 307/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5304 - accuracy: 0.7309 - val_loss: 0.5343 - val_accuracy: 0.7280\n",
      "Epoch 308/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5313 - accuracy: 0.7288 - val_loss: 0.5320 - val_accuracy: 0.7305\n",
      "Epoch 309/500\n",
      "2878/2878 [==============================] - 2s 755us/step - loss: 0.5300 - accuracy: 0.7326 - val_loss: 0.5343 - val_accuracy: 0.7289\n",
      "Epoch 310/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.5315 - accuracy: 0.7303 - val_loss: 0.5330 - val_accuracy: 0.7282\n",
      "Epoch 311/500\n",
      "2878/2878 [==============================] - 2s 781us/step - loss: 0.5313 - accuracy: 0.7312 - val_loss: 0.5333 - val_accuracy: 0.7286\n",
      "Epoch 312/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.5292 - accuracy: 0.7289 - val_loss: 0.5305 - val_accuracy: 0.7310\n",
      "Epoch 313/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5292 - accuracy: 0.7321 - val_loss: 0.5339 - val_accuracy: 0.7304\n",
      "Epoch 314/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.5301 - accuracy: 0.7321 - val_loss: 0.5306 - val_accuracy: 0.7314\n",
      "Epoch 315/500\n",
      "2878/2878 [==============================] - 2s 761us/step - loss: 0.5328 - accuracy: 0.7287 - val_loss: 0.5321 - val_accuracy: 0.7306\n",
      "Epoch 316/500\n",
      "2878/2878 [==============================] - 2s 812us/step - loss: 0.5341 - accuracy: 0.7278 - val_loss: 0.5335 - val_accuracy: 0.7302\n",
      "Epoch 317/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5303 - accuracy: 0.7317 - val_loss: 0.5320 - val_accuracy: 0.7287\n",
      "Epoch 318/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5350 - accuracy: 0.7259 - val_loss: 0.5315 - val_accuracy: 0.7291\n",
      "Epoch 319/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.5309 - accuracy: 0.7321 - val_loss: 0.5314 - val_accuracy: 0.7307\n",
      "Epoch 320/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5308 - accuracy: 0.7306 - val_loss: 0.5322 - val_accuracy: 0.7289\n",
      "Epoch 321/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5307 - accuracy: 0.7311 - val_loss: 0.5328 - val_accuracy: 0.7302\n",
      "Epoch 322/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5294 - accuracy: 0.7319 - val_loss: 0.5313 - val_accuracy: 0.7295\n",
      "Epoch 323/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5313 - accuracy: 0.7311 - val_loss: 0.5343 - val_accuracy: 0.7278\n",
      "Epoch 324/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5291 - accuracy: 0.7316 - val_loss: 0.5320 - val_accuracy: 0.7307\n",
      "Epoch 325/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5337 - accuracy: 0.7269 - val_loss: 0.5322 - val_accuracy: 0.7284\n",
      "Epoch 326/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5332 - accuracy: 0.7298 - val_loss: 0.5327 - val_accuracy: 0.7292\n",
      "Epoch 327/500\n",
      "2878/2878 [==============================] - 2s 772us/step - loss: 0.5299 - accuracy: 0.7303 - val_loss: 0.5308 - val_accuracy: 0.7308\n",
      "Epoch 328/500\n",
      "2878/2878 [==============================] - 2s 838us/step - loss: 0.5316 - accuracy: 0.7302 - val_loss: 0.5323 - val_accuracy: 0.7299\n",
      "Epoch 329/500\n",
      "2878/2878 [==============================] - 2s 836us/step - loss: 0.5319 - accuracy: 0.7305 - val_loss: 0.5326 - val_accuracy: 0.7272\n",
      "Epoch 330/500\n",
      "2878/2878 [==============================] - 2s 834us/step - loss: 0.5299 - accuracy: 0.7309 - val_loss: 0.5334 - val_accuracy: 0.7267\n",
      "Epoch 331/500\n",
      "2878/2878 [==============================] - 2s 852us/step - loss: 0.5295 - accuracy: 0.7309 - val_loss: 0.5304 - val_accuracy: 0.7308\n",
      "Epoch 332/500\n",
      "2878/2878 [==============================] - 2s 826us/step - loss: 0.5320 - accuracy: 0.7291 - val_loss: 0.5311 - val_accuracy: 0.7307\n",
      "Epoch 333/500\n",
      "2878/2878 [==============================] - 2s 768us/step - loss: 0.5300 - accuracy: 0.7306 - val_loss: 0.5302 - val_accuracy: 0.7333\n",
      "Epoch 334/500\n",
      "2878/2878 [==============================] - 2s 837us/step - loss: 0.5291 - accuracy: 0.7317 - val_loss: 0.5321 - val_accuracy: 0.7276\n",
      "Epoch 335/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.5300 - accuracy: 0.7312 - val_loss: 0.5311 - val_accuracy: 0.7304\n",
      "Epoch 336/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5327 - accuracy: 0.7279 - val_loss: 0.5308 - val_accuracy: 0.7316\n",
      "Epoch 337/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5296 - accuracy: 0.7312 - val_loss: 0.5362 - val_accuracy: 0.7260\n",
      "Epoch 338/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5315 - accuracy: 0.7300 - val_loss: 0.5302 - val_accuracy: 0.7311\n",
      "Epoch 339/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5305 - accuracy: 0.7329 - val_loss: 0.5312 - val_accuracy: 0.7291\n",
      "Epoch 340/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5287 - accuracy: 0.7326 - val_loss: 0.5320 - val_accuracy: 0.7292\n",
      "Epoch 341/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5271 - accuracy: 0.7337 - val_loss: 0.5352 - val_accuracy: 0.7286\n",
      "Epoch 342/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5289 - accuracy: 0.7333 - val_loss: 0.5325 - val_accuracy: 0.7287\n",
      "Epoch 343/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5302 - accuracy: 0.7300 - val_loss: 0.5330 - val_accuracy: 0.7267\n",
      "Epoch 344/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.5280 - accuracy: 0.7333 - val_loss: 0.5309 - val_accuracy: 0.7309\n",
      "Epoch 345/500\n",
      "2878/2878 [==============================] - 2s 757us/step - loss: 0.5292 - accuracy: 0.7318 - val_loss: 0.5333 - val_accuracy: 0.7276\n",
      "Epoch 346/500\n",
      "2878/2878 [==============================] - 3s 934us/step - loss: 0.5311 - accuracy: 0.7297 - val_loss: 0.5345 - val_accuracy: 0.7265\n",
      "Epoch 347/500\n",
      "2878/2878 [==============================] - 2s 824us/step - loss: 0.5309 - accuracy: 0.7292 - val_loss: 0.5321 - val_accuracy: 0.7276\n",
      "Epoch 348/500\n",
      "2878/2878 [==============================] - 2s 826us/step - loss: 0.5309 - accuracy: 0.7302 - val_loss: 0.5312 - val_accuracy: 0.7289\n",
      "Epoch 349/500\n",
      "2878/2878 [==============================] - 3s 980us/step - loss: 0.5307 - accuracy: 0.7305 - val_loss: 0.5329 - val_accuracy: 0.7295\n",
      "Epoch 350/500\n",
      "2878/2878 [==============================] - 2s 863us/step - loss: 0.5313 - accuracy: 0.7306 - val_loss: 0.5343 - val_accuracy: 0.7297\n",
      "Epoch 351/500\n",
      "2878/2878 [==============================] - 2s 783us/step - loss: 0.5322 - accuracy: 0.7310 - val_loss: 0.5311 - val_accuracy: 0.7295\n",
      "Epoch 352/500\n",
      "2878/2878 [==============================] - 2s 812us/step - loss: 0.5277 - accuracy: 0.7337 - val_loss: 0.5337 - val_accuracy: 0.7278\n",
      "Epoch 353/500\n",
      "2878/2878 [==============================] - 2s 814us/step - loss: 0.5294 - accuracy: 0.7322 - val_loss: 0.5315 - val_accuracy: 0.7312\n",
      "Epoch 354/500\n",
      "2878/2878 [==============================] - 2s 762us/step - loss: 0.5289 - accuracy: 0.7342 - val_loss: 0.5304 - val_accuracy: 0.7294\n",
      "Epoch 355/500\n",
      "2878/2878 [==============================] - 2s 782us/step - loss: 0.5323 - accuracy: 0.7303 - val_loss: 0.5322 - val_accuracy: 0.7286\n",
      "Epoch 356/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5294 - accuracy: 0.7316 - val_loss: 0.5317 - val_accuracy: 0.7293\n",
      "Epoch 357/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5289 - accuracy: 0.7321 - val_loss: 0.5315 - val_accuracy: 0.7297\n",
      "Epoch 358/500\n",
      "2878/2878 [==============================] - 2s 749us/step - loss: 0.5286 - accuracy: 0.7332 - val_loss: 0.5329 - val_accuracy: 0.7308\n",
      "Epoch 359/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5298 - accuracy: 0.7305 - val_loss: 0.5335 - val_accuracy: 0.7300\n",
      "Epoch 360/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.5273 - accuracy: 0.7346 - val_loss: 0.5346 - val_accuracy: 0.7275\n",
      "Epoch 361/500\n",
      "2878/2878 [==============================] - 2s 773us/step - loss: 0.5313 - accuracy: 0.7306 - val_loss: 0.5306 - val_accuracy: 0.7315\n",
      "Epoch 362/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5311 - accuracy: 0.7312 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
      "Epoch 363/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5315 - accuracy: 0.7293 - val_loss: 0.5328 - val_accuracy: 0.7288\n",
      "Epoch 364/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5320 - accuracy: 0.7296 - val_loss: 0.5320 - val_accuracy: 0.7304\n",
      "Epoch 365/500\n",
      "2878/2878 [==============================] - 2s 826us/step - loss: 0.5314 - accuracy: 0.7309 - val_loss: 0.5309 - val_accuracy: 0.7313\n",
      "Epoch 366/500\n",
      "2878/2878 [==============================] - 2s 745us/step - loss: 0.5320 - accuracy: 0.7303 - val_loss: 0.5305 - val_accuracy: 0.7323\n",
      "Epoch 367/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5294 - accuracy: 0.7334 - val_loss: 0.5305 - val_accuracy: 0.7316\n",
      "Epoch 368/500\n",
      "2878/2878 [==============================] - 2s 762us/step - loss: 0.5294 - accuracy: 0.7331 - val_loss: 0.5300 - val_accuracy: 0.7305\n",
      "Epoch 369/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.5321 - accuracy: 0.7278 - val_loss: 0.5303 - val_accuracy: 0.7296\n",
      "Epoch 370/500\n",
      "2878/2878 [==============================] - 2s 756us/step - loss: 0.5297 - accuracy: 0.7303 - val_loss: 0.5314 - val_accuracy: 0.7304\n",
      "Epoch 371/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5282 - accuracy: 0.7331 - val_loss: 0.5312 - val_accuracy: 0.7315\n",
      "Epoch 372/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5285 - accuracy: 0.7321 - val_loss: 0.5331 - val_accuracy: 0.7301\n",
      "Epoch 373/500\n",
      "2878/2878 [==============================] - 2s 756us/step - loss: 0.5325 - accuracy: 0.7289 - val_loss: 0.5332 - val_accuracy: 0.7286\n",
      "Epoch 374/500\n",
      "2878/2878 [==============================] - 3s 914us/step - loss: 0.5296 - accuracy: 0.7315 - val_loss: 0.5366 - val_accuracy: 0.7250\n",
      "Epoch 375/500\n",
      "2878/2878 [==============================] - 2s 802us/step - loss: 0.5299 - accuracy: 0.7318 - val_loss: 0.5308 - val_accuracy: 0.7304\n",
      "Epoch 376/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.5311 - accuracy: 0.7316 - val_loss: 0.5306 - val_accuracy: 0.7306\n",
      "Epoch 377/500\n",
      "2878/2878 [==============================] - 2s 790us/step - loss: 0.5278 - accuracy: 0.7338 - val_loss: 0.5335 - val_accuracy: 0.7294\n",
      "Epoch 378/500\n",
      "2878/2878 [==============================] - 2s 820us/step - loss: 0.5293 - accuracy: 0.7332 - val_loss: 0.5350 - val_accuracy: 0.7279\n",
      "Epoch 379/500\n",
      "2878/2878 [==============================] - 2s 833us/step - loss: 0.5294 - accuracy: 0.7316 - val_loss: 0.5304 - val_accuracy: 0.7313\n",
      "Epoch 380/500\n",
      "2878/2878 [==============================] - 2s 761us/step - loss: 0.5319 - accuracy: 0.7297 - val_loss: 0.5301 - val_accuracy: 0.7312\n",
      "Epoch 381/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.5273 - accuracy: 0.7333 - val_loss: 0.5305 - val_accuracy: 0.7307\n",
      "Epoch 382/500\n",
      "2878/2878 [==============================] - 2s 750us/step - loss: 0.5297 - accuracy: 0.7307 - val_loss: 0.5305 - val_accuracy: 0.7318\n",
      "Epoch 383/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.5292 - accuracy: 0.7327 - val_loss: 0.5308 - val_accuracy: 0.7310\n",
      "Epoch 384/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5291 - accuracy: 0.7317 - val_loss: 0.5307 - val_accuracy: 0.7312\n",
      "Epoch 385/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.5286 - accuracy: 0.7335 - val_loss: 0.5304 - val_accuracy: 0.7313\n",
      "Epoch 386/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5286 - accuracy: 0.7331 - val_loss: 0.5348 - val_accuracy: 0.7274\n",
      "Epoch 387/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5296 - accuracy: 0.7335 - val_loss: 0.5311 - val_accuracy: 0.7305\n",
      "Epoch 388/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5276 - accuracy: 0.7353 - val_loss: 0.5319 - val_accuracy: 0.7287\n",
      "Epoch 389/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5287 - accuracy: 0.7321 - val_loss: 0.5308 - val_accuracy: 0.7296\n",
      "Epoch 390/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5308 - accuracy: 0.7307 - val_loss: 0.5321 - val_accuracy: 0.7297\n",
      "Epoch 391/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5305 - accuracy: 0.7317 - val_loss: 0.5301 - val_accuracy: 0.7308\n",
      "Epoch 392/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5283 - accuracy: 0.7321 - val_loss: 0.5322 - val_accuracy: 0.7308\n",
      "Epoch 393/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5310 - accuracy: 0.7293 - val_loss: 0.5313 - val_accuracy: 0.7292\n",
      "Epoch 394/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5261 - accuracy: 0.7347 - val_loss: 0.5319 - val_accuracy: 0.7281\n",
      "Epoch 395/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5299 - accuracy: 0.7311 - val_loss: 0.5318 - val_accuracy: 0.7290\n",
      "Epoch 396/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5296 - accuracy: 0.7324 - val_loss: 0.5312 - val_accuracy: 0.7303\n",
      "Epoch 397/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5310 - accuracy: 0.7314 - val_loss: 0.5301 - val_accuracy: 0.7291\n",
      "Epoch 398/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5294 - accuracy: 0.7316 - val_loss: 0.5319 - val_accuracy: 0.7300\n",
      "Epoch 399/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5293 - accuracy: 0.7338 - val_loss: 0.5303 - val_accuracy: 0.7318\n",
      "Epoch 400/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.5292 - accuracy: 0.7307 - val_loss: 0.5307 - val_accuracy: 0.7317\n",
      "Epoch 401/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5294 - accuracy: 0.7324 - val_loss: 0.5317 - val_accuracy: 0.7295\n",
      "Epoch 402/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5271 - accuracy: 0.7339 - val_loss: 0.5336 - val_accuracy: 0.7285\n",
      "Epoch 403/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.5304 - accuracy: 0.7300 - val_loss: 0.5301 - val_accuracy: 0.7319\n",
      "Epoch 404/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5298 - accuracy: 0.7309 - val_loss: 0.5321 - val_accuracy: 0.7305\n",
      "Epoch 405/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5253 - accuracy: 0.7339 - val_loss: 0.5357 - val_accuracy: 0.7259\n",
      "Epoch 406/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5291 - accuracy: 0.7326 - val_loss: 0.5326 - val_accuracy: 0.7306\n",
      "Epoch 407/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.5312 - accuracy: 0.7305 - val_loss: 0.5304 - val_accuracy: 0.7304\n",
      "Epoch 408/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5299 - accuracy: 0.7318 - val_loss: 0.5303 - val_accuracy: 0.7314\n",
      "Epoch 409/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.5314 - accuracy: 0.7286 - val_loss: 0.5308 - val_accuracy: 0.7318\n",
      "Epoch 410/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.5269 - accuracy: 0.7339 - val_loss: 0.5311 - val_accuracy: 0.7289\n",
      "Epoch 411/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5265 - accuracy: 0.7340 - val_loss: 0.5294 - val_accuracy: 0.7315\n",
      "Epoch 412/500\n",
      "2878/2878 [==============================] - 2s 776us/step - loss: 0.5279 - accuracy: 0.7318 - val_loss: 0.5316 - val_accuracy: 0.7301\n",
      "Epoch 413/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.5314 - accuracy: 0.7309 - val_loss: 0.5340 - val_accuracy: 0.7312\n",
      "Epoch 414/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.5273 - accuracy: 0.7333 - val_loss: 0.5322 - val_accuracy: 0.7302\n",
      "Epoch 415/500\n",
      "2878/2878 [==============================] - 2s 830us/step - loss: 0.5279 - accuracy: 0.7339 - val_loss: 0.5335 - val_accuracy: 0.7275\n",
      "Epoch 416/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.5294 - accuracy: 0.7337 - val_loss: 0.5316 - val_accuracy: 0.7314\n",
      "Epoch 417/500\n",
      "2878/2878 [==============================] - 2s 755us/step - loss: 0.5275 - accuracy: 0.7339 - val_loss: 0.5321 - val_accuracy: 0.7299\n",
      "Epoch 418/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.5281 - accuracy: 0.7350 - val_loss: 0.5301 - val_accuracy: 0.7305\n",
      "Epoch 419/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5289 - accuracy: 0.7318 - val_loss: 0.5321 - val_accuracy: 0.7284\n",
      "Epoch 420/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5282 - accuracy: 0.7328 - val_loss: 0.5311 - val_accuracy: 0.7296\n",
      "Epoch 421/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5286 - accuracy: 0.7315 - val_loss: 0.5332 - val_accuracy: 0.7288\n",
      "Epoch 422/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5286 - accuracy: 0.7330 - val_loss: 0.5303 - val_accuracy: 0.7316\n",
      "Epoch 423/500\n",
      "2878/2878 [==============================] - 2s 668us/step - loss: 0.5309 - accuracy: 0.7315 - val_loss: 0.5303 - val_accuracy: 0.7310\n",
      "Epoch 424/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5267 - accuracy: 0.7328 - val_loss: 0.5326 - val_accuracy: 0.7283\n",
      "Epoch 425/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5291 - accuracy: 0.7315 - val_loss: 0.5338 - val_accuracy: 0.7269\n",
      "Epoch 426/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.5289 - accuracy: 0.7336 - val_loss: 0.5318 - val_accuracy: 0.7296\n",
      "Epoch 427/500\n",
      "2878/2878 [==============================] - 2s 666us/step - loss: 0.5309 - accuracy: 0.7295 - val_loss: 0.5296 - val_accuracy: 0.7308\n",
      "Epoch 428/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5294 - accuracy: 0.7314 - val_loss: 0.5326 - val_accuracy: 0.7281\n",
      "Epoch 429/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5302 - accuracy: 0.7320 - val_loss: 0.5307 - val_accuracy: 0.7307\n",
      "Epoch 430/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5303 - accuracy: 0.7301 - val_loss: 0.5298 - val_accuracy: 0.7334\n",
      "Epoch 431/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5275 - accuracy: 0.7336 - val_loss: 0.5324 - val_accuracy: 0.7298\n",
      "Epoch 432/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5299 - accuracy: 0.7327 - val_loss: 0.5310 - val_accuracy: 0.7292\n",
      "Epoch 433/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5313 - accuracy: 0.7287 - val_loss: 0.5344 - val_accuracy: 0.7269\n",
      "Epoch 434/500\n",
      "2878/2878 [==============================] - 2s 750us/step - loss: 0.5321 - accuracy: 0.7291 - val_loss: 0.5299 - val_accuracy: 0.7313\n",
      "Epoch 435/500\n",
      "2878/2878 [==============================] - 2s 773us/step - loss: 0.5286 - accuracy: 0.7337 - val_loss: 0.5303 - val_accuracy: 0.7302\n",
      "Epoch 436/500\n",
      "2878/2878 [==============================] - 2s 785us/step - loss: 0.5287 - accuracy: 0.7332 - val_loss: 0.5324 - val_accuracy: 0.7272\n",
      "Epoch 437/500\n",
      "2878/2878 [==============================] - 2s 807us/step - loss: 0.5255 - accuracy: 0.7355 - val_loss: 0.5309 - val_accuracy: 0.7315\n",
      "Epoch 438/500\n",
      "2878/2878 [==============================] - 2s 785us/step - loss: 0.5295 - accuracy: 0.7320 - val_loss: 0.5305 - val_accuracy: 0.7295\n",
      "Epoch 439/500\n",
      "2878/2878 [==============================] - 2s 755us/step - loss: 0.5289 - accuracy: 0.7313 - val_loss: 0.5320 - val_accuracy: 0.7287\n",
      "Epoch 440/500\n",
      "2878/2878 [==============================] - 2s 752us/step - loss: 0.5303 - accuracy: 0.7293 - val_loss: 0.5304 - val_accuracy: 0.7314\n",
      "Epoch 441/500\n",
      "2878/2878 [==============================] - 2s 755us/step - loss: 0.5270 - accuracy: 0.7348 - val_loss: 0.5339 - val_accuracy: 0.7291\n",
      "Epoch 442/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.5279 - accuracy: 0.7323 - val_loss: 0.5295 - val_accuracy: 0.7321\n",
      "Epoch 443/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.5294 - accuracy: 0.7318 - val_loss: 0.5299 - val_accuracy: 0.7303\n",
      "Epoch 444/500\n",
      "2878/2878 [==============================] - 2s 766us/step - loss: 0.5283 - accuracy: 0.7332 - val_loss: 0.5303 - val_accuracy: 0.7297\n",
      "Epoch 445/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.5289 - accuracy: 0.7318 - val_loss: 0.5311 - val_accuracy: 0.7288\n",
      "Epoch 446/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5283 - accuracy: 0.7323 - val_loss: 0.5307 - val_accuracy: 0.7306\n",
      "Epoch 447/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5295 - accuracy: 0.7313 - val_loss: 0.5309 - val_accuracy: 0.7300\n",
      "Epoch 448/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5306 - accuracy: 0.7319 - val_loss: 0.5324 - val_accuracy: 0.7281\n",
      "Epoch 449/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.5303 - accuracy: 0.7309 - val_loss: 0.5328 - val_accuracy: 0.7276\n",
      "Epoch 450/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5273 - accuracy: 0.7348 - val_loss: 0.5303 - val_accuracy: 0.7298\n",
      "Epoch 451/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5255 - accuracy: 0.7338 - val_loss: 0.5318 - val_accuracy: 0.7290\n",
      "Epoch 452/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.5258 - accuracy: 0.7339 - val_loss: 0.5309 - val_accuracy: 0.7314\n",
      "Epoch 453/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.5295 - accuracy: 0.7320 - val_loss: 0.5309 - val_accuracy: 0.7293\n",
      "Epoch 454/500\n",
      "2878/2878 [==============================] - 2s 784us/step - loss: 0.5310 - accuracy: 0.7295 - val_loss: 0.5371 - val_accuracy: 0.7266\n",
      "Epoch 455/500\n",
      "2878/2878 [==============================] - 2s 799us/step - loss: 0.5306 - accuracy: 0.7318 - val_loss: 0.5308 - val_accuracy: 0.7310\n",
      "Epoch 456/500\n",
      "2878/2878 [==============================] - 2s 770us/step - loss: 0.5279 - accuracy: 0.7337 - val_loss: 0.5327 - val_accuracy: 0.7306\n",
      "Epoch 457/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5303 - accuracy: 0.7312 - val_loss: 0.5326 - val_accuracy: 0.7278\n",
      "Epoch 458/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5276 - accuracy: 0.7322 - val_loss: 0.5302 - val_accuracy: 0.7312\n",
      "Epoch 459/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5300 - accuracy: 0.7327 - val_loss: 0.5335 - val_accuracy: 0.7283\n",
      "Epoch 460/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5291 - accuracy: 0.7303 - val_loss: 0.5314 - val_accuracy: 0.7291\n",
      "Epoch 461/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5272 - accuracy: 0.7337 - val_loss: 0.5305 - val_accuracy: 0.7326\n",
      "Epoch 462/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5299 - accuracy: 0.7310 - val_loss: 0.5294 - val_accuracy: 0.7315\n",
      "Epoch 463/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5314 - accuracy: 0.7294 - val_loss: 0.5308 - val_accuracy: 0.7309\n",
      "Epoch 464/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5264 - accuracy: 0.7364 - val_loss: 0.5308 - val_accuracy: 0.7301\n",
      "Epoch 465/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5303 - accuracy: 0.7315 - val_loss: 0.5354 - val_accuracy: 0.7284\n",
      "Epoch 466/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5300 - accuracy: 0.7306 - val_loss: 0.5310 - val_accuracy: 0.7305\n",
      "Epoch 467/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5285 - accuracy: 0.7330 - val_loss: 0.5296 - val_accuracy: 0.7316\n",
      "Epoch 468/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5309 - accuracy: 0.7311 - val_loss: 0.5317 - val_accuracy: 0.7278\n",
      "Epoch 469/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5299 - accuracy: 0.7308 - val_loss: 0.5310 - val_accuracy: 0.7307\n",
      "Epoch 470/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5300 - accuracy: 0.7328 - val_loss: 0.5307 - val_accuracy: 0.7311\n",
      "Epoch 471/500\n",
      "2878/2878 [==============================] - 2s 672us/step - loss: 0.5260 - accuracy: 0.7340 - val_loss: 0.5303 - val_accuracy: 0.7318\n",
      "Epoch 472/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5284 - accuracy: 0.7331 - val_loss: 0.5307 - val_accuracy: 0.7309\n",
      "Epoch 473/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5315 - accuracy: 0.7308 - val_loss: 0.5312 - val_accuracy: 0.7291\n",
      "Epoch 474/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5282 - accuracy: 0.7324 - val_loss: 0.5327 - val_accuracy: 0.7300\n",
      "Epoch 475/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5299 - accuracy: 0.7322 - val_loss: 0.5342 - val_accuracy: 0.7253\n",
      "Epoch 476/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.5294 - accuracy: 0.7322 - val_loss: 0.5308 - val_accuracy: 0.7319\n",
      "Epoch 477/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5309 - accuracy: 0.7302 - val_loss: 0.5301 - val_accuracy: 0.7315\n",
      "Epoch 478/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5274 - accuracy: 0.7326 - val_loss: 0.5325 - val_accuracy: 0.7282\n",
      "Epoch 479/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5300 - accuracy: 0.7336 - val_loss: 0.5295 - val_accuracy: 0.7312\n",
      "Epoch 480/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5271 - accuracy: 0.7321 - val_loss: 0.5304 - val_accuracy: 0.7313\n",
      "Epoch 481/500\n",
      "2878/2878 [==============================] - 2s 672us/step - loss: 0.5272 - accuracy: 0.7348 - val_loss: 0.5331 - val_accuracy: 0.7248\n",
      "Epoch 482/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5309 - accuracy: 0.7306 - val_loss: 0.5348 - val_accuracy: 0.7289\n",
      "Epoch 483/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5301 - accuracy: 0.7312 - val_loss: 0.5295 - val_accuracy: 0.7318\n",
      "Epoch 484/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5312 - accuracy: 0.7293 - val_loss: 0.5286 - val_accuracy: 0.7324\n",
      "Epoch 485/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5288 - accuracy: 0.7314 - val_loss: 0.5301 - val_accuracy: 0.7308\n",
      "Epoch 486/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5277 - accuracy: 0.7333 - val_loss: 0.5300 - val_accuracy: 0.7313\n",
      "Epoch 487/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5285 - accuracy: 0.7313 - val_loss: 0.5322 - val_accuracy: 0.7312\n",
      "Epoch 488/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5281 - accuracy: 0.7331 - val_loss: 0.5316 - val_accuracy: 0.7293\n",
      "Epoch 489/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5296 - accuracy: 0.7310 - val_loss: 0.5319 - val_accuracy: 0.7298\n",
      "Epoch 490/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5321 - accuracy: 0.7302 - val_loss: 0.5299 - val_accuracy: 0.7310\n",
      "Epoch 491/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5297 - accuracy: 0.7310 - val_loss: 0.5307 - val_accuracy: 0.7306\n",
      "Epoch 492/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.5297 - accuracy: 0.7321 - val_loss: 0.5314 - val_accuracy: 0.7305\n",
      "Epoch 493/500\n",
      "2878/2878 [==============================] - 2s 754us/step - loss: 0.5307 - accuracy: 0.7307 - val_loss: 0.5314 - val_accuracy: 0.7310\n",
      "Epoch 494/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5273 - accuracy: 0.7338 - val_loss: 0.5295 - val_accuracy: 0.7302\n",
      "Epoch 495/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5297 - accuracy: 0.7326 - val_loss: 0.5318 - val_accuracy: 0.7301\n",
      "Epoch 496/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5315 - accuracy: 0.7307 - val_loss: 0.5312 - val_accuracy: 0.7292\n",
      "Epoch 497/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5302 - accuracy: 0.7307 - val_loss: 0.5306 - val_accuracy: 0.7306\n",
      "Epoch 498/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5288 - accuracy: 0.7315 - val_loss: 0.5292 - val_accuracy: 0.7307\n",
      "Epoch 499/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5272 - accuracy: 0.7334 - val_loss: 0.5301 - val_accuracy: 0.7309\n",
      "Epoch 500/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.5291 - accuracy: 0.7336 - val_loss: 0.5293 - val_accuracy: 0.7320\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(shuffle(pd.DataFrame(x_train_resampled),random_state=1), shuffle(pd.DataFrame(y_train_resampled),random_state=1), epochs=500,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train_resampled)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_10.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 11\n",
    "-Robust Scaler & Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 362\n",
      "Trainable params: 362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2878/2878 [==============================] - 3s 802us/step - loss: 0.6086 - accuracy: 0.6619 - val_loss: 0.5586 - val_accuracy: 0.7053\n",
      "Epoch 2/500\n",
      "2878/2878 [==============================] - 2s 650us/step - loss: 0.5585 - accuracy: 0.7063 - val_loss: 0.5511 - val_accuracy: 0.7124\n",
      "Epoch 3/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.5497 - accuracy: 0.7137 - val_loss: 0.5459 - val_accuracy: 0.7191\n",
      "Epoch 4/500\n",
      "2878/2878 [==============================] - 2s 646us/step - loss: 0.5458 - accuracy: 0.7206 - val_loss: 0.5400 - val_accuracy: 0.7246\n",
      "Epoch 5/500\n",
      "2878/2878 [==============================] - 2s 643us/step - loss: 0.5438 - accuracy: 0.7203 - val_loss: 0.5372 - val_accuracy: 0.7223\n",
      "Epoch 6/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5393 - accuracy: 0.7235 - val_loss: 0.5349 - val_accuracy: 0.7261\n",
      "Epoch 7/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5357 - accuracy: 0.7272 - val_loss: 0.5340 - val_accuracy: 0.7274\n",
      "Epoch 8/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5325 - accuracy: 0.7279 - val_loss: 0.5297 - val_accuracy: 0.7325\n",
      "Epoch 9/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5312 - accuracy: 0.7306 - val_loss: 0.5276 - val_accuracy: 0.7338\n",
      "Epoch 10/500\n",
      "2878/2878 [==============================] - 2s 667us/step - loss: 0.5281 - accuracy: 0.7322 - val_loss: 0.5255 - val_accuracy: 0.7325\n",
      "Epoch 11/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5423 - accuracy: 0.7279 - val_loss: 0.5294 - val_accuracy: 0.7322\n",
      "Epoch 12/500\n",
      "2878/2878 [==============================] - 2s 769us/step - loss: 0.5321 - accuracy: 0.7272 - val_loss: 0.5230 - val_accuracy: 0.7343\n",
      "Epoch 13/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.5246 - accuracy: 0.7343 - val_loss: 0.5254 - val_accuracy: 0.7338\n",
      "Epoch 14/500\n",
      "2878/2878 [==============================] - 2s 670us/step - loss: 0.5245 - accuracy: 0.7325 - val_loss: 0.5224 - val_accuracy: 0.7338\n",
      "Epoch 15/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5253 - accuracy: 0.7333 - val_loss: 0.5195 - val_accuracy: 0.7374\n",
      "Epoch 16/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5218 - accuracy: 0.7364 - val_loss: 0.5179 - val_accuracy: 0.7404\n",
      "Epoch 17/500\n",
      "2878/2878 [==============================] - 2s 640us/step - loss: 0.5228 - accuracy: 0.7342 - val_loss: 0.5175 - val_accuracy: 0.7377\n",
      "Epoch 18/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.5212 - accuracy: 0.7357 - val_loss: 0.5186 - val_accuracy: 0.7360\n",
      "Epoch 19/500\n",
      "2878/2878 [==============================] - 2s 664us/step - loss: 0.5225 - accuracy: 0.7347 - val_loss: 0.5251 - val_accuracy: 0.7354\n",
      "Epoch 20/500\n",
      "2878/2878 [==============================] - 2s 655us/step - loss: 0.5195 - accuracy: 0.7374 - val_loss: 0.5169 - val_accuracy: 0.7405\n",
      "Epoch 21/500\n",
      "2878/2878 [==============================] - 2s 645us/step - loss: 0.5200 - accuracy: 0.7382 - val_loss: 0.5183 - val_accuracy: 0.7367\n",
      "Epoch 22/500\n",
      "2878/2878 [==============================] - 2s 647us/step - loss: 0.5181 - accuracy: 0.7375 - val_loss: 0.5175 - val_accuracy: 0.7362\n",
      "Epoch 23/500\n",
      "2878/2878 [==============================] - 2s 611us/step - loss: 0.5162 - accuracy: 0.7404 - val_loss: 0.5175 - val_accuracy: 0.7371\n",
      "Epoch 24/500\n",
      "2878/2878 [==============================] - 2s 629us/step - loss: 0.5140 - accuracy: 0.7405 - val_loss: 0.5181 - val_accuracy: 0.7420\n",
      "Epoch 25/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5155 - accuracy: 0.7406 - val_loss: 0.5199 - val_accuracy: 0.7350\n",
      "Epoch 26/500\n",
      "2878/2878 [==============================] - 2s 660us/step - loss: 0.5176 - accuracy: 0.7376 - val_loss: 0.5155 - val_accuracy: 0.7402\n",
      "Epoch 27/500\n",
      "2878/2878 [==============================] - 2s 747us/step - loss: 0.5170 - accuracy: 0.7407 - val_loss: 0.5171 - val_accuracy: 0.7390\n",
      "Epoch 28/500\n",
      "2878/2878 [==============================] - 2s 776us/step - loss: 0.5162 - accuracy: 0.7424 - val_loss: 0.5151 - val_accuracy: 0.7427\n",
      "Epoch 29/500\n",
      "2878/2878 [==============================] - 2s 798us/step - loss: 0.5147 - accuracy: 0.7419 - val_loss: 0.5161 - val_accuracy: 0.7419\n",
      "Epoch 30/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.5126 - accuracy: 0.7425 - val_loss: 0.5169 - val_accuracy: 0.7370\n",
      "Epoch 31/500\n",
      "2878/2878 [==============================] - 2s 637us/step - loss: 0.5179 - accuracy: 0.7402 - val_loss: 0.5141 - val_accuracy: 0.7436\n",
      "Epoch 32/500\n",
      "2878/2878 [==============================] - 2s 620us/step - loss: 0.5140 - accuracy: 0.7428 - val_loss: 0.5189 - val_accuracy: 0.7392\n",
      "Epoch 33/500\n",
      "2878/2878 [==============================] - 3s 906us/step - loss: 0.5146 - accuracy: 0.7397 - val_loss: 0.5176 - val_accuracy: 0.7376\n",
      "Epoch 34/500\n",
      "2878/2878 [==============================] - 3s 874us/step - loss: 0.5122 - accuracy: 0.7417 - val_loss: 0.5176 - val_accuracy: 0.7388\n",
      "Epoch 35/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5153 - accuracy: 0.7413 - val_loss: 0.5137 - val_accuracy: 0.7406\n",
      "Epoch 36/500\n",
      "2878/2878 [==============================] - 2s 646us/step - loss: 0.5153 - accuracy: 0.7409 - val_loss: 0.5203 - val_accuracy: 0.7400\n",
      "Epoch 37/500\n",
      "2878/2878 [==============================] - 2s 669us/step - loss: 0.5137 - accuracy: 0.7423 - val_loss: 0.5183 - val_accuracy: 0.7410\n",
      "Epoch 38/500\n",
      "2878/2878 [==============================] - 2s 645us/step - loss: 0.5125 - accuracy: 0.7459 - val_loss: 0.5164 - val_accuracy: 0.7391\n",
      "Epoch 39/500\n",
      "2878/2878 [==============================] - 2s 628us/step - loss: 0.5124 - accuracy: 0.7433 - val_loss: 0.5219 - val_accuracy: 0.7389\n",
      "Epoch 40/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5125 - accuracy: 0.7428 - val_loss: 0.5144 - val_accuracy: 0.7393\n",
      "Epoch 41/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5149 - accuracy: 0.7404 - val_loss: 0.5141 - val_accuracy: 0.7437\n",
      "Epoch 42/500\n",
      "2878/2878 [==============================] - 2s 647us/step - loss: 0.5142 - accuracy: 0.7407 - val_loss: 0.5150 - val_accuracy: 0.7434\n",
      "Epoch 43/500\n",
      "2878/2878 [==============================] - 2s 630us/step - loss: 0.5146 - accuracy: 0.7414 - val_loss: 0.5136 - val_accuracy: 0.7419\n",
      "Epoch 44/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5113 - accuracy: 0.7464 - val_loss: 0.5146 - val_accuracy: 0.7439\n",
      "Epoch 45/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5146 - accuracy: 0.7430 - val_loss: 0.5122 - val_accuracy: 0.7423\n",
      "Epoch 46/500\n",
      "2878/2878 [==============================] - 2s 788us/step - loss: 0.5104 - accuracy: 0.7466 - val_loss: 0.5122 - val_accuracy: 0.7437\n",
      "Epoch 47/500\n",
      "2878/2878 [==============================] - 2s 801us/step - loss: 0.5127 - accuracy: 0.7449 - val_loss: 0.5172 - val_accuracy: 0.7375\n",
      "Epoch 48/500\n",
      "2878/2878 [==============================] - 2s 828us/step - loss: 0.5122 - accuracy: 0.7434 - val_loss: 0.5138 - val_accuracy: 0.7438\n",
      "Epoch 49/500\n",
      "2878/2878 [==============================] - 2s 652us/step - loss: 0.5127 - accuracy: 0.7417 - val_loss: 0.5150 - val_accuracy: 0.7394\n",
      "Epoch 50/500\n",
      "2878/2878 [==============================] - 2s 643us/step - loss: 0.5151 - accuracy: 0.7411 - val_loss: 0.5145 - val_accuracy: 0.7432\n",
      "Epoch 51/500\n",
      "2878/2878 [==============================] - 2s 629us/step - loss: 0.5151 - accuracy: 0.7426 - val_loss: 0.5152 - val_accuracy: 0.7430\n",
      "Epoch 52/500\n",
      "2878/2878 [==============================] - 2s 643us/step - loss: 0.5145 - accuracy: 0.7420 - val_loss: 0.5233 - val_accuracy: 0.7423\n",
      "Epoch 53/500\n",
      "2878/2878 [==============================] - 2s 660us/step - loss: 0.5147 - accuracy: 0.7414 - val_loss: 0.5128 - val_accuracy: 0.7468\n",
      "Epoch 54/500\n",
      "2878/2878 [==============================] - 2s 647us/step - loss: 0.5110 - accuracy: 0.7440 - val_loss: 0.5125 - val_accuracy: 0.7444\n",
      "Epoch 55/500\n",
      "2878/2878 [==============================] - 2s 624us/step - loss: 0.5145 - accuracy: 0.7409 - val_loss: 0.5121 - val_accuracy: 0.7421\n",
      "Epoch 56/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5140 - accuracy: 0.7410 - val_loss: 0.5145 - val_accuracy: 0.7388\n",
      "Epoch 57/500\n",
      "2878/2878 [==============================] - 2s 659us/step - loss: 0.5148 - accuracy: 0.7405 - val_loss: 0.5139 - val_accuracy: 0.7430\n",
      "Epoch 58/500\n",
      "2878/2878 [==============================] - 2s 631us/step - loss: 0.5131 - accuracy: 0.7440 - val_loss: 0.5148 - val_accuracy: 0.7439\n",
      "Epoch 59/500\n",
      "2878/2878 [==============================] - 2s 635us/step - loss: 0.5121 - accuracy: 0.7445 - val_loss: 0.5133 - val_accuracy: 0.7436\n",
      "Epoch 60/500\n",
      "2878/2878 [==============================] - 2s 655us/step - loss: 0.5117 - accuracy: 0.7429 - val_loss: 0.5145 - val_accuracy: 0.7433\n",
      "Epoch 61/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5160 - accuracy: 0.7410 - val_loss: 0.5175 - val_accuracy: 0.7404\n",
      "Epoch 62/500\n",
      "2878/2878 [==============================] - 2s 667us/step - loss: 0.5122 - accuracy: 0.7450 - val_loss: 0.5127 - val_accuracy: 0.7427\n",
      "Epoch 63/500\n",
      "2878/2878 [==============================] - 2s 663us/step - loss: 0.5120 - accuracy: 0.7432 - val_loss: 0.5122 - val_accuracy: 0.7444\n",
      "Epoch 64/500\n",
      "2878/2878 [==============================] - 2s 667us/step - loss: 0.5115 - accuracy: 0.7439 - val_loss: 0.5124 - val_accuracy: 0.7445\n",
      "Epoch 65/500\n",
      "2878/2878 [==============================] - 2s 659us/step - loss: 0.5109 - accuracy: 0.7445 - val_loss: 0.5121 - val_accuracy: 0.7444\n",
      "Epoch 66/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5087 - accuracy: 0.7454 - val_loss: 0.5144 - val_accuracy: 0.7430\n",
      "Epoch 67/500\n",
      "2878/2878 [==============================] - 2s 635us/step - loss: 0.5097 - accuracy: 0.7457 - val_loss: 0.5129 - val_accuracy: 0.7450\n",
      "Epoch 68/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5129 - accuracy: 0.7425 - val_loss: 0.5152 - val_accuracy: 0.7422\n",
      "Epoch 69/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5139 - accuracy: 0.7409 - val_loss: 0.5146 - val_accuracy: 0.7406\n",
      "Epoch 70/500\n",
      "2878/2878 [==============================] - 2s 665us/step - loss: 0.5124 - accuracy: 0.7435 - val_loss: 0.5123 - val_accuracy: 0.7472\n",
      "Epoch 71/500\n",
      "2878/2878 [==============================] - 2s 644us/step - loss: 0.5128 - accuracy: 0.7432 - val_loss: 0.5132 - val_accuracy: 0.7452\n",
      "Epoch 72/500\n",
      "2878/2878 [==============================] - 2s 659us/step - loss: 0.5100 - accuracy: 0.7449 - val_loss: 0.5132 - val_accuracy: 0.7430\n",
      "Epoch 73/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5114 - accuracy: 0.7434 - val_loss: 0.5138 - val_accuracy: 0.7440\n",
      "Epoch 74/500\n",
      "2878/2878 [==============================] - 2s 666us/step - loss: 0.5114 - accuracy: 0.7453 - val_loss: 0.5120 - val_accuracy: 0.7444\n",
      "Epoch 75/500\n",
      "2878/2878 [==============================] - 2s 664us/step - loss: 0.5096 - accuracy: 0.7456 - val_loss: 0.5157 - val_accuracy: 0.7403\n",
      "Epoch 76/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5101 - accuracy: 0.7424 - val_loss: 0.5116 - val_accuracy: 0.7446\n",
      "Epoch 77/500\n",
      "2878/2878 [==============================] - 2s 664us/step - loss: 0.5109 - accuracy: 0.7448 - val_loss: 0.5112 - val_accuracy: 0.7443\n",
      "Epoch 78/500\n",
      "2878/2878 [==============================] - 2s 652us/step - loss: 0.5137 - accuracy: 0.7418 - val_loss: 0.5199 - val_accuracy: 0.7364\n",
      "Epoch 79/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.5128 - accuracy: 0.7413 - val_loss: 0.5123 - val_accuracy: 0.7470\n",
      "Epoch 80/500\n",
      "2878/2878 [==============================] - 2s 667us/step - loss: 0.5151 - accuracy: 0.7406 - val_loss: 0.5188 - val_accuracy: 0.7454\n",
      "Epoch 81/500\n",
      "2878/2878 [==============================] - 2s 649us/step - loss: 0.5107 - accuracy: 0.7461 - val_loss: 0.5124 - val_accuracy: 0.7431\n",
      "Epoch 82/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5114 - accuracy: 0.7436 - val_loss: 0.5112 - val_accuracy: 0.7447\n",
      "Epoch 83/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5112 - accuracy: 0.7441 - val_loss: 0.5182 - val_accuracy: 0.7433\n",
      "Epoch 84/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5134 - accuracy: 0.7442 - val_loss: 0.5113 - val_accuracy: 0.7460\n",
      "Epoch 85/500\n",
      "2878/2878 [==============================] - 2s 668us/step - loss: 0.5102 - accuracy: 0.7427 - val_loss: 0.5152 - val_accuracy: 0.7414\n",
      "Epoch 86/500\n",
      "2878/2878 [==============================] - 2s 668us/step - loss: 0.5100 - accuracy: 0.7460 - val_loss: 0.5111 - val_accuracy: 0.7461\n",
      "Epoch 87/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.5147 - accuracy: 0.7426 - val_loss: 0.5163 - val_accuracy: 0.7449\n",
      "Epoch 88/500\n",
      "2878/2878 [==============================] - 2s 793us/step - loss: 0.5117 - accuracy: 0.7456 - val_loss: 0.5121 - val_accuracy: 0.7457\n",
      "Epoch 89/500\n",
      "2878/2878 [==============================] - 2s 665us/step - loss: 0.5115 - accuracy: 0.7427 - val_loss: 0.5112 - val_accuracy: 0.7443\n",
      "Epoch 90/500\n",
      "2878/2878 [==============================] - 2s 644us/step - loss: 0.5118 - accuracy: 0.7425 - val_loss: 0.5127 - val_accuracy: 0.7455\n",
      "Epoch 91/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5109 - accuracy: 0.7442 - val_loss: 0.5112 - val_accuracy: 0.7450\n",
      "Epoch 92/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5111 - accuracy: 0.7446 - val_loss: 0.5127 - val_accuracy: 0.7463\n",
      "Epoch 93/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5099 - accuracy: 0.7450 - val_loss: 0.5094 - val_accuracy: 0.7463\n",
      "Epoch 94/500\n",
      "2878/2878 [==============================] - 2s 671us/step - loss: 0.5088 - accuracy: 0.7456 - val_loss: 0.5136 - val_accuracy: 0.7457\n",
      "Epoch 95/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5126 - accuracy: 0.7439 - val_loss: 0.5122 - val_accuracy: 0.7455\n",
      "Epoch 96/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.5085 - accuracy: 0.7464 - val_loss: 0.5147 - val_accuracy: 0.7441\n",
      "Epoch 97/500\n",
      "2878/2878 [==============================] - 2s 669us/step - loss: 0.5100 - accuracy: 0.7438 - val_loss: 0.5114 - val_accuracy: 0.7437\n",
      "Epoch 98/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5092 - accuracy: 0.7440 - val_loss: 0.5117 - val_accuracy: 0.7450\n",
      "Epoch 99/500\n",
      "2878/2878 [==============================] - 8s 3ms/step - loss: 0.5106 - accuracy: 0.7436 - val_loss: 0.5099 - val_accuracy: 0.7451\n",
      "Epoch 100/500\n",
      "2878/2878 [==============================] - 2s 660us/step - loss: 0.5117 - accuracy: 0.7426 - val_loss: 0.5105 - val_accuracy: 0.7429\n",
      "Epoch 101/500\n",
      "2878/2878 [==============================] - 2s 639us/step - loss: 0.5122 - accuracy: 0.7452 - val_loss: 0.5091 - val_accuracy: 0.7453\n",
      "Epoch 102/500\n",
      "2878/2878 [==============================] - 2s 638us/step - loss: 0.5091 - accuracy: 0.7426 - val_loss: 0.5086 - val_accuracy: 0.7467\n",
      "Epoch 103/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5075 - accuracy: 0.7468 - val_loss: 0.5086 - val_accuracy: 0.7470\n",
      "Epoch 104/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.5097 - accuracy: 0.7442 - val_loss: 0.5157 - val_accuracy: 0.7399\n",
      "Epoch 105/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5102 - accuracy: 0.7456 - val_loss: 0.5133 - val_accuracy: 0.7433\n",
      "Epoch 106/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.5101 - accuracy: 0.7437 - val_loss: 0.5093 - val_accuracy: 0.7481\n",
      "Epoch 107/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5087 - accuracy: 0.7440 - val_loss: 0.5112 - val_accuracy: 0.7459\n",
      "Epoch 108/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5085 - accuracy: 0.7457 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 109/500\n",
      "2878/2878 [==============================] - 2s 802us/step - loss: 0.5107 - accuracy: 0.7423 - val_loss: 0.5088 - val_accuracy: 0.7431\n",
      "Epoch 110/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.5137 - accuracy: 0.7425 - val_loss: 0.5090 - val_accuracy: 0.7467\n",
      "Epoch 111/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.5091 - accuracy: 0.7454 - val_loss: 0.5088 - val_accuracy: 0.7453\n",
      "Epoch 112/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5110 - accuracy: 0.7415 - val_loss: 0.5106 - val_accuracy: 0.7484\n",
      "Epoch 113/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5104 - accuracy: 0.7447 - val_loss: 0.5123 - val_accuracy: 0.7425\n",
      "Epoch 114/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5064 - accuracy: 0.7462 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 115/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5110 - accuracy: 0.7433 - val_loss: 0.5087 - val_accuracy: 0.7478\n",
      "Epoch 116/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5074 - accuracy: 0.7452 - val_loss: 0.5073 - val_accuracy: 0.7497\n",
      "Epoch 117/500\n",
      "2878/2878 [==============================] - 2s 670us/step - loss: 0.5075 - accuracy: 0.7473 - val_loss: 0.5101 - val_accuracy: 0.7447\n",
      "Epoch 118/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5063 - accuracy: 0.7462 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
      "Epoch 119/500\n",
      "2878/2878 [==============================] - 2s 666us/step - loss: 0.5074 - accuracy: 0.7460 - val_loss: 0.5116 - val_accuracy: 0.7440\n",
      "Epoch 120/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5065 - accuracy: 0.7482 - val_loss: 0.5081 - val_accuracy: 0.7489\n",
      "Epoch 121/500\n",
      "2878/2878 [==============================] - 2s 668us/step - loss: 0.5095 - accuracy: 0.7435 - val_loss: 0.5111 - val_accuracy: 0.7435\n",
      "Epoch 122/500\n",
      "2878/2878 [==============================] - 2s 669us/step - loss: 0.5078 - accuracy: 0.7460 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 123/500\n",
      "2878/2878 [==============================] - 2s 667us/step - loss: 0.5081 - accuracy: 0.7478 - val_loss: 0.5086 - val_accuracy: 0.7477\n",
      "Epoch 124/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5104 - accuracy: 0.7449 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 125/500\n",
      "2878/2878 [==============================] - 2s 669us/step - loss: 0.5074 - accuracy: 0.7452 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
      "Epoch 126/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5094 - accuracy: 0.7451 - val_loss: 0.5073 - val_accuracy: 0.7489\n",
      "Epoch 127/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5067 - accuracy: 0.7465 - val_loss: 0.5102 - val_accuracy: 0.7474\n",
      "Epoch 128/500\n",
      "2878/2878 [==============================] - 2s 672us/step - loss: 0.5077 - accuracy: 0.7444 - val_loss: 0.5106 - val_accuracy: 0.7429\n",
      "Epoch 129/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.5073 - accuracy: 0.7458 - val_loss: 0.5079 - val_accuracy: 0.7499\n",
      "Epoch 130/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.5062 - accuracy: 0.7466 - val_loss: 0.5086 - val_accuracy: 0.7440\n",
      "Epoch 131/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5062 - accuracy: 0.7463 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 132/500\n",
      "2878/2878 [==============================] - 2s 671us/step - loss: 0.5065 - accuracy: 0.7471 - val_loss: 0.5094 - val_accuracy: 0.7479\n",
      "Epoch 133/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5064 - accuracy: 0.7479 - val_loss: 0.5076 - val_accuracy: 0.7465\n",
      "Epoch 134/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5044 - accuracy: 0.7496 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 135/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5068 - accuracy: 0.7463 - val_loss: 0.5106 - val_accuracy: 0.7484\n",
      "Epoch 136/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5091 - accuracy: 0.7439 - val_loss: 0.5113 - val_accuracy: 0.7457\n",
      "Epoch 137/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5063 - accuracy: 0.7458 - val_loss: 0.5097 - val_accuracy: 0.7487\n",
      "Epoch 138/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5070 - accuracy: 0.7469 - val_loss: 0.5103 - val_accuracy: 0.7459\n",
      "Epoch 139/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5077 - accuracy: 0.7463 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 140/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5058 - accuracy: 0.7490 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 141/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5085 - accuracy: 0.7451 - val_loss: 0.5076 - val_accuracy: 0.7486\n",
      "Epoch 142/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5063 - accuracy: 0.7467 - val_loss: 0.5078 - val_accuracy: 0.7504\n",
      "Epoch 143/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5021 - accuracy: 0.7489 - val_loss: 0.5090 - val_accuracy: 0.7458\n",
      "Epoch 144/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5084 - accuracy: 0.7448 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 145/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5023 - accuracy: 0.7488 - val_loss: 0.5073 - val_accuracy: 0.7495\n",
      "Epoch 146/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5077 - accuracy: 0.7480 - val_loss: 0.5085 - val_accuracy: 0.7475\n",
      "Epoch 147/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5058 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7493\n",
      "Epoch 148/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5075 - accuracy: 0.7467 - val_loss: 0.5061 - val_accuracy: 0.7488\n",
      "Epoch 149/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5059 - accuracy: 0.7465 - val_loss: 0.5067 - val_accuracy: 0.7476\n",
      "Epoch 150/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5033 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7459\n",
      "Epoch 151/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.5085 - accuracy: 0.7440 - val_loss: 0.5099 - val_accuracy: 0.7439\n",
      "Epoch 152/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5032 - accuracy: 0.7479 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 153/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5066 - accuracy: 0.7460 - val_loss: 0.5065 - val_accuracy: 0.7474\n",
      "Epoch 154/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5076 - accuracy: 0.7449 - val_loss: 0.5079 - val_accuracy: 0.7482\n",
      "Epoch 155/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5050 - accuracy: 0.7466 - val_loss: 0.5075 - val_accuracy: 0.7497\n",
      "Epoch 156/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5010 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7487\n",
      "Epoch 157/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5066 - accuracy: 0.7450 - val_loss: 0.5117 - val_accuracy: 0.7442\n",
      "Epoch 158/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5114 - accuracy: 0.7448 - val_loss: 0.5175 - val_accuracy: 0.7407\n",
      "Epoch 159/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5094 - accuracy: 0.7469 - val_loss: 0.5085 - val_accuracy: 0.7480\n",
      "Epoch 160/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5032 - accuracy: 0.7484 - val_loss: 0.5078 - val_accuracy: 0.7482\n",
      "Epoch 161/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5068 - accuracy: 0.7451 - val_loss: 0.5049 - val_accuracy: 0.7501\n",
      "Epoch 162/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5067 - accuracy: 0.7468 - val_loss: 0.5112 - val_accuracy: 0.7479\n",
      "Epoch 163/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5073 - accuracy: 0.7463 - val_loss: 0.5048 - val_accuracy: 0.7517\n",
      "Epoch 164/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.5033 - accuracy: 0.7481 - val_loss: 0.5075 - val_accuracy: 0.7485\n",
      "Epoch 165/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5058 - accuracy: 0.7458 - val_loss: 0.5085 - val_accuracy: 0.7481\n",
      "Epoch 166/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5047 - accuracy: 0.7458 - val_loss: 0.5192 - val_accuracy: 0.7462\n",
      "Epoch 167/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5058 - accuracy: 0.7478 - val_loss: 0.5167 - val_accuracy: 0.7415\n",
      "Epoch 168/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5083 - accuracy: 0.7438 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 169/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5060 - accuracy: 0.7452 - val_loss: 0.5067 - val_accuracy: 0.7476\n",
      "Epoch 170/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.5065 - accuracy: 0.7449 - val_loss: 0.5318 - val_accuracy: 0.7306\n",
      "Epoch 171/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5051 - accuracy: 0.7462 - val_loss: 0.5076 - val_accuracy: 0.7467\n",
      "Epoch 172/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5070 - accuracy: 0.7459 - val_loss: 0.5064 - val_accuracy: 0.7487\n",
      "Epoch 173/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5025 - accuracy: 0.7493 - val_loss: 0.5057 - val_accuracy: 0.7483\n",
      "Epoch 174/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5263 - accuracy: 0.7466 - val_loss: 0.5063 - val_accuracy: 0.7476\n",
      "Epoch 175/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5006 - accuracy: 0.7500 - val_loss: 0.5087 - val_accuracy: 0.7477\n",
      "Epoch 176/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5013 - accuracy: 0.7495 - val_loss: 0.5053 - val_accuracy: 0.7519\n",
      "Epoch 177/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5046 - accuracy: 0.7454 - val_loss: 0.5080 - val_accuracy: 0.7457\n",
      "Epoch 178/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.5044 - accuracy: 0.7479 - val_loss: 0.5068 - val_accuracy: 0.7472\n",
      "Epoch 179/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5030 - accuracy: 0.7458 - val_loss: 0.5050 - val_accuracy: 0.7494\n",
      "Epoch 180/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5013 - accuracy: 0.7490 - val_loss: 0.5043 - val_accuracy: 0.7507\n",
      "Epoch 181/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5034 - accuracy: 0.7469 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 182/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5013 - accuracy: 0.7498 - val_loss: 0.5052 - val_accuracy: 0.7504\n",
      "Epoch 183/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5010 - accuracy: 0.7489 - val_loss: 0.5068 - val_accuracy: 0.7458\n",
      "Epoch 184/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5012 - accuracy: 0.7487 - val_loss: 0.5048 - val_accuracy: 0.7493\n",
      "Epoch 185/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5006 - accuracy: 0.7484 - val_loss: 0.5034 - val_accuracy: 0.7509\n",
      "Epoch 186/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5021 - accuracy: 0.7479 - val_loss: 0.5052 - val_accuracy: 0.7488\n",
      "Epoch 187/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5029 - accuracy: 0.7480 - val_loss: 0.5040 - val_accuracy: 0.7495\n",
      "Epoch 188/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5055 - accuracy: 0.7461 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 189/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5023 - accuracy: 0.7499 - val_loss: 0.5066 - val_accuracy: 0.7519\n",
      "Epoch 190/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5034 - accuracy: 0.7478 - val_loss: 0.5053 - val_accuracy: 0.7493\n",
      "Epoch 191/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5021 - accuracy: 0.7496 - val_loss: 0.5037 - val_accuracy: 0.7498\n",
      "Epoch 192/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5006 - accuracy: 0.7488 - val_loss: 0.5039 - val_accuracy: 0.7505\n",
      "Epoch 193/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5019 - accuracy: 0.7487 - val_loss: 0.5066 - val_accuracy: 0.7485\n",
      "Epoch 194/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5063 - accuracy: 0.7437 - val_loss: 0.5041 - val_accuracy: 0.7517\n",
      "Epoch 195/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5021 - accuracy: 0.7484 - val_loss: 0.5054 - val_accuracy: 0.7509\n",
      "Epoch 196/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5034 - accuracy: 0.7473 - val_loss: 0.5035 - val_accuracy: 0.7507\n",
      "Epoch 197/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4996 - accuracy: 0.7513 - val_loss: 0.5059 - val_accuracy: 0.7484\n",
      "Epoch 198/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5033 - accuracy: 0.7468 - val_loss: 0.5047 - val_accuracy: 0.7493\n",
      "Epoch 199/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5032 - accuracy: 0.7473 - val_loss: 0.5037 - val_accuracy: 0.7479\n",
      "Epoch 200/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5022 - accuracy: 0.7472 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 201/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5018 - accuracy: 0.7460 - val_loss: 0.5065 - val_accuracy: 0.7463\n",
      "Epoch 202/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.5010 - accuracy: 0.7497 - val_loss: 0.5053 - val_accuracy: 0.7499\n",
      "Epoch 203/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.4992 - accuracy: 0.7504 - val_loss: 0.5064 - val_accuracy: 0.7524\n",
      "Epoch 204/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5022 - accuracy: 0.7493 - val_loss: 0.5044 - val_accuracy: 0.7478\n",
      "Epoch 205/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5009 - accuracy: 0.7471 - val_loss: 0.5038 - val_accuracy: 0.7513\n",
      "Epoch 206/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5037 - accuracy: 0.7485 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 207/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5013 - accuracy: 0.7500 - val_loss: 0.5055 - val_accuracy: 0.7455\n",
      "Epoch 208/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5026 - accuracy: 0.7473 - val_loss: 0.5026 - val_accuracy: 0.7511\n",
      "Epoch 209/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.5010 - accuracy: 0.7486 - val_loss: 0.5038 - val_accuracy: 0.7499\n",
      "Epoch 210/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.5008 - accuracy: 0.7502 - val_loss: 0.5035 - val_accuracy: 0.7507\n",
      "Epoch 211/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5023 - accuracy: 0.7469 - val_loss: 0.5062 - val_accuracy: 0.7452\n",
      "Epoch 212/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5027 - accuracy: 0.7492 - val_loss: 0.5042 - val_accuracy: 0.7471\n",
      "Epoch 213/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.5023 - accuracy: 0.7486 - val_loss: 0.5094 - val_accuracy: 0.7480\n",
      "Epoch 214/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5053 - accuracy: 0.7448 - val_loss: 0.5049 - val_accuracy: 0.7486\n",
      "Epoch 215/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5031 - accuracy: 0.7481 - val_loss: 0.5031 - val_accuracy: 0.7519\n",
      "Epoch 216/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4996 - accuracy: 0.7491 - val_loss: 0.5025 - val_accuracy: 0.7514\n",
      "Epoch 217/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.4997 - accuracy: 0.7506 - val_loss: 0.5055 - val_accuracy: 0.7445\n",
      "Epoch 218/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5000 - accuracy: 0.7497 - val_loss: 0.5060 - val_accuracy: 0.7477\n",
      "Epoch 219/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5025 - accuracy: 0.7484 - val_loss: 0.5059 - val_accuracy: 0.7498\n",
      "Epoch 220/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5020 - accuracy: 0.7502 - val_loss: 0.5051 - val_accuracy: 0.7499\n",
      "Epoch 221/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5020 - accuracy: 0.7480 - val_loss: 0.5037 - val_accuracy: 0.7490\n",
      "Epoch 222/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5033 - accuracy: 0.7477 - val_loss: 0.5031 - val_accuracy: 0.7509\n",
      "Epoch 223/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.5015 - accuracy: 0.7489 - val_loss: 0.5019 - val_accuracy: 0.7498\n",
      "Epoch 224/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.4998 - accuracy: 0.7503 - val_loss: 0.5055 - val_accuracy: 0.7507\n",
      "Epoch 225/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5006 - accuracy: 0.7508 - val_loss: 0.5098 - val_accuracy: 0.7421\n",
      "Epoch 226/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5028 - accuracy: 0.7489 - val_loss: 0.5047 - val_accuracy: 0.7498\n",
      "Epoch 227/500\n",
      "2878/2878 [==============================] - 2s 767us/step - loss: 0.5025 - accuracy: 0.7468 - val_loss: 0.5031 - val_accuracy: 0.7488\n",
      "Epoch 228/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5042 - accuracy: 0.7458 - val_loss: 0.5056 - val_accuracy: 0.7460\n",
      "Epoch 229/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.4989 - accuracy: 0.7502 - val_loss: 0.5019 - val_accuracy: 0.7523\n",
      "Epoch 230/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5033 - accuracy: 0.7468 - val_loss: 0.5042 - val_accuracy: 0.7509\n",
      "Epoch 231/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5019 - accuracy: 0.7486 - val_loss: 0.5021 - val_accuracy: 0.7519\n",
      "Epoch 232/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5016 - accuracy: 0.7489 - val_loss: 0.5026 - val_accuracy: 0.7498\n",
      "Epoch 233/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.5003 - accuracy: 0.7499 - val_loss: 0.5062 - val_accuracy: 0.7502\n",
      "Epoch 234/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5022 - accuracy: 0.7486 - val_loss: 0.5025 - val_accuracy: 0.7491\n",
      "Epoch 235/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.5011 - accuracy: 0.7485 - val_loss: 0.5043 - val_accuracy: 0.7523\n",
      "Epoch 236/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5001 - accuracy: 0.7502 - val_loss: 0.5041 - val_accuracy: 0.7501\n",
      "Epoch 237/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5000 - accuracy: 0.7492 - val_loss: 0.5046 - val_accuracy: 0.7503\n",
      "Epoch 238/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.4993 - accuracy: 0.7482 - val_loss: 0.5036 - val_accuracy: 0.7493\n",
      "Epoch 239/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.4991 - accuracy: 0.7489 - val_loss: 0.5043 - val_accuracy: 0.7498\n",
      "Epoch 240/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5026 - accuracy: 0.7496 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
      "Epoch 241/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4994 - accuracy: 0.7508 - val_loss: 0.5027 - val_accuracy: 0.7511\n",
      "Epoch 242/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5052 - accuracy: 0.7443 - val_loss: 0.5043 - val_accuracy: 0.7490\n",
      "Epoch 243/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5020 - accuracy: 0.7481 - val_loss: 0.5019 - val_accuracy: 0.7504\n",
      "Epoch 244/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5022 - accuracy: 0.7472 - val_loss: 0.5063 - val_accuracy: 0.7497\n",
      "Epoch 245/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5023 - accuracy: 0.7506 - val_loss: 0.5028 - val_accuracy: 0.7502\n",
      "Epoch 246/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5016 - accuracy: 0.7472 - val_loss: 0.5033 - val_accuracy: 0.7511\n",
      "Epoch 247/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4996 - accuracy: 0.7502 - val_loss: 0.5051 - val_accuracy: 0.7487\n",
      "Epoch 248/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5020 - accuracy: 0.7474 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
      "Epoch 249/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5023 - accuracy: 0.7498 - val_loss: 0.5020 - val_accuracy: 0.7504\n",
      "Epoch 250/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5008 - accuracy: 0.7488 - val_loss: 0.5046 - val_accuracy: 0.7498\n",
      "Epoch 251/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5000 - accuracy: 0.7504 - val_loss: 0.5024 - val_accuracy: 0.7513\n",
      "Epoch 252/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5000 - accuracy: 0.7497 - val_loss: 0.5026 - val_accuracy: 0.7522\n",
      "Epoch 253/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.4996 - accuracy: 0.7492 - val_loss: 0.5037 - val_accuracy: 0.7503\n",
      "Epoch 254/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5007 - accuracy: 0.7496 - val_loss: 0.5041 - val_accuracy: 0.7487\n",
      "Epoch 255/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.4988 - accuracy: 0.7516 - val_loss: 0.5086 - val_accuracy: 0.7476\n",
      "Epoch 256/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.4994 - accuracy: 0.7504 - val_loss: 0.5025 - val_accuracy: 0.7490\n",
      "Epoch 257/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5018 - accuracy: 0.7484 - val_loss: 0.5061 - val_accuracy: 0.7468\n",
      "Epoch 258/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5010 - accuracy: 0.7492 - val_loss: 0.5045 - val_accuracy: 0.7484\n",
      "Epoch 259/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5011 - accuracy: 0.7490 - val_loss: 0.5025 - val_accuracy: 0.7504\n",
      "Epoch 260/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.4999 - accuracy: 0.7493 - val_loss: 0.5024 - val_accuracy: 0.7510\n",
      "Epoch 261/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.4984 - accuracy: 0.7510 - val_loss: 0.5033 - val_accuracy: 0.7491\n",
      "Epoch 262/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5016 - accuracy: 0.7480 - val_loss: 0.5035 - val_accuracy: 0.7501\n",
      "Epoch 263/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5015 - accuracy: 0.7473 - val_loss: 0.5061 - val_accuracy: 0.7464\n",
      "Epoch 264/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.4967 - accuracy: 0.7519 - val_loss: 0.5014 - val_accuracy: 0.7515\n",
      "Epoch 265/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.4988 - accuracy: 0.7497 - val_loss: 0.5044 - val_accuracy: 0.7531\n",
      "Epoch 266/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.4977 - accuracy: 0.7513 - val_loss: 0.5015 - val_accuracy: 0.7520\n",
      "Epoch 267/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5027 - accuracy: 0.7477 - val_loss: 0.5008 - val_accuracy: 0.7529\n",
      "Epoch 268/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.4996 - accuracy: 0.7504 - val_loss: 0.5052 - val_accuracy: 0.7497\n",
      "Epoch 269/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5012 - accuracy: 0.7479 - val_loss: 0.5018 - val_accuracy: 0.7527\n",
      "Epoch 270/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5010 - accuracy: 0.7497 - val_loss: 0.5033 - val_accuracy: 0.7529\n",
      "Epoch 271/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5007 - accuracy: 0.7507 - val_loss: 0.5039 - val_accuracy: 0.7467\n",
      "Epoch 272/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5002 - accuracy: 0.7507 - val_loss: 0.5052 - val_accuracy: 0.7528\n",
      "Epoch 273/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.5029 - accuracy: 0.7475 - val_loss: 0.5028 - val_accuracy: 0.7526\n",
      "Epoch 274/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5012 - accuracy: 0.7491 - val_loss: 0.5037 - val_accuracy: 0.7492\n",
      "Epoch 275/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4992 - accuracy: 0.7510 - val_loss: 0.5034 - val_accuracy: 0.7536\n",
      "Epoch 276/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4988 - accuracy: 0.7510 - val_loss: 0.5039 - val_accuracy: 0.7490\n",
      "Epoch 277/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5001 - accuracy: 0.7513 - val_loss: 0.5032 - val_accuracy: 0.7483\n",
      "Epoch 278/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4995 - accuracy: 0.7516 - val_loss: 0.5045 - val_accuracy: 0.7511\n",
      "Epoch 279/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5004 - accuracy: 0.7497 - val_loss: 0.5040 - val_accuracy: 0.7503\n",
      "Epoch 280/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.4983 - accuracy: 0.7510 - val_loss: 0.5061 - val_accuracy: 0.7505\n",
      "Epoch 281/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5035 - accuracy: 0.7487 - val_loss: 0.5093 - val_accuracy: 0.7485\n",
      "Epoch 282/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5011 - accuracy: 0.7503 - val_loss: 0.5023 - val_accuracy: 0.7506\n",
      "Epoch 283/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5004 - accuracy: 0.7499 - val_loss: 0.5055 - val_accuracy: 0.7492\n",
      "Epoch 284/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5001 - accuracy: 0.7478 - val_loss: 0.5016 - val_accuracy: 0.7513\n",
      "Epoch 285/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.4989 - accuracy: 0.7507 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 286/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.5014 - accuracy: 0.7479 - val_loss: 0.5034 - val_accuracy: 0.7485\n",
      "Epoch 287/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.4998 - accuracy: 0.7503 - val_loss: 0.5061 - val_accuracy: 0.7495\n",
      "Epoch 288/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5024 - accuracy: 0.7492 - val_loss: 0.5052 - val_accuracy: 0.7490\n",
      "Epoch 289/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.4999 - accuracy: 0.7493 - val_loss: 0.5029 - val_accuracy: 0.7523\n",
      "Epoch 290/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.4998 - accuracy: 0.7504 - val_loss: 0.4998 - val_accuracy: 0.7504\n",
      "Epoch 291/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.4996 - accuracy: 0.7489 - val_loss: 0.4999 - val_accuracy: 0.7523\n",
      "Epoch 292/500\n",
      "2878/2878 [==============================] - 2s 672us/step - loss: 0.5017 - accuracy: 0.7489 - val_loss: 0.5042 - val_accuracy: 0.7484\n",
      "Epoch 293/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.4995 - accuracy: 0.7524 - val_loss: 0.5039 - val_accuracy: 0.7478\n",
      "Epoch 294/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4967 - accuracy: 0.7498 - val_loss: 0.5020 - val_accuracy: 0.7512\n",
      "Epoch 295/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.5002 - accuracy: 0.7509 - val_loss: 0.5033 - val_accuracy: 0.7510\n",
      "Epoch 296/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5028 - accuracy: 0.7498 - val_loss: 0.5039 - val_accuracy: 0.7490\n",
      "Epoch 297/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5005 - accuracy: 0.7487 - val_loss: 0.5043 - val_accuracy: 0.7520\n",
      "Epoch 298/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.4986 - accuracy: 0.7514 - val_loss: 0.5032 - val_accuracy: 0.7490\n",
      "Epoch 299/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.4987 - accuracy: 0.7498 - val_loss: 0.5004 - val_accuracy: 0.7532\n",
      "Epoch 300/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.4987 - accuracy: 0.7521 - val_loss: 0.5026 - val_accuracy: 0.7506\n",
      "Epoch 301/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5012 - accuracy: 0.7485 - val_loss: 0.5059 - val_accuracy: 0.7457\n",
      "Epoch 302/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.4989 - accuracy: 0.7505 - val_loss: 0.5009 - val_accuracy: 0.7513\n",
      "Epoch 303/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.4981 - accuracy: 0.7524 - val_loss: 0.5044 - val_accuracy: 0.7487\n",
      "Epoch 304/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.4988 - accuracy: 0.7498 - val_loss: 0.5100 - val_accuracy: 0.7434\n",
      "Epoch 305/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.4972 - accuracy: 0.7520 - val_loss: 0.5022 - val_accuracy: 0.7492\n",
      "Epoch 306/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5004 - accuracy: 0.7500 - val_loss: 0.5018 - val_accuracy: 0.7515\n",
      "Epoch 307/500\n",
      "2878/2878 [==============================] - 2s 672us/step - loss: 0.5013 - accuracy: 0.7483 - val_loss: 0.5009 - val_accuracy: 0.7525\n",
      "Epoch 308/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5000 - accuracy: 0.7503 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
      "Epoch 309/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5002 - accuracy: 0.7502 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
      "Epoch 310/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5023 - accuracy: 0.7487 - val_loss: 0.5051 - val_accuracy: 0.7503\n",
      "Epoch 311/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5000 - accuracy: 0.7508 - val_loss: 0.5029 - val_accuracy: 0.7534\n",
      "Epoch 312/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.4983 - accuracy: 0.7517 - val_loss: 0.5032 - val_accuracy: 0.7490\n",
      "Epoch 313/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5012 - accuracy: 0.7501 - val_loss: 0.5018 - val_accuracy: 0.7520\n",
      "Epoch 314/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5023 - accuracy: 0.7492 - val_loss: 0.5009 - val_accuracy: 0.7526\n",
      "Epoch 315/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5011 - accuracy: 0.7499 - val_loss: 0.5052 - val_accuracy: 0.7516\n",
      "Epoch 316/500\n",
      "2878/2878 [==============================] - 2s 670us/step - loss: 0.4990 - accuracy: 0.7518 - val_loss: 0.5011 - val_accuracy: 0.7511\n",
      "Epoch 317/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.4993 - accuracy: 0.7487 - val_loss: 0.5019 - val_accuracy: 0.7493\n",
      "Epoch 318/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5002 - accuracy: 0.7502 - val_loss: 0.5039 - val_accuracy: 0.7482\n",
      "Epoch 319/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.4996 - accuracy: 0.7480 - val_loss: 0.5004 - val_accuracy: 0.7510\n",
      "Epoch 320/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4961 - accuracy: 0.7521 - val_loss: 0.5024 - val_accuracy: 0.7507\n",
      "Epoch 321/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5027 - accuracy: 0.7487 - val_loss: 0.5048 - val_accuracy: 0.7493\n",
      "Epoch 322/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.4965 - accuracy: 0.7522 - val_loss: 0.5003 - val_accuracy: 0.7528\n",
      "Epoch 323/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.4979 - accuracy: 0.7513 - val_loss: 0.5001 - val_accuracy: 0.7514\n",
      "Epoch 324/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.4981 - accuracy: 0.7514 - val_loss: 0.5035 - val_accuracy: 0.7487\n",
      "Epoch 325/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.4993 - accuracy: 0.7516 - val_loss: 0.5039 - val_accuracy: 0.7509\n",
      "Epoch 326/500\n",
      "2878/2878 [==============================] - 2s 670us/step - loss: 0.5031 - accuracy: 0.7465 - val_loss: 0.5044 - val_accuracy: 0.7517\n",
      "Epoch 327/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.4996 - accuracy: 0.7499 - val_loss: 0.5020 - val_accuracy: 0.7517\n",
      "Epoch 328/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.4996 - accuracy: 0.7499 - val_loss: 0.5044 - val_accuracy: 0.7461\n",
      "Epoch 329/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4995 - accuracy: 0.7507 - val_loss: 0.5043 - val_accuracy: 0.7503\n",
      "Epoch 330/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.4986 - accuracy: 0.7521 - val_loss: 0.5015 - val_accuracy: 0.7510\n",
      "Epoch 331/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4976 - accuracy: 0.7518 - val_loss: 0.5017 - val_accuracy: 0.7513\n",
      "Epoch 332/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.4972 - accuracy: 0.7524 - val_loss: 0.5005 - val_accuracy: 0.7535\n",
      "Epoch 333/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.4988 - accuracy: 0.7508 - val_loss: 0.5018 - val_accuracy: 0.7535\n",
      "Epoch 334/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.4984 - accuracy: 0.7506 - val_loss: 0.5015 - val_accuracy: 0.7536\n",
      "Epoch 335/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.4993 - accuracy: 0.7496 - val_loss: 0.5035 - val_accuracy: 0.7484\n",
      "Epoch 336/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4994 - accuracy: 0.7486 - val_loss: 0.5068 - val_accuracy: 0.7433\n",
      "Epoch 337/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.4997 - accuracy: 0.7513 - val_loss: 0.5050 - val_accuracy: 0.7479\n",
      "Epoch 338/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5003 - accuracy: 0.7492 - val_loss: 0.5055 - val_accuracy: 0.7522\n",
      "Epoch 339/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4987 - accuracy: 0.7523 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
      "Epoch 340/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5018 - accuracy: 0.7478 - val_loss: 0.5012 - val_accuracy: 0.7518\n",
      "Epoch 341/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.4973 - accuracy: 0.7527 - val_loss: 0.5027 - val_accuracy: 0.7514\n",
      "Epoch 342/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5014 - accuracy: 0.7480 - val_loss: 0.5034 - val_accuracy: 0.7516\n",
      "Epoch 343/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4980 - accuracy: 0.7513 - val_loss: 0.5037 - val_accuracy: 0.7519\n",
      "Epoch 344/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5013 - accuracy: 0.7501 - val_loss: 0.5034 - val_accuracy: 0.7491\n",
      "Epoch 345/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5019 - accuracy: 0.7491 - val_loss: 0.5084 - val_accuracy: 0.7436\n",
      "Epoch 346/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.4978 - accuracy: 0.7529 - val_loss: 0.5058 - val_accuracy: 0.7491\n",
      "Epoch 347/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.4984 - accuracy: 0.7509 - val_loss: 0.5050 - val_accuracy: 0.7465\n",
      "Epoch 348/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.4977 - accuracy: 0.7523 - val_loss: 0.5076 - val_accuracy: 0.7433\n",
      "Epoch 349/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5017 - accuracy: 0.7472 - val_loss: 0.4999 - val_accuracy: 0.7539\n",
      "Epoch 350/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5010 - accuracy: 0.7473 - val_loss: 0.5067 - val_accuracy: 0.7441\n",
      "Epoch 351/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5010 - accuracy: 0.7489 - val_loss: 0.5025 - val_accuracy: 0.7510\n",
      "Epoch 352/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.4969 - accuracy: 0.7517 - val_loss: 0.5021 - val_accuracy: 0.7523\n",
      "Epoch 353/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5005 - accuracy: 0.7498 - val_loss: 0.5034 - val_accuracy: 0.7513\n",
      "Epoch 354/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.4995 - accuracy: 0.7500 - val_loss: 0.5032 - val_accuracy: 0.7527\n",
      "Epoch 355/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4971 - accuracy: 0.7524 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 356/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.4965 - accuracy: 0.7518 - val_loss: 0.5064 - val_accuracy: 0.7503\n",
      "Epoch 357/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.5015 - accuracy: 0.7478 - val_loss: 0.5063 - val_accuracy: 0.7473\n",
      "Epoch 358/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.4956 - accuracy: 0.7531 - val_loss: 0.5013 - val_accuracy: 0.7519\n",
      "Epoch 359/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4993 - accuracy: 0.7505 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
      "Epoch 360/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5002 - accuracy: 0.7499 - val_loss: 0.5020 - val_accuracy: 0.7523\n",
      "Epoch 361/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.4992 - accuracy: 0.7522 - val_loss: 0.5017 - val_accuracy: 0.7497\n",
      "Epoch 362/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.4979 - accuracy: 0.7502 - val_loss: 0.5028 - val_accuracy: 0.7480\n",
      "Epoch 363/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5007 - accuracy: 0.7481 - val_loss: 0.5027 - val_accuracy: 0.7489\n",
      "Epoch 364/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5007 - accuracy: 0.7491 - val_loss: 0.5043 - val_accuracy: 0.7512\n",
      "Epoch 365/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.5004 - accuracy: 0.7498 - val_loss: 0.5027 - val_accuracy: 0.7485\n",
      "Epoch 366/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.4997 - accuracy: 0.7511 - val_loss: 0.5009 - val_accuracy: 0.7534\n",
      "Epoch 367/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5011 - accuracy: 0.7461 - val_loss: 0.5026 - val_accuracy: 0.7473\n",
      "Epoch 368/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5020 - accuracy: 0.7479 - val_loss: 0.5066 - val_accuracy: 0.7502\n",
      "Epoch 369/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.4955 - accuracy: 0.7542 - val_loss: 0.5033 - val_accuracy: 0.7517\n",
      "Epoch 370/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5000 - accuracy: 0.7510 - val_loss: 0.5063 - val_accuracy: 0.7514\n",
      "Epoch 371/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.5001 - accuracy: 0.7500 - val_loss: 0.5023 - val_accuracy: 0.7491\n",
      "Epoch 372/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.4982 - accuracy: 0.7529 - val_loss: 0.5043 - val_accuracy: 0.7497\n",
      "Epoch 373/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5013 - accuracy: 0.7487 - val_loss: 0.5032 - val_accuracy: 0.7502\n",
      "Epoch 374/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.4977 - accuracy: 0.7519 - val_loss: 0.5014 - val_accuracy: 0.7516\n",
      "Epoch 375/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4973 - accuracy: 0.7518 - val_loss: 0.5014 - val_accuracy: 0.7508\n",
      "Epoch 376/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.4964 - accuracy: 0.7526 - val_loss: 0.5251 - val_accuracy: 0.7248\n",
      "Epoch 377/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4992 - accuracy: 0.7514 - val_loss: 0.5054 - val_accuracy: 0.7487\n",
      "Epoch 378/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.5004 - accuracy: 0.7505 - val_loss: 0.5061 - val_accuracy: 0.7517\n",
      "Epoch 379/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.4975 - accuracy: 0.7526 - val_loss: 0.5065 - val_accuracy: 0.7464\n",
      "Epoch 380/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4980 - accuracy: 0.7505 - val_loss: 0.5025 - val_accuracy: 0.7512\n",
      "Epoch 381/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.4991 - accuracy: 0.7514 - val_loss: 0.5035 - val_accuracy: 0.7491\n",
      "Epoch 382/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5006 - accuracy: 0.7507 - val_loss: 0.5031 - val_accuracy: 0.7477\n",
      "Epoch 383/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4951 - accuracy: 0.7552 - val_loss: 0.5035 - val_accuracy: 0.7503\n",
      "Epoch 384/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5007 - accuracy: 0.7489 - val_loss: 0.5032 - val_accuracy: 0.7515\n",
      "Epoch 385/500\n",
      "2878/2878 [==============================] - 2s 669us/step - loss: 0.4991 - accuracy: 0.7504 - val_loss: 0.5025 - val_accuracy: 0.7516\n",
      "Epoch 386/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.4997 - accuracy: 0.7484 - val_loss: 0.5025 - val_accuracy: 0.7517\n",
      "Epoch 387/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.4985 - accuracy: 0.7515 - val_loss: 0.5035 - val_accuracy: 0.7501\n",
      "Epoch 388/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.4992 - accuracy: 0.7500 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 389/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5009 - accuracy: 0.7487 - val_loss: 0.5040 - val_accuracy: 0.7490\n",
      "Epoch 390/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4965 - accuracy: 0.7515 - val_loss: 0.4996 - val_accuracy: 0.7529\n",
      "Epoch 391/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5002 - accuracy: 0.7485 - val_loss: 0.5042 - val_accuracy: 0.7487\n",
      "Epoch 392/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4982 - accuracy: 0.7499 - val_loss: 0.5064 - val_accuracy: 0.7483\n",
      "Epoch 393/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5013 - accuracy: 0.7481 - val_loss: 0.5022 - val_accuracy: 0.7536\n",
      "Epoch 394/500\n",
      "2878/2878 [==============================] - 2s 672us/step - loss: 0.4984 - accuracy: 0.7511 - val_loss: 0.5048 - val_accuracy: 0.7474\n",
      "Epoch 395/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5013 - accuracy: 0.7485 - val_loss: 0.5040 - val_accuracy: 0.7536\n",
      "Epoch 396/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.5012 - accuracy: 0.7486 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
      "Epoch 397/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5025 - accuracy: 0.7479 - val_loss: 0.5032 - val_accuracy: 0.7496\n",
      "Epoch 398/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4981 - accuracy: 0.7495 - val_loss: 0.5037 - val_accuracy: 0.7508\n",
      "Epoch 399/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.4985 - accuracy: 0.7507 - val_loss: 0.5018 - val_accuracy: 0.7517\n",
      "Epoch 400/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.4975 - accuracy: 0.7526 - val_loss: 0.5008 - val_accuracy: 0.7529\n",
      "Epoch 401/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4978 - accuracy: 0.7519 - val_loss: 0.5024 - val_accuracy: 0.7506\n",
      "Epoch 402/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.4986 - accuracy: 0.7517 - val_loss: 0.5050 - val_accuracy: 0.7459\n",
      "Epoch 403/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5003 - accuracy: 0.7488 - val_loss: 0.5052 - val_accuracy: 0.7464\n",
      "Epoch 404/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4993 - accuracy: 0.7506 - val_loss: 0.5087 - val_accuracy: 0.7434\n",
      "Epoch 405/500\n",
      "2878/2878 [==============================] - 2s 669us/step - loss: 0.4973 - accuracy: 0.7503 - val_loss: 0.5024 - val_accuracy: 0.7489\n",
      "Epoch 406/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.4981 - accuracy: 0.7515 - val_loss: 0.5033 - val_accuracy: 0.7514\n",
      "Epoch 407/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.4978 - accuracy: 0.7507 - val_loss: 0.5062 - val_accuracy: 0.7509\n",
      "Epoch 408/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5003 - accuracy: 0.7498 - val_loss: 0.5022 - val_accuracy: 0.7514\n",
      "Epoch 409/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.4987 - accuracy: 0.7497 - val_loss: 0.5125 - val_accuracy: 0.7419\n",
      "Epoch 410/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.4998 - accuracy: 0.7515 - val_loss: 0.5041 - val_accuracy: 0.7481\n",
      "Epoch 411/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5005 - accuracy: 0.7500 - val_loss: 0.5022 - val_accuracy: 0.7530\n",
      "Epoch 412/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.4986 - accuracy: 0.7497 - val_loss: 0.5031 - val_accuracy: 0.7526\n",
      "Epoch 413/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.4982 - accuracy: 0.7504 - val_loss: 0.5024 - val_accuracy: 0.7524\n",
      "Epoch 414/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.4997 - accuracy: 0.7517 - val_loss: 0.5051 - val_accuracy: 0.7471\n",
      "Epoch 415/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.4989 - accuracy: 0.7512 - val_loss: 0.5042 - val_accuracy: 0.7484\n",
      "Epoch 416/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.4985 - accuracy: 0.7497 - val_loss: 0.5023 - val_accuracy: 0.7501\n",
      "Epoch 417/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.4983 - accuracy: 0.7500 - val_loss: 0.5026 - val_accuracy: 0.7503\n",
      "Epoch 418/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.4971 - accuracy: 0.7525 - val_loss: 0.5017 - val_accuracy: 0.7543\n",
      "Epoch 419/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.4954 - accuracy: 0.7538 - val_loss: 0.5007 - val_accuracy: 0.7520\n",
      "Epoch 420/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5014 - accuracy: 0.7497 - val_loss: 0.5042 - val_accuracy: 0.7524\n",
      "Epoch 421/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.4968 - accuracy: 0.7532 - val_loss: 0.5026 - val_accuracy: 0.7519\n",
      "Epoch 422/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.4978 - accuracy: 0.7517 - val_loss: 0.5003 - val_accuracy: 0.7527\n",
      "Epoch 423/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5012 - accuracy: 0.7491 - val_loss: 0.5024 - val_accuracy: 0.7536\n",
      "Epoch 424/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4993 - accuracy: 0.7499 - val_loss: 0.5018 - val_accuracy: 0.7536\n",
      "Epoch 425/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4955 - accuracy: 0.7531 - val_loss: 0.5077 - val_accuracy: 0.7501\n",
      "Epoch 426/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.4969 - accuracy: 0.7534 - val_loss: 0.5043 - val_accuracy: 0.7506\n",
      "Epoch 427/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.4991 - accuracy: 0.7486 - val_loss: 0.5047 - val_accuracy: 0.7490\n",
      "Epoch 428/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.4996 - accuracy: 0.7496 - val_loss: 0.5012 - val_accuracy: 0.7501\n",
      "Epoch 429/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.4945 - accuracy: 0.7532 - val_loss: 0.5024 - val_accuracy: 0.7509\n",
      "Epoch 430/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.4983 - accuracy: 0.7515 - val_loss: 0.5121 - val_accuracy: 0.7383\n",
      "Epoch 431/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5006 - accuracy: 0.7495 - val_loss: 0.5027 - val_accuracy: 0.7515\n",
      "Epoch 432/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5012 - accuracy: 0.7493 - val_loss: 0.4999 - val_accuracy: 0.7545\n",
      "Epoch 433/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4989 - accuracy: 0.7487 - val_loss: 0.5037 - val_accuracy: 0.7475\n",
      "Epoch 434/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5000 - accuracy: 0.7500 - val_loss: 0.5030 - val_accuracy: 0.7534\n",
      "Epoch 435/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5006 - accuracy: 0.7489 - val_loss: 0.5039 - val_accuracy: 0.7457\n",
      "Epoch 436/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.4981 - accuracy: 0.7506 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
      "Epoch 437/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.4966 - accuracy: 0.7508 - val_loss: 0.5019 - val_accuracy: 0.7497\n",
      "Epoch 438/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5016 - accuracy: 0.7492 - val_loss: 0.5015 - val_accuracy: 0.7525\n",
      "Epoch 439/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.4982 - accuracy: 0.7511 - val_loss: 0.5031 - val_accuracy: 0.7480\n",
      "Epoch 440/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5005 - accuracy: 0.7488 - val_loss: 0.5031 - val_accuracy: 0.7483\n",
      "Epoch 441/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.4993 - accuracy: 0.7504 - val_loss: 0.5049 - val_accuracy: 0.7458\n",
      "Epoch 442/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4986 - accuracy: 0.7509 - val_loss: 0.5119 - val_accuracy: 0.7375\n",
      "Epoch 443/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4977 - accuracy: 0.7537 - val_loss: 0.5045 - val_accuracy: 0.7518\n",
      "Epoch 444/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.4986 - accuracy: 0.7490 - val_loss: 0.5006 - val_accuracy: 0.7520\n",
      "Epoch 445/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.4998 - accuracy: 0.7483 - val_loss: 0.5031 - val_accuracy: 0.7502\n",
      "Epoch 446/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4935 - accuracy: 0.7547 - val_loss: 0.5053 - val_accuracy: 0.7464\n",
      "Epoch 447/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4985 - accuracy: 0.7494 - val_loss: 0.5027 - val_accuracy: 0.7481\n",
      "Epoch 448/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.4975 - accuracy: 0.7525 - val_loss: 0.5031 - val_accuracy: 0.7483\n",
      "Epoch 449/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5001 - accuracy: 0.7465 - val_loss: 0.5027 - val_accuracy: 0.7528\n",
      "Epoch 450/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.4985 - accuracy: 0.7501 - val_loss: 0.5000 - val_accuracy: 0.7539\n",
      "Epoch 451/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.4987 - accuracy: 0.7503 - val_loss: 0.5030 - val_accuracy: 0.7537\n",
      "Epoch 452/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.4982 - accuracy: 0.7503 - val_loss: 0.5017 - val_accuracy: 0.7507\n",
      "Epoch 453/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.4978 - accuracy: 0.7530 - val_loss: 0.5061 - val_accuracy: 0.7520\n",
      "Epoch 454/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.4987 - accuracy: 0.7496 - val_loss: 0.5025 - val_accuracy: 0.7510\n",
      "Epoch 455/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.4952 - accuracy: 0.7537 - val_loss: 0.5034 - val_accuracy: 0.7484\n",
      "Epoch 456/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.4983 - accuracy: 0.7535 - val_loss: 0.5033 - val_accuracy: 0.7503\n",
      "Epoch 457/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.4984 - accuracy: 0.7535 - val_loss: 0.5012 - val_accuracy: 0.7532\n",
      "Epoch 458/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4997 - accuracy: 0.7479 - val_loss: 0.5099 - val_accuracy: 0.7454\n",
      "Epoch 459/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.4981 - accuracy: 0.7522 - val_loss: 0.5008 - val_accuracy: 0.7531\n",
      "Epoch 460/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4981 - accuracy: 0.7514 - val_loss: 0.5088 - val_accuracy: 0.7421\n",
      "Epoch 461/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.4953 - accuracy: 0.7527 - val_loss: 0.5017 - val_accuracy: 0.7506\n",
      "Epoch 462/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.4980 - accuracy: 0.7510 - val_loss: 0.5028 - val_accuracy: 0.7521\n",
      "Epoch 463/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.4985 - accuracy: 0.7500 - val_loss: 0.5005 - val_accuracy: 0.7526\n",
      "Epoch 464/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5004 - accuracy: 0.7501 - val_loss: 0.5047 - val_accuracy: 0.7465\n",
      "Epoch 465/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4965 - accuracy: 0.7528 - val_loss: 0.5029 - val_accuracy: 0.7517\n",
      "Epoch 466/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5007 - accuracy: 0.7495 - val_loss: 0.5019 - val_accuracy: 0.7511\n",
      "Epoch 467/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4985 - accuracy: 0.7504 - val_loss: 0.5046 - val_accuracy: 0.7489\n",
      "Epoch 468/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.4977 - accuracy: 0.7523 - val_loss: 0.5054 - val_accuracy: 0.7507\n",
      "Epoch 469/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.4969 - accuracy: 0.7517 - val_loss: 0.5015 - val_accuracy: 0.7540\n",
      "Epoch 470/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4975 - accuracy: 0.7524 - val_loss: 0.5034 - val_accuracy: 0.7470\n",
      "Epoch 471/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4999 - accuracy: 0.7500 - val_loss: 0.5018 - val_accuracy: 0.7519\n",
      "Epoch 472/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5003 - accuracy: 0.7498 - val_loss: 0.5031 - val_accuracy: 0.7485\n",
      "Epoch 473/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4991 - accuracy: 0.7507 - val_loss: 0.5025 - val_accuracy: 0.7517\n",
      "Epoch 474/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4996 - accuracy: 0.7493 - val_loss: 0.5050 - val_accuracy: 0.7470\n",
      "Epoch 475/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5002 - accuracy: 0.7500 - val_loss: 0.5068 - val_accuracy: 0.7437\n",
      "Epoch 476/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.4987 - accuracy: 0.7494 - val_loss: 0.5024 - val_accuracy: 0.7532\n",
      "Epoch 477/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.4988 - accuracy: 0.7488 - val_loss: 0.5018 - val_accuracy: 0.7489\n",
      "Epoch 478/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.4985 - accuracy: 0.7512 - val_loss: 0.5050 - val_accuracy: 0.7525\n",
      "Epoch 479/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.4992 - accuracy: 0.7508 - val_loss: 0.5017 - val_accuracy: 0.7523\n",
      "Epoch 480/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5012 - accuracy: 0.7479 - val_loss: 0.5021 - val_accuracy: 0.7507\n",
      "Epoch 481/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4981 - accuracy: 0.7528 - val_loss: 0.5037 - val_accuracy: 0.7477\n",
      "Epoch 482/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.4974 - accuracy: 0.7505 - val_loss: 0.5068 - val_accuracy: 0.7496\n",
      "Epoch 483/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4952 - accuracy: 0.7531 - val_loss: 0.5036 - val_accuracy: 0.7503\n",
      "Epoch 484/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5018 - accuracy: 0.7478 - val_loss: 0.5048 - val_accuracy: 0.7507\n",
      "Epoch 485/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.4989 - accuracy: 0.7510 - val_loss: 0.5014 - val_accuracy: 0.7507\n",
      "Epoch 486/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.4966 - accuracy: 0.7502 - val_loss: 0.5031 - val_accuracy: 0.7512\n",
      "Epoch 487/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4991 - accuracy: 0.7514 - val_loss: 0.5026 - val_accuracy: 0.7513\n",
      "Epoch 488/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.4966 - accuracy: 0.7528 - val_loss: 0.5004 - val_accuracy: 0.7530\n",
      "Epoch 489/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.4972 - accuracy: 0.7518 - val_loss: 0.5033 - val_accuracy: 0.7523\n",
      "Epoch 490/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.4967 - accuracy: 0.7531 - val_loss: 0.5036 - val_accuracy: 0.7504\n",
      "Epoch 491/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4963 - accuracy: 0.7519 - val_loss: 0.5019 - val_accuracy: 0.7524\n",
      "Epoch 492/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4977 - accuracy: 0.7527 - val_loss: 0.5011 - val_accuracy: 0.7527\n",
      "Epoch 493/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.4967 - accuracy: 0.7516 - val_loss: 0.5035 - val_accuracy: 0.7482\n",
      "Epoch 494/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.4990 - accuracy: 0.7501 - val_loss: 0.5044 - val_accuracy: 0.7491\n",
      "Epoch 495/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.4965 - accuracy: 0.7530 - val_loss: 0.5025 - val_accuracy: 0.7521\n",
      "Epoch 496/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.4979 - accuracy: 0.7514 - val_loss: 0.5044 - val_accuracy: 0.7501\n",
      "Epoch 497/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.4980 - accuracy: 0.7503 - val_loss: 0.5031 - val_accuracy: 0.7499\n",
      "Epoch 498/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.4976 - accuracy: 0.7499 - val_loss: 0.5082 - val_accuracy: 0.7503\n",
      "Epoch 499/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5004 - accuracy: 0.7500 - val_loss: 0.5022 - val_accuracy: 0.7527\n",
      "Epoch 500/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4936 - accuracy: 0.7538 - val_loss: 0.5031 - val_accuracy: 0.7520\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(shuffle(pd.DataFrame(x_train_resampled),random_state=1), shuffle(pd.DataFrame(y_train_resampled),random_state=1), epochs=500,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train_resampled)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_11.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 12\n",
    "-MinMax Scaler & Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 1,292\n",
      "Trainable params: 1,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.6201 - accuracy: 0.6430 - val_loss: 0.5778 - val_accuracy: 0.6910\n",
      "Epoch 2/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5796 - accuracy: 0.6863 - val_loss: 0.5765 - val_accuracy: 0.6914\n",
      "Epoch 3/500\n",
      "2878/2878 [==============================] - 2s 670us/step - loss: 0.5750 - accuracy: 0.6903 - val_loss: 0.5712 - val_accuracy: 0.6960\n",
      "Epoch 4/500\n",
      "2878/2878 [==============================] - 2s 663us/step - loss: 0.5703 - accuracy: 0.6950 - val_loss: 0.5706 - val_accuracy: 0.6948\n",
      "Epoch 5/500\n",
      "2878/2878 [==============================] - 2s 670us/step - loss: 0.5688 - accuracy: 0.6941 - val_loss: 0.5685 - val_accuracy: 0.7004\n",
      "Epoch 6/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5665 - accuracy: 0.6955 - val_loss: 0.5654 - val_accuracy: 0.7012\n",
      "Epoch 7/500\n",
      "2878/2878 [==============================] - 2s 668us/step - loss: 0.5626 - accuracy: 0.7020 - val_loss: 0.5609 - val_accuracy: 0.7042\n",
      "Epoch 8/500\n",
      "2878/2878 [==============================] - 2s 636us/step - loss: 0.5623 - accuracy: 0.7018 - val_loss: 0.5588 - val_accuracy: 0.7073\n",
      "Epoch 9/500\n",
      "2878/2878 [==============================] - 2s 661us/step - loss: 0.5571 - accuracy: 0.7056 - val_loss: 0.5571 - val_accuracy: 0.7074\n",
      "Epoch 10/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5569 - accuracy: 0.7057 - val_loss: 0.5535 - val_accuracy: 0.7100\n",
      "Epoch 11/500\n",
      "2878/2878 [==============================] - 2s 653us/step - loss: 0.5534 - accuracy: 0.7083 - val_loss: 0.5532 - val_accuracy: 0.7084\n",
      "Epoch 12/500\n",
      "2878/2878 [==============================] - 2s 653us/step - loss: 0.5549 - accuracy: 0.7062 - val_loss: 0.5530 - val_accuracy: 0.7096\n",
      "Epoch 13/500\n",
      "2878/2878 [==============================] - 2s 653us/step - loss: 0.5530 - accuracy: 0.7085 - val_loss: 0.5495 - val_accuracy: 0.7120\n",
      "Epoch 14/500\n",
      "2878/2878 [==============================] - 2s 656us/step - loss: 0.5502 - accuracy: 0.7111 - val_loss: 0.5560 - val_accuracy: 0.7087\n",
      "Epoch 15/500\n",
      "2878/2878 [==============================] - 2s 669us/step - loss: 0.5484 - accuracy: 0.7091 - val_loss: 0.5466 - val_accuracy: 0.7115\n",
      "Epoch 16/500\n",
      "2878/2878 [==============================] - 2s 659us/step - loss: 0.5461 - accuracy: 0.7126 - val_loss: 0.5448 - val_accuracy: 0.7148\n",
      "Epoch 17/500\n",
      "2878/2878 [==============================] - 2s 660us/step - loss: 0.5454 - accuracy: 0.7147 - val_loss: 0.5441 - val_accuracy: 0.7156\n",
      "Epoch 18/500\n",
      "2878/2878 [==============================] - 2s 667us/step - loss: 0.5423 - accuracy: 0.7164 - val_loss: 0.5439 - val_accuracy: 0.7136\n",
      "Epoch 19/500\n",
      "2878/2878 [==============================] - 2s 634us/step - loss: 0.5420 - accuracy: 0.7154 - val_loss: 0.5403 - val_accuracy: 0.7190\n",
      "Epoch 20/500\n",
      "2878/2878 [==============================] - 2s 660us/step - loss: 0.5431 - accuracy: 0.7149 - val_loss: 0.5474 - val_accuracy: 0.7140\n",
      "Epoch 21/500\n",
      "2878/2878 [==============================] - 2s 665us/step - loss: 0.5391 - accuracy: 0.7180 - val_loss: 0.5391 - val_accuracy: 0.7215\n",
      "Epoch 22/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.5393 - accuracy: 0.7166 - val_loss: 0.5385 - val_accuracy: 0.7176\n",
      "Epoch 23/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5388 - accuracy: 0.7168 - val_loss: 0.5367 - val_accuracy: 0.7198\n",
      "Epoch 24/500\n",
      "2878/2878 [==============================] - 2s 652us/step - loss: 0.5378 - accuracy: 0.7179 - val_loss: 0.5391 - val_accuracy: 0.7194\n",
      "Epoch 25/500\n",
      "2878/2878 [==============================] - 2s 645us/step - loss: 0.5348 - accuracy: 0.7231 - val_loss: 0.5390 - val_accuracy: 0.7217\n",
      "Epoch 26/500\n",
      "2878/2878 [==============================] - 2s 659us/step - loss: 0.5348 - accuracy: 0.7213 - val_loss: 0.5366 - val_accuracy: 0.7210\n",
      "Epoch 27/500\n",
      "2878/2878 [==============================] - 2s 666us/step - loss: 0.5372 - accuracy: 0.7191 - val_loss: 0.5349 - val_accuracy: 0.7219\n",
      "Epoch 28/500\n",
      "2878/2878 [==============================] - 2s 638us/step - loss: 0.5298 - accuracy: 0.7263 - val_loss: 0.5374 - val_accuracy: 0.7166\n",
      "Epoch 29/500\n",
      "2878/2878 [==============================] - 2s 664us/step - loss: 0.5332 - accuracy: 0.7220 - val_loss: 0.5361 - val_accuracy: 0.7219\n",
      "Epoch 30/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.5335 - accuracy: 0.7246 - val_loss: 0.5314 - val_accuracy: 0.7243\n",
      "Epoch 31/500\n",
      "2878/2878 [==============================] - 2s 637us/step - loss: 0.5326 - accuracy: 0.7239 - val_loss: 0.5343 - val_accuracy: 0.7214\n",
      "Epoch 32/500\n",
      "2878/2878 [==============================] - 2s 662us/step - loss: 0.5306 - accuracy: 0.7253 - val_loss: 0.5315 - val_accuracy: 0.7258\n",
      "Epoch 33/500\n",
      "2878/2878 [==============================] - 2s 671us/step - loss: 0.5312 - accuracy: 0.7244 - val_loss: 0.5314 - val_accuracy: 0.7243\n",
      "Epoch 34/500\n",
      "2878/2878 [==============================] - 2s 642us/step - loss: 0.5305 - accuracy: 0.7250 - val_loss: 0.5316 - val_accuracy: 0.7238\n",
      "Epoch 35/500\n",
      "2878/2878 [==============================] - 2s 665us/step - loss: 0.5270 - accuracy: 0.7276 - val_loss: 0.5277 - val_accuracy: 0.7282\n",
      "Epoch 36/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5275 - accuracy: 0.7275 - val_loss: 0.5289 - val_accuracy: 0.7282\n",
      "Epoch 37/500\n",
      "2878/2878 [==============================] - 2s 661us/step - loss: 0.5272 - accuracy: 0.7276 - val_loss: 0.5270 - val_accuracy: 0.7295\n",
      "Epoch 38/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5254 - accuracy: 0.7271 - val_loss: 0.5309 - val_accuracy: 0.7272\n",
      "Epoch 39/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5263 - accuracy: 0.7273 - val_loss: 0.5283 - val_accuracy: 0.7262\n",
      "Epoch 40/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5232 - accuracy: 0.7324 - val_loss: 0.5352 - val_accuracy: 0.7177\n",
      "Epoch 41/500\n",
      "2878/2878 [==============================] - 2s 654us/step - loss: 0.5252 - accuracy: 0.7272 - val_loss: 0.5237 - val_accuracy: 0.7353\n",
      "Epoch 42/500\n",
      "2878/2878 [==============================] - 2s 665us/step - loss: 0.5236 - accuracy: 0.7327 - val_loss: 0.5284 - val_accuracy: 0.7285\n",
      "Epoch 43/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5218 - accuracy: 0.7335 - val_loss: 0.5257 - val_accuracy: 0.7318\n",
      "Epoch 44/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5226 - accuracy: 0.7293 - val_loss: 0.5238 - val_accuracy: 0.7328\n",
      "Epoch 45/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5227 - accuracy: 0.7308 - val_loss: 0.5216 - val_accuracy: 0.7320\n",
      "Epoch 46/500\n",
      "2878/2878 [==============================] - 2s 658us/step - loss: 0.5201 - accuracy: 0.7338 - val_loss: 0.5301 - val_accuracy: 0.7267\n",
      "Epoch 47/500\n",
      "2878/2878 [==============================] - 2s 671us/step - loss: 0.5190 - accuracy: 0.7365 - val_loss: 0.5236 - val_accuracy: 0.7298\n",
      "Epoch 48/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5187 - accuracy: 0.7350 - val_loss: 0.5218 - val_accuracy: 0.7342\n",
      "Epoch 49/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5189 - accuracy: 0.7337 - val_loss: 0.5194 - val_accuracy: 0.7332\n",
      "Epoch 50/500\n",
      "2878/2878 [==============================] - 2s 655us/step - loss: 0.5169 - accuracy: 0.7363 - val_loss: 0.5224 - val_accuracy: 0.7338\n",
      "Epoch 51/500\n",
      "2878/2878 [==============================] - 2s 666us/step - loss: 0.5156 - accuracy: 0.7400 - val_loss: 0.5314 - val_accuracy: 0.7265\n",
      "Epoch 52/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5141 - accuracy: 0.7375 - val_loss: 0.5195 - val_accuracy: 0.7389\n",
      "Epoch 53/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5154 - accuracy: 0.7354 - val_loss: 0.5241 - val_accuracy: 0.7303\n",
      "Epoch 54/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5170 - accuracy: 0.7359 - val_loss: 0.5209 - val_accuracy: 0.7374\n",
      "Epoch 55/500\n",
      "2878/2878 [==============================] - 2s 671us/step - loss: 0.5150 - accuracy: 0.7371 - val_loss: 0.5222 - val_accuracy: 0.7335\n",
      "Epoch 56/500\n",
      "2878/2878 [==============================] - 2s 664us/step - loss: 0.5136 - accuracy: 0.7393 - val_loss: 0.5348 - val_accuracy: 0.7234\n",
      "Epoch 57/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5139 - accuracy: 0.7391 - val_loss: 0.5172 - val_accuracy: 0.7371\n",
      "Epoch 58/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5104 - accuracy: 0.7409 - val_loss: 0.5153 - val_accuracy: 0.7367\n",
      "Epoch 59/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5128 - accuracy: 0.7394 - val_loss: 0.5150 - val_accuracy: 0.7373\n",
      "Epoch 60/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5105 - accuracy: 0.7415 - val_loss: 0.5211 - val_accuracy: 0.7343\n",
      "Epoch 61/500\n",
      "2878/2878 [==============================] - 2s 661us/step - loss: 0.5134 - accuracy: 0.7385 - val_loss: 0.5165 - val_accuracy: 0.7370\n",
      "Epoch 62/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5122 - accuracy: 0.7398 - val_loss: 0.5186 - val_accuracy: 0.7316\n",
      "Epoch 63/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5133 - accuracy: 0.7394 - val_loss: 0.5170 - val_accuracy: 0.7328\n",
      "Epoch 64/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5114 - accuracy: 0.7391 - val_loss: 0.5149 - val_accuracy: 0.7362\n",
      "Epoch 65/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5084 - accuracy: 0.7410 - val_loss: 0.5134 - val_accuracy: 0.7388\n",
      "Epoch 66/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5142 - accuracy: 0.7377 - val_loss: 0.5157 - val_accuracy: 0.7353\n",
      "Epoch 67/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5119 - accuracy: 0.7389 - val_loss: 0.5147 - val_accuracy: 0.7359\n",
      "Epoch 68/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5088 - accuracy: 0.7421 - val_loss: 0.5139 - val_accuracy: 0.7393\n",
      "Epoch 69/500\n",
      "2878/2878 [==============================] - 2s 660us/step - loss: 0.5103 - accuracy: 0.7393 - val_loss: 0.5116 - val_accuracy: 0.7397\n",
      "Epoch 70/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5075 - accuracy: 0.7449 - val_loss: 0.5152 - val_accuracy: 0.7398\n",
      "Epoch 71/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5089 - accuracy: 0.7432 - val_loss: 0.5176 - val_accuracy: 0.7351\n",
      "Epoch 72/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5077 - accuracy: 0.7425 - val_loss: 0.5190 - val_accuracy: 0.7350\n",
      "Epoch 73/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5082 - accuracy: 0.7432 - val_loss: 0.5109 - val_accuracy: 0.7389\n",
      "Epoch 74/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.5049 - accuracy: 0.7431 - val_loss: 0.5128 - val_accuracy: 0.7365\n",
      "Epoch 75/500\n",
      "2878/2878 [==============================] - 2s 664us/step - loss: 0.5108 - accuracy: 0.7390 - val_loss: 0.5135 - val_accuracy: 0.7380\n",
      "Epoch 76/500\n",
      "2878/2878 [==============================] - 2s 669us/step - loss: 0.5068 - accuracy: 0.7435 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 77/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5071 - accuracy: 0.7438 - val_loss: 0.5142 - val_accuracy: 0.7363\n",
      "Epoch 78/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5077 - accuracy: 0.7422 - val_loss: 0.5198 - val_accuracy: 0.7328\n",
      "Epoch 79/500\n",
      "2878/2878 [==============================] - 2s 668us/step - loss: 0.5087 - accuracy: 0.7425 - val_loss: 0.5134 - val_accuracy: 0.7354\n",
      "Epoch 80/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5051 - accuracy: 0.7442 - val_loss: 0.5178 - val_accuracy: 0.7355\n",
      "Epoch 81/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5063 - accuracy: 0.7448 - val_loss: 0.5155 - val_accuracy: 0.7361\n",
      "Epoch 82/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5071 - accuracy: 0.7424 - val_loss: 0.5123 - val_accuracy: 0.7391\n",
      "Epoch 83/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5082 - accuracy: 0.7428 - val_loss: 0.5230 - val_accuracy: 0.7321\n",
      "Epoch 84/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5071 - accuracy: 0.7430 - val_loss: 0.5102 - val_accuracy: 0.7441\n",
      "Epoch 85/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5051 - accuracy: 0.7452 - val_loss: 0.5073 - val_accuracy: 0.7411\n",
      "Epoch 86/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5037 - accuracy: 0.7449 - val_loss: 0.5083 - val_accuracy: 0.7446\n",
      "Epoch 87/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5041 - accuracy: 0.7453 - val_loss: 0.5090 - val_accuracy: 0.7418\n",
      "Epoch 88/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5028 - accuracy: 0.7452 - val_loss: 0.5104 - val_accuracy: 0.7397\n",
      "Epoch 89/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5063 - accuracy: 0.7433 - val_loss: 0.5126 - val_accuracy: 0.7407\n",
      "Epoch 90/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5053 - accuracy: 0.7445 - val_loss: 0.5098 - val_accuracy: 0.7445\n",
      "Epoch 91/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5059 - accuracy: 0.7424 - val_loss: 0.5063 - val_accuracy: 0.7403\n",
      "Epoch 92/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5015 - accuracy: 0.7489 - val_loss: 0.5064 - val_accuracy: 0.7421\n",
      "Epoch 93/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5031 - accuracy: 0.7462 - val_loss: 0.5087 - val_accuracy: 0.7434\n",
      "Epoch 94/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5034 - accuracy: 0.7466 - val_loss: 0.5095 - val_accuracy: 0.7421\n",
      "Epoch 95/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5012 - accuracy: 0.7476 - val_loss: 0.5076 - val_accuracy: 0.7407\n",
      "Epoch 96/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5010 - accuracy: 0.7469 - val_loss: 0.5115 - val_accuracy: 0.7405\n",
      "Epoch 97/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5007 - accuracy: 0.7476 - val_loss: 0.5083 - val_accuracy: 0.7451\n",
      "Epoch 98/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5038 - accuracy: 0.7464 - val_loss: 0.5054 - val_accuracy: 0.7444\n",
      "Epoch 99/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5030 - accuracy: 0.7476 - val_loss: 0.5074 - val_accuracy: 0.7417\n",
      "Epoch 100/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5004 - accuracy: 0.7466 - val_loss: 0.5082 - val_accuracy: 0.7417\n",
      "Epoch 101/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5001 - accuracy: 0.7495 - val_loss: 0.5062 - val_accuracy: 0.7453\n",
      "Epoch 102/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5017 - accuracy: 0.7481 - val_loss: 0.5092 - val_accuracy: 0.7451\n",
      "Epoch 103/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.4994 - accuracy: 0.7474 - val_loss: 0.5029 - val_accuracy: 0.7487\n",
      "Epoch 104/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5008 - accuracy: 0.7479 - val_loss: 0.5051 - val_accuracy: 0.7461\n",
      "Epoch 105/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5018 - accuracy: 0.7470 - val_loss: 0.5087 - val_accuracy: 0.7412\n",
      "Epoch 106/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.4977 - accuracy: 0.7506 - val_loss: 0.5036 - val_accuracy: 0.7485\n",
      "Epoch 107/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.4993 - accuracy: 0.7498 - val_loss: 0.5027 - val_accuracy: 0.7485\n",
      "Epoch 108/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.4993 - accuracy: 0.7493 - val_loss: 0.5038 - val_accuracy: 0.7463\n",
      "Epoch 109/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5007 - accuracy: 0.7480 - val_loss: 0.5049 - val_accuracy: 0.7468\n",
      "Epoch 110/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.5008 - accuracy: 0.7476 - val_loss: 0.5051 - val_accuracy: 0.7456\n",
      "Epoch 111/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.4967 - accuracy: 0.7506 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 112/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.4978 - accuracy: 0.7496 - val_loss: 0.5133 - val_accuracy: 0.7431\n",
      "Epoch 113/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.4984 - accuracy: 0.7490 - val_loss: 0.5031 - val_accuracy: 0.7482\n",
      "Epoch 114/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.4996 - accuracy: 0.7491 - val_loss: 0.5057 - val_accuracy: 0.7467\n",
      "Epoch 115/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.4996 - accuracy: 0.7485 - val_loss: 0.5138 - val_accuracy: 0.7410\n",
      "Epoch 116/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4985 - accuracy: 0.7486 - val_loss: 0.5024 - val_accuracy: 0.7469\n",
      "Epoch 117/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.4951 - accuracy: 0.7522 - val_loss: 0.5013 - val_accuracy: 0.7502\n",
      "Epoch 118/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.4982 - accuracy: 0.7495 - val_loss: 0.5010 - val_accuracy: 0.7488\n",
      "Epoch 119/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.4969 - accuracy: 0.7510 - val_loss: 0.5009 - val_accuracy: 0.7486\n",
      "Epoch 120/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.4977 - accuracy: 0.7498 - val_loss: 0.5005 - val_accuracy: 0.7488\n",
      "Epoch 121/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.4963 - accuracy: 0.7499 - val_loss: 0.4991 - val_accuracy: 0.7504\n",
      "Epoch 122/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4991 - accuracy: 0.7500 - val_loss: 0.5032 - val_accuracy: 0.7490\n",
      "Epoch 123/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.4986 - accuracy: 0.7504 - val_loss: 0.5036 - val_accuracy: 0.7480\n",
      "Epoch 124/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4961 - accuracy: 0.7510 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 125/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4942 - accuracy: 0.7528 - val_loss: 0.4989 - val_accuracy: 0.7496\n",
      "Epoch 126/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.4976 - accuracy: 0.7509 - val_loss: 0.4999 - val_accuracy: 0.7497\n",
      "Epoch 127/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4959 - accuracy: 0.7515 - val_loss: 0.5023 - val_accuracy: 0.7473\n",
      "Epoch 128/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.4953 - accuracy: 0.7516 - val_loss: 0.5046 - val_accuracy: 0.7435\n",
      "Epoch 129/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.4924 - accuracy: 0.7540 - val_loss: 0.5070 - val_accuracy: 0.7458\n",
      "Epoch 130/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.4971 - accuracy: 0.7522 - val_loss: 0.5054 - val_accuracy: 0.7461\n",
      "Epoch 131/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.4931 - accuracy: 0.7532 - val_loss: 0.5021 - val_accuracy: 0.7484\n",
      "Epoch 132/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.4952 - accuracy: 0.7526 - val_loss: 0.5035 - val_accuracy: 0.7450\n",
      "Epoch 133/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.4954 - accuracy: 0.7537 - val_loss: 0.4969 - val_accuracy: 0.7520\n",
      "Epoch 134/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.4948 - accuracy: 0.7533 - val_loss: 0.5044 - val_accuracy: 0.7468\n",
      "Epoch 135/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4957 - accuracy: 0.7528 - val_loss: 0.4969 - val_accuracy: 0.7515\n",
      "Epoch 136/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4951 - accuracy: 0.7529 - val_loss: 0.5026 - val_accuracy: 0.7480\n",
      "Epoch 137/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.4930 - accuracy: 0.7553 - val_loss: 0.4988 - val_accuracy: 0.7511\n",
      "Epoch 138/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4944 - accuracy: 0.7538 - val_loss: 0.5002 - val_accuracy: 0.7494\n",
      "Epoch 139/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.4921 - accuracy: 0.7556 - val_loss: 0.5031 - val_accuracy: 0.7490\n",
      "Epoch 140/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.4967 - accuracy: 0.7514 - val_loss: 0.4975 - val_accuracy: 0.7508\n",
      "Epoch 141/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4924 - accuracy: 0.7548 - val_loss: 0.5047 - val_accuracy: 0.7472\n",
      "Epoch 142/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.4930 - accuracy: 0.7569 - val_loss: 0.5032 - val_accuracy: 0.7474\n",
      "Epoch 143/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.4942 - accuracy: 0.7527 - val_loss: 0.4988 - val_accuracy: 0.7478\n",
      "Epoch 144/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.4925 - accuracy: 0.7528 - val_loss: 0.4962 - val_accuracy: 0.7532\n",
      "Epoch 145/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4930 - accuracy: 0.7530 - val_loss: 0.4990 - val_accuracy: 0.7497\n",
      "Epoch 146/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.4942 - accuracy: 0.7540 - val_loss: 0.5049 - val_accuracy: 0.7493\n",
      "Epoch 147/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4949 - accuracy: 0.7527 - val_loss: 0.5031 - val_accuracy: 0.7463\n",
      "Epoch 148/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.4916 - accuracy: 0.7549 - val_loss: 0.5021 - val_accuracy: 0.7505\n",
      "Epoch 149/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.4930 - accuracy: 0.7544 - val_loss: 0.5013 - val_accuracy: 0.7507\n",
      "Epoch 150/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4918 - accuracy: 0.7540 - val_loss: 0.5094 - val_accuracy: 0.7444\n",
      "Epoch 151/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.4922 - accuracy: 0.7571 - val_loss: 0.5017 - val_accuracy: 0.7490\n",
      "Epoch 152/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.4953 - accuracy: 0.7525 - val_loss: 0.4989 - val_accuracy: 0.7486\n",
      "Epoch 153/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4936 - accuracy: 0.7539 - val_loss: 0.5025 - val_accuracy: 0.7497\n",
      "Epoch 154/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.4914 - accuracy: 0.7548 - val_loss: 0.4954 - val_accuracy: 0.7559\n",
      "Epoch 155/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.4932 - accuracy: 0.7535 - val_loss: 0.4971 - val_accuracy: 0.7521\n",
      "Epoch 156/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.4913 - accuracy: 0.7533 - val_loss: 0.4955 - val_accuracy: 0.7541\n",
      "Epoch 157/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.4929 - accuracy: 0.7532 - val_loss: 0.5010 - val_accuracy: 0.7498\n",
      "Epoch 158/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.4916 - accuracy: 0.7559 - val_loss: 0.4992 - val_accuracy: 0.7490\n",
      "Epoch 159/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.4913 - accuracy: 0.7546 - val_loss: 0.4981 - val_accuracy: 0.7505\n",
      "Epoch 160/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4902 - accuracy: 0.7561 - val_loss: 0.4966 - val_accuracy: 0.7534\n",
      "Epoch 161/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4903 - accuracy: 0.7555 - val_loss: 0.4953 - val_accuracy: 0.7536\n",
      "Epoch 162/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.4921 - accuracy: 0.7538 - val_loss: 0.5019 - val_accuracy: 0.7520\n",
      "Epoch 163/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4922 - accuracy: 0.7549 - val_loss: 0.5026 - val_accuracy: 0.7464\n",
      "Epoch 164/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4903 - accuracy: 0.7552 - val_loss: 0.4982 - val_accuracy: 0.7526\n",
      "Epoch 165/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.4952 - accuracy: 0.7524 - val_loss: 0.4987 - val_accuracy: 0.7516\n",
      "Epoch 166/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4921 - accuracy: 0.7555 - val_loss: 0.4991 - val_accuracy: 0.7503\n",
      "Epoch 167/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4920 - accuracy: 0.7542 - val_loss: 0.4952 - val_accuracy: 0.7550\n",
      "Epoch 168/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.4912 - accuracy: 0.7547 - val_loss: 0.4944 - val_accuracy: 0.7550\n",
      "Epoch 169/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4912 - accuracy: 0.7543 - val_loss: 0.4975 - val_accuracy: 0.7517\n",
      "Epoch 170/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4900 - accuracy: 0.7560 - val_loss: 0.5051 - val_accuracy: 0.7431\n",
      "Epoch 171/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.4905 - accuracy: 0.7573 - val_loss: 0.4971 - val_accuracy: 0.7497\n",
      "Epoch 172/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4878 - accuracy: 0.7596 - val_loss: 0.4967 - val_accuracy: 0.7511\n",
      "Epoch 173/500\n",
      "2878/2878 [==============================] - 2s 784us/step - loss: 0.4908 - accuracy: 0.7541 - val_loss: 0.4985 - val_accuracy: 0.7526\n",
      "Epoch 174/500\n",
      "2878/2878 [==============================] - 2s 749us/step - loss: 0.4891 - accuracy: 0.7569 - val_loss: 0.4955 - val_accuracy: 0.7517\n",
      "Epoch 175/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4875 - accuracy: 0.7566 - val_loss: 0.5008 - val_accuracy: 0.7520\n",
      "Epoch 176/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4912 - accuracy: 0.7569 - val_loss: 0.5027 - val_accuracy: 0.7431\n",
      "Epoch 177/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4886 - accuracy: 0.7577 - val_loss: 0.4954 - val_accuracy: 0.7533\n",
      "Epoch 178/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.4875 - accuracy: 0.7576 - val_loss: 0.5084 - val_accuracy: 0.7426\n",
      "Epoch 179/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4876 - accuracy: 0.7578 - val_loss: 0.5022 - val_accuracy: 0.7536\n",
      "Epoch 180/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4872 - accuracy: 0.7582 - val_loss: 0.4961 - val_accuracy: 0.7534\n",
      "Epoch 181/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4900 - accuracy: 0.7562 - val_loss: 0.5007 - val_accuracy: 0.7485\n",
      "Epoch 182/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4898 - accuracy: 0.7558 - val_loss: 0.5013 - val_accuracy: 0.7513\n",
      "Epoch 183/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.4870 - accuracy: 0.7578 - val_loss: 0.4942 - val_accuracy: 0.7537\n",
      "Epoch 184/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.4900 - accuracy: 0.7551 - val_loss: 0.4986 - val_accuracy: 0.7503\n",
      "Epoch 185/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.4871 - accuracy: 0.7584 - val_loss: 0.4950 - val_accuracy: 0.7521\n",
      "Epoch 186/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4880 - accuracy: 0.7576 - val_loss: 0.4938 - val_accuracy: 0.7555\n",
      "Epoch 187/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4915 - accuracy: 0.7554 - val_loss: 0.4973 - val_accuracy: 0.7518\n",
      "Epoch 188/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4879 - accuracy: 0.7567 - val_loss: 0.4902 - val_accuracy: 0.7585\n",
      "Epoch 189/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4893 - accuracy: 0.7583 - val_loss: 0.5034 - val_accuracy: 0.7407\n",
      "Epoch 190/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4892 - accuracy: 0.7579 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 191/500\n",
      "2878/2878 [==============================] - 2s 757us/step - loss: 0.4891 - accuracy: 0.7569 - val_loss: 0.4926 - val_accuracy: 0.7576\n",
      "Epoch 192/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4892 - accuracy: 0.7544 - val_loss: 0.4941 - val_accuracy: 0.7538\n",
      "Epoch 193/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4902 - accuracy: 0.7558 - val_loss: 0.5044 - val_accuracy: 0.7422\n",
      "Epoch 194/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.4899 - accuracy: 0.7570 - val_loss: 0.4951 - val_accuracy: 0.7533\n",
      "Epoch 195/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4882 - accuracy: 0.7560 - val_loss: 0.4951 - val_accuracy: 0.7546\n",
      "Epoch 196/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.4866 - accuracy: 0.7600 - val_loss: 0.4954 - val_accuracy: 0.7539\n",
      "Epoch 197/500\n",
      "2878/2878 [==============================] - 2s 750us/step - loss: 0.4835 - accuracy: 0.7598 - val_loss: 0.4993 - val_accuracy: 0.7521\n",
      "Epoch 198/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4886 - accuracy: 0.7589 - val_loss: 0.4942 - val_accuracy: 0.7549\n",
      "Epoch 199/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4854 - accuracy: 0.7608 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 200/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.4868 - accuracy: 0.7583 - val_loss: 0.4937 - val_accuracy: 0.7542\n",
      "Epoch 201/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4906 - accuracy: 0.7551 - val_loss: 0.4932 - val_accuracy: 0.7556\n",
      "Epoch 202/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.4863 - accuracy: 0.7572 - val_loss: 0.4918 - val_accuracy: 0.7554\n",
      "Epoch 203/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4882 - accuracy: 0.7574 - val_loss: 0.4961 - val_accuracy: 0.7542\n",
      "Epoch 204/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.4835 - accuracy: 0.7626 - val_loss: 0.4941 - val_accuracy: 0.7524\n",
      "Epoch 205/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4881 - accuracy: 0.7587 - val_loss: 0.4956 - val_accuracy: 0.7540\n",
      "Epoch 206/500\n",
      "2878/2878 [==============================] - 2s 747us/step - loss: 0.4876 - accuracy: 0.7599 - val_loss: 0.4932 - val_accuracy: 0.7553\n",
      "Epoch 207/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.4881 - accuracy: 0.7572 - val_loss: 0.4971 - val_accuracy: 0.7522\n",
      "Epoch 208/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.4884 - accuracy: 0.7566 - val_loss: 0.4988 - val_accuracy: 0.7515\n",
      "Epoch 209/500\n",
      "2878/2878 [==============================] - 2s 749us/step - loss: 0.4872 - accuracy: 0.7589 - val_loss: 0.4938 - val_accuracy: 0.7565\n",
      "Epoch 210/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4869 - accuracy: 0.7571 - val_loss: 0.4965 - val_accuracy: 0.7532\n",
      "Epoch 211/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4878 - accuracy: 0.7577 - val_loss: 0.4933 - val_accuracy: 0.7529\n",
      "Epoch 212/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.4870 - accuracy: 0.7585 - val_loss: 0.4938 - val_accuracy: 0.7551\n",
      "Epoch 213/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4872 - accuracy: 0.7579 - val_loss: 0.4961 - val_accuracy: 0.7527\n",
      "Epoch 214/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4897 - accuracy: 0.7549 - val_loss: 0.4906 - val_accuracy: 0.7603\n",
      "Epoch 215/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.4860 - accuracy: 0.7599 - val_loss: 0.4938 - val_accuracy: 0.7544\n",
      "Epoch 216/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.4877 - accuracy: 0.7575 - val_loss: 0.4920 - val_accuracy: 0.7556\n",
      "Epoch 217/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4881 - accuracy: 0.7589 - val_loss: 0.5059 - val_accuracy: 0.7514\n",
      "Epoch 218/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.4860 - accuracy: 0.7602 - val_loss: 0.4996 - val_accuracy: 0.7525\n",
      "Epoch 219/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.4895 - accuracy: 0.7572 - val_loss: 0.4963 - val_accuracy: 0.7527\n",
      "Epoch 220/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.4875 - accuracy: 0.7580 - val_loss: 0.4889 - val_accuracy: 0.7591\n",
      "Epoch 221/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4857 - accuracy: 0.7572 - val_loss: 0.4946 - val_accuracy: 0.7568\n",
      "Epoch 222/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4839 - accuracy: 0.7621 - val_loss: 0.4906 - val_accuracy: 0.7570\n",
      "Epoch 223/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4869 - accuracy: 0.7590 - val_loss: 0.4995 - val_accuracy: 0.7492\n",
      "Epoch 224/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.4865 - accuracy: 0.7586 - val_loss: 0.4965 - val_accuracy: 0.7545\n",
      "Epoch 225/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4821 - accuracy: 0.7620 - val_loss: 0.4968 - val_accuracy: 0.7517\n",
      "Epoch 226/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4832 - accuracy: 0.7615 - val_loss: 0.4946 - val_accuracy: 0.7577\n",
      "Epoch 227/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4869 - accuracy: 0.7585 - val_loss: 0.4939 - val_accuracy: 0.7557\n",
      "Epoch 228/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4875 - accuracy: 0.7584 - val_loss: 0.5000 - val_accuracy: 0.7484\n",
      "Epoch 229/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4858 - accuracy: 0.7588 - val_loss: 0.4950 - val_accuracy: 0.7571\n",
      "Epoch 230/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4853 - accuracy: 0.7606 - val_loss: 0.4945 - val_accuracy: 0.7549\n",
      "Epoch 231/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.4860 - accuracy: 0.7602 - val_loss: 0.4921 - val_accuracy: 0.7576\n",
      "Epoch 232/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.4859 - accuracy: 0.7586 - val_loss: 0.4937 - val_accuracy: 0.7580\n",
      "Epoch 233/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4823 - accuracy: 0.7627 - val_loss: 0.4957 - val_accuracy: 0.7515\n",
      "Epoch 234/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4861 - accuracy: 0.7592 - val_loss: 0.4949 - val_accuracy: 0.7551\n",
      "Epoch 235/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4892 - accuracy: 0.7590 - val_loss: 0.4890 - val_accuracy: 0.7603\n",
      "Epoch 236/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4848 - accuracy: 0.7595 - val_loss: 0.4963 - val_accuracy: 0.7563\n",
      "Epoch 237/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4855 - accuracy: 0.7624 - val_loss: 0.4918 - val_accuracy: 0.7565\n",
      "Epoch 238/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4838 - accuracy: 0.7594 - val_loss: 0.4936 - val_accuracy: 0.7517\n",
      "Epoch 239/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4856 - accuracy: 0.7615 - val_loss: 0.4949 - val_accuracy: 0.7547\n",
      "Epoch 240/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.4834 - accuracy: 0.7633 - val_loss: 0.4937 - val_accuracy: 0.7586\n",
      "Epoch 241/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4864 - accuracy: 0.7594 - val_loss: 0.4933 - val_accuracy: 0.7554\n",
      "Epoch 242/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4844 - accuracy: 0.7593 - val_loss: 0.4916 - val_accuracy: 0.7609\n",
      "Epoch 243/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.4820 - accuracy: 0.7629 - val_loss: 0.4904 - val_accuracy: 0.7602\n",
      "Epoch 244/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4832 - accuracy: 0.7606 - val_loss: 0.4998 - val_accuracy: 0.7545\n",
      "Epoch 245/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.4837 - accuracy: 0.7624 - val_loss: 0.4918 - val_accuracy: 0.7563\n",
      "Epoch 246/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4821 - accuracy: 0.7637 - val_loss: 0.4899 - val_accuracy: 0.7565\n",
      "Epoch 247/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.4814 - accuracy: 0.7628 - val_loss: 0.4929 - val_accuracy: 0.7554\n",
      "Epoch 248/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4837 - accuracy: 0.7611 - val_loss: 0.4903 - val_accuracy: 0.7581\n",
      "Epoch 249/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4852 - accuracy: 0.7598 - val_loss: 0.4943 - val_accuracy: 0.7549\n",
      "Epoch 250/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4850 - accuracy: 0.7589 - val_loss: 0.4927 - val_accuracy: 0.7603\n",
      "Epoch 251/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4858 - accuracy: 0.7603 - val_loss: 0.4921 - val_accuracy: 0.7574\n",
      "Epoch 252/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4826 - accuracy: 0.7618 - val_loss: 0.4940 - val_accuracy: 0.7564\n",
      "Epoch 253/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4827 - accuracy: 0.7650 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 254/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.4833 - accuracy: 0.7613 - val_loss: 0.4958 - val_accuracy: 0.7528\n",
      "Epoch 255/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.4810 - accuracy: 0.7629 - val_loss: 0.4974 - val_accuracy: 0.7546\n",
      "Epoch 256/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4867 - accuracy: 0.7589 - val_loss: 0.4930 - val_accuracy: 0.7553\n",
      "Epoch 257/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4853 - accuracy: 0.7596 - val_loss: 0.4889 - val_accuracy: 0.7607\n",
      "Epoch 258/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4840 - accuracy: 0.7621 - val_loss: 0.4955 - val_accuracy: 0.7547\n",
      "Epoch 259/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.4843 - accuracy: 0.7599 - val_loss: 0.4928 - val_accuracy: 0.7551\n",
      "Epoch 260/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.4846 - accuracy: 0.7608 - val_loss: 0.4916 - val_accuracy: 0.7550\n",
      "Epoch 261/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4811 - accuracy: 0.7627 - val_loss: 0.4942 - val_accuracy: 0.7531\n",
      "Epoch 262/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.4810 - accuracy: 0.7632 - val_loss: 0.4872 - val_accuracy: 0.7612\n",
      "Epoch 263/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.4831 - accuracy: 0.7612 - val_loss: 0.4897 - val_accuracy: 0.7583\n",
      "Epoch 264/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4834 - accuracy: 0.7615 - val_loss: 0.4900 - val_accuracy: 0.7601\n",
      "Epoch 265/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4813 - accuracy: 0.7620 - val_loss: 0.4944 - val_accuracy: 0.7556\n",
      "Epoch 266/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4817 - accuracy: 0.7642 - val_loss: 0.4998 - val_accuracy: 0.7476\n",
      "Epoch 267/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4819 - accuracy: 0.7624 - val_loss: 0.4929 - val_accuracy: 0.7586\n",
      "Epoch 268/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4796 - accuracy: 0.7628 - val_loss: 0.4909 - val_accuracy: 0.7614\n",
      "Epoch 269/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.4872 - accuracy: 0.7595 - val_loss: 0.4915 - val_accuracy: 0.7585\n",
      "Epoch 270/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4846 - accuracy: 0.7614 - val_loss: 0.4902 - val_accuracy: 0.7583\n",
      "Epoch 271/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4815 - accuracy: 0.7614 - val_loss: 0.4882 - val_accuracy: 0.7590\n",
      "Epoch 272/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4803 - accuracy: 0.7624 - val_loss: 0.4879 - val_accuracy: 0.7612\n",
      "Epoch 273/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4812 - accuracy: 0.7638 - val_loss: 0.4887 - val_accuracy: 0.7629\n",
      "Epoch 274/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4830 - accuracy: 0.7637 - val_loss: 0.4890 - val_accuracy: 0.7593\n",
      "Epoch 275/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4822 - accuracy: 0.7614 - val_loss: 0.4961 - val_accuracy: 0.7546\n",
      "Epoch 276/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4825 - accuracy: 0.7635 - val_loss: 0.4919 - val_accuracy: 0.7555\n",
      "Epoch 277/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4818 - accuracy: 0.7631 - val_loss: 0.4928 - val_accuracy: 0.7578\n",
      "Epoch 278/500\n",
      "2878/2878 [==============================] - 2s 766us/step - loss: 0.4851 - accuracy: 0.7599 - val_loss: 0.4948 - val_accuracy: 0.7556\n",
      "Epoch 279/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.4814 - accuracy: 0.7639 - val_loss: 0.4885 - val_accuracy: 0.7626\n",
      "Epoch 280/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4830 - accuracy: 0.7612 - val_loss: 0.4879 - val_accuracy: 0.7602\n",
      "Epoch 281/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.4816 - accuracy: 0.7622 - val_loss: 0.4960 - val_accuracy: 0.7588\n",
      "Epoch 282/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4838 - accuracy: 0.7616 - val_loss: 0.4896 - val_accuracy: 0.7609\n",
      "Epoch 283/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4843 - accuracy: 0.7617 - val_loss: 0.4957 - val_accuracy: 0.7518\n",
      "Epoch 284/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4810 - accuracy: 0.7652 - val_loss: 0.4925 - val_accuracy: 0.7581\n",
      "Epoch 285/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4816 - accuracy: 0.7621 - val_loss: 0.4899 - val_accuracy: 0.7543\n",
      "Epoch 286/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.4801 - accuracy: 0.7628 - val_loss: 0.4904 - val_accuracy: 0.7613\n",
      "Epoch 287/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.4813 - accuracy: 0.7630 - val_loss: 0.4893 - val_accuracy: 0.7606\n",
      "Epoch 288/500\n",
      "2878/2878 [==============================] - 2s 747us/step - loss: 0.4804 - accuracy: 0.7635 - val_loss: 0.4918 - val_accuracy: 0.7594\n",
      "Epoch 289/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4818 - accuracy: 0.7631 - val_loss: 0.4938 - val_accuracy: 0.7532\n",
      "Epoch 290/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4823 - accuracy: 0.7625 - val_loss: 0.4909 - val_accuracy: 0.7603\n",
      "Epoch 291/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.4823 - accuracy: 0.7618 - val_loss: 0.4930 - val_accuracy: 0.7593\n",
      "Epoch 292/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4822 - accuracy: 0.7622 - val_loss: 0.4901 - val_accuracy: 0.7592\n",
      "Epoch 293/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4786 - accuracy: 0.7655 - val_loss: 0.4936 - val_accuracy: 0.7543\n",
      "Epoch 294/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.4764 - accuracy: 0.7669 - val_loss: 0.4889 - val_accuracy: 0.7609\n",
      "Epoch 295/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4819 - accuracy: 0.7631 - val_loss: 0.4872 - val_accuracy: 0.7631\n",
      "Epoch 296/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4792 - accuracy: 0.7655 - val_loss: 0.4929 - val_accuracy: 0.7571\n",
      "Epoch 297/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.4806 - accuracy: 0.7645 - val_loss: 0.4869 - val_accuracy: 0.7622\n",
      "Epoch 298/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4815 - accuracy: 0.7640 - val_loss: 0.4897 - val_accuracy: 0.7589\n",
      "Epoch 299/500\n",
      "2878/2878 [==============================] - 2s 754us/step - loss: 0.4818 - accuracy: 0.7641 - val_loss: 0.4927 - val_accuracy: 0.7560\n",
      "Epoch 300/500\n",
      "2878/2878 [==============================] - 2s 760us/step - loss: 0.4816 - accuracy: 0.7626 - val_loss: 0.4882 - val_accuracy: 0.7603\n",
      "Epoch 301/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4812 - accuracy: 0.7620 - val_loss: 0.4911 - val_accuracy: 0.7591\n",
      "Epoch 302/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4815 - accuracy: 0.7627 - val_loss: 0.4885 - val_accuracy: 0.7634\n",
      "Epoch 303/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4788 - accuracy: 0.7662 - val_loss: 0.4871 - val_accuracy: 0.7639\n",
      "Epoch 304/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.4809 - accuracy: 0.7634 - val_loss: 0.4867 - val_accuracy: 0.7647\n",
      "Epoch 305/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.4799 - accuracy: 0.7631 - val_loss: 0.4874 - val_accuracy: 0.7631\n",
      "Epoch 306/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4828 - accuracy: 0.7645 - val_loss: 0.4894 - val_accuracy: 0.7611\n",
      "Epoch 307/500\n",
      "2878/2878 [==============================] - 2s 799us/step - loss: 0.4805 - accuracy: 0.7625 - val_loss: 0.4920 - val_accuracy: 0.7608\n",
      "Epoch 308/500\n",
      "2878/2878 [==============================] - 2s 765us/step - loss: 0.4843 - accuracy: 0.7612 - val_loss: 0.4856 - val_accuracy: 0.7637\n",
      "Epoch 309/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.4807 - accuracy: 0.7651 - val_loss: 0.4863 - val_accuracy: 0.7625\n",
      "Epoch 310/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4792 - accuracy: 0.7649 - val_loss: 0.4887 - val_accuracy: 0.7584\n",
      "Epoch 311/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4803 - accuracy: 0.7651 - val_loss: 0.4895 - val_accuracy: 0.7600\n",
      "Epoch 312/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4816 - accuracy: 0.7638 - val_loss: 0.4884 - val_accuracy: 0.7575\n",
      "Epoch 313/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4786 - accuracy: 0.7657 - val_loss: 0.4905 - val_accuracy: 0.7599\n",
      "Epoch 314/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.4811 - accuracy: 0.7628 - val_loss: 0.4858 - val_accuracy: 0.7619\n",
      "Epoch 315/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4812 - accuracy: 0.7646 - val_loss: 0.4901 - val_accuracy: 0.7573\n",
      "Epoch 316/500\n",
      "2878/2878 [==============================] - 2s 750us/step - loss: 0.4816 - accuracy: 0.7638 - val_loss: 0.4921 - val_accuracy: 0.7578\n",
      "Epoch 317/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4805 - accuracy: 0.7635 - val_loss: 0.4901 - val_accuracy: 0.7608\n",
      "Epoch 318/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.4786 - accuracy: 0.7655 - val_loss: 0.4903 - val_accuracy: 0.7577\n",
      "Epoch 319/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.4797 - accuracy: 0.7627 - val_loss: 0.4876 - val_accuracy: 0.7614\n",
      "Epoch 320/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4784 - accuracy: 0.7656 - val_loss: 0.4851 - val_accuracy: 0.7649\n",
      "Epoch 321/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4787 - accuracy: 0.7666 - val_loss: 0.4943 - val_accuracy: 0.7525\n",
      "Epoch 322/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.4837 - accuracy: 0.7620 - val_loss: 0.4937 - val_accuracy: 0.7587\n",
      "Epoch 323/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4816 - accuracy: 0.7620 - val_loss: 0.4861 - val_accuracy: 0.7625\n",
      "Epoch 324/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4804 - accuracy: 0.7640 - val_loss: 0.4892 - val_accuracy: 0.7583\n",
      "Epoch 325/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4787 - accuracy: 0.7655 - val_loss: 0.4877 - val_accuracy: 0.7631\n",
      "Epoch 326/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4794 - accuracy: 0.7641 - val_loss: 0.4901 - val_accuracy: 0.7566\n",
      "Epoch 327/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4823 - accuracy: 0.7625 - val_loss: 0.4898 - val_accuracy: 0.7609\n",
      "Epoch 328/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4803 - accuracy: 0.7642 - val_loss: 0.4867 - val_accuracy: 0.7616\n",
      "Epoch 329/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4786 - accuracy: 0.7669 - val_loss: 0.4900 - val_accuracy: 0.7580\n",
      "Epoch 330/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4771 - accuracy: 0.7676 - val_loss: 0.4897 - val_accuracy: 0.7599\n",
      "Epoch 331/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4799 - accuracy: 0.7639 - val_loss: 0.4861 - val_accuracy: 0.7626\n",
      "Epoch 332/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4790 - accuracy: 0.7654 - val_loss: 0.4894 - val_accuracy: 0.7593\n",
      "Epoch 333/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4809 - accuracy: 0.7651 - val_loss: 0.4885 - val_accuracy: 0.7621\n",
      "Epoch 334/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4823 - accuracy: 0.7614 - val_loss: 0.4887 - val_accuracy: 0.7614\n",
      "Epoch 335/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.4808 - accuracy: 0.7645 - val_loss: 0.4842 - val_accuracy: 0.7611\n",
      "Epoch 336/500\n",
      "2878/2878 [==============================] - 2s 750us/step - loss: 0.4770 - accuracy: 0.7652 - val_loss: 0.4929 - val_accuracy: 0.7594\n",
      "Epoch 337/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.4776 - accuracy: 0.7661 - val_loss: 0.4898 - val_accuracy: 0.7574\n",
      "Epoch 338/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4790 - accuracy: 0.7668 - val_loss: 0.4844 - val_accuracy: 0.7627\n",
      "Epoch 339/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.4791 - accuracy: 0.7652 - val_loss: 0.4887 - val_accuracy: 0.7611\n",
      "Epoch 340/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4800 - accuracy: 0.7634 - val_loss: 0.4895 - val_accuracy: 0.7623\n",
      "Epoch 341/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4788 - accuracy: 0.7662 - val_loss: 0.4853 - val_accuracy: 0.7622\n",
      "Epoch 342/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4812 - accuracy: 0.7641 - val_loss: 0.4917 - val_accuracy: 0.7583\n",
      "Epoch 343/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.4767 - accuracy: 0.7674 - val_loss: 0.4886 - val_accuracy: 0.7617\n",
      "Epoch 344/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4820 - accuracy: 0.7636 - val_loss: 0.4995 - val_accuracy: 0.7503\n",
      "Epoch 345/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4807 - accuracy: 0.7621 - val_loss: 0.4884 - val_accuracy: 0.7587\n",
      "Epoch 346/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4816 - accuracy: 0.7625 - val_loss: 0.4875 - val_accuracy: 0.7613\n",
      "Epoch 347/500\n",
      "2878/2878 [==============================] - 2s 756us/step - loss: 0.4795 - accuracy: 0.7646 - val_loss: 0.4868 - val_accuracy: 0.7619\n",
      "Epoch 348/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.4776 - accuracy: 0.7653 - val_loss: 0.4893 - val_accuracy: 0.7594\n",
      "Epoch 349/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4802 - accuracy: 0.7628 - val_loss: 0.4860 - val_accuracy: 0.7642\n",
      "Epoch 350/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4802 - accuracy: 0.7648 - val_loss: 0.4910 - val_accuracy: 0.7596\n",
      "Epoch 351/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4799 - accuracy: 0.7633 - val_loss: 0.4920 - val_accuracy: 0.7570\n",
      "Epoch 352/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4779 - accuracy: 0.7628 - val_loss: 0.4858 - val_accuracy: 0.7629\n",
      "Epoch 353/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.4793 - accuracy: 0.7653 - val_loss: 0.4892 - val_accuracy: 0.7648\n",
      "Epoch 354/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.4740 - accuracy: 0.7679 - val_loss: 0.4924 - val_accuracy: 0.7509\n",
      "Epoch 355/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4772 - accuracy: 0.7662 - val_loss: 0.4914 - val_accuracy: 0.7573\n",
      "Epoch 356/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4790 - accuracy: 0.7658 - val_loss: 0.4936 - val_accuracy: 0.7622\n",
      "Epoch 357/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4800 - accuracy: 0.7648 - val_loss: 0.4885 - val_accuracy: 0.7599\n",
      "Epoch 358/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4790 - accuracy: 0.7655 - val_loss: 0.4901 - val_accuracy: 0.7615\n",
      "Epoch 359/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4786 - accuracy: 0.7640 - val_loss: 0.4949 - val_accuracy: 0.7596\n",
      "Epoch 360/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4773 - accuracy: 0.7669 - val_loss: 0.4865 - val_accuracy: 0.7610\n",
      "Epoch 361/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4781 - accuracy: 0.7636 - val_loss: 0.4872 - val_accuracy: 0.7622\n",
      "Epoch 362/500\n",
      "2878/2878 [==============================] - 2s 757us/step - loss: 0.4786 - accuracy: 0.7674 - val_loss: 0.4849 - val_accuracy: 0.7621\n",
      "Epoch 363/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.4771 - accuracy: 0.7677 - val_loss: 0.4869 - val_accuracy: 0.7641\n",
      "Epoch 364/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.4759 - accuracy: 0.7646 - val_loss: 0.4874 - val_accuracy: 0.7651\n",
      "Epoch 365/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4799 - accuracy: 0.7646 - val_loss: 0.4843 - val_accuracy: 0.7628\n",
      "Epoch 366/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4772 - accuracy: 0.7666 - val_loss: 0.4864 - val_accuracy: 0.7655\n",
      "Epoch 367/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4796 - accuracy: 0.7646 - val_loss: 0.4906 - val_accuracy: 0.7587\n",
      "Epoch 368/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.4774 - accuracy: 0.7654 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 369/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4789 - accuracy: 0.7661 - val_loss: 0.4861 - val_accuracy: 0.7621\n",
      "Epoch 370/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4765 - accuracy: 0.7651 - val_loss: 0.4924 - val_accuracy: 0.7606\n",
      "Epoch 371/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.4781 - accuracy: 0.7669 - val_loss: 0.4888 - val_accuracy: 0.7594\n",
      "Epoch 372/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.4775 - accuracy: 0.7646 - val_loss: 0.4883 - val_accuracy: 0.7623\n",
      "Epoch 373/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.4768 - accuracy: 0.7664 - val_loss: 0.4882 - val_accuracy: 0.7596\n",
      "Epoch 374/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4769 - accuracy: 0.7688 - val_loss: 0.4855 - val_accuracy: 0.7626\n",
      "Epoch 375/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.4782 - accuracy: 0.7649 - val_loss: 0.4856 - val_accuracy: 0.7617\n",
      "Epoch 376/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4788 - accuracy: 0.7646 - val_loss: 0.4854 - val_accuracy: 0.7646\n",
      "Epoch 377/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4775 - accuracy: 0.7654 - val_loss: 0.4944 - val_accuracy: 0.7518\n",
      "Epoch 378/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4797 - accuracy: 0.7617 - val_loss: 0.4879 - val_accuracy: 0.7607\n",
      "Epoch 379/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4780 - accuracy: 0.7646 - val_loss: 0.4901 - val_accuracy: 0.7612\n",
      "Epoch 380/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.4775 - accuracy: 0.7660 - val_loss: 0.4860 - val_accuracy: 0.7614\n",
      "Epoch 381/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4791 - accuracy: 0.7643 - val_loss: 0.4879 - val_accuracy: 0.7603\n",
      "Epoch 382/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4755 - accuracy: 0.7678 - val_loss: 0.4869 - val_accuracy: 0.7590\n",
      "Epoch 383/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4806 - accuracy: 0.7641 - val_loss: 0.4902 - val_accuracy: 0.7603\n",
      "Epoch 384/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4763 - accuracy: 0.7675 - val_loss: 0.4844 - val_accuracy: 0.7642\n",
      "Epoch 385/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4773 - accuracy: 0.7667 - val_loss: 0.4877 - val_accuracy: 0.7621\n",
      "Epoch 386/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.4807 - accuracy: 0.7636 - val_loss: 0.4871 - val_accuracy: 0.7626\n",
      "Epoch 387/500\n",
      "2878/2878 [==============================] - 2s 745us/step - loss: 0.4785 - accuracy: 0.7645 - val_loss: 0.4867 - val_accuracy: 0.7623\n",
      "Epoch 388/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4785 - accuracy: 0.7657 - val_loss: 0.4820 - val_accuracy: 0.7672\n",
      "Epoch 389/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4780 - accuracy: 0.7658 - val_loss: 0.4833 - val_accuracy: 0.7667\n",
      "Epoch 390/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.4807 - accuracy: 0.7649 - val_loss: 0.4886 - val_accuracy: 0.7626\n",
      "Epoch 391/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4781 - accuracy: 0.7657 - val_loss: 0.4854 - val_accuracy: 0.7619\n",
      "Epoch 392/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4751 - accuracy: 0.7684 - val_loss: 0.4882 - val_accuracy: 0.7636\n",
      "Epoch 393/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4797 - accuracy: 0.7643 - val_loss: 0.4839 - val_accuracy: 0.7648\n",
      "Epoch 394/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4827 - accuracy: 0.7625 - val_loss: 0.4865 - val_accuracy: 0.7637\n",
      "Epoch 395/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4792 - accuracy: 0.7655 - val_loss: 0.4860 - val_accuracy: 0.7641\n",
      "Epoch 396/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4773 - accuracy: 0.7669 - val_loss: 0.4911 - val_accuracy: 0.7588\n",
      "Epoch 397/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4772 - accuracy: 0.7665 - val_loss: 0.4830 - val_accuracy: 0.7667\n",
      "Epoch 398/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.4775 - accuracy: 0.7653 - val_loss: 0.4840 - val_accuracy: 0.7643\n",
      "Epoch 399/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.4855 - val_accuracy: 0.7637\n",
      "Epoch 400/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4786 - accuracy: 0.7636 - val_loss: 0.4910 - val_accuracy: 0.7600\n",
      "Epoch 401/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4769 - accuracy: 0.7679 - val_loss: 0.4895 - val_accuracy: 0.7585\n",
      "Epoch 402/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.4718 - accuracy: 0.7703 - val_loss: 0.4865 - val_accuracy: 0.7627\n",
      "Epoch 403/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4753 - accuracy: 0.7676 - val_loss: 0.4876 - val_accuracy: 0.7605\n",
      "Epoch 404/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4766 - accuracy: 0.7668 - val_loss: 0.4870 - val_accuracy: 0.7628\n",
      "Epoch 405/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4762 - accuracy: 0.7678 - val_loss: 0.4875 - val_accuracy: 0.7634\n",
      "Epoch 406/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4750 - accuracy: 0.7674 - val_loss: 0.4878 - val_accuracy: 0.7624\n",
      "Epoch 407/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4748 - accuracy: 0.7672 - val_loss: 0.4867 - val_accuracy: 0.7642\n",
      "Epoch 408/500\n",
      "2878/2878 [==============================] - 2s 764us/step - loss: 0.4758 - accuracy: 0.7673 - val_loss: 0.4888 - val_accuracy: 0.7597\n",
      "Epoch 409/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.4765 - accuracy: 0.7683 - val_loss: 0.4855 - val_accuracy: 0.7649\n",
      "Epoch 410/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.4757 - accuracy: 0.7675 - val_loss: 0.4915 - val_accuracy: 0.7600\n",
      "Epoch 411/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4791 - accuracy: 0.7642 - val_loss: 0.4858 - val_accuracy: 0.7619\n",
      "Epoch 412/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4751 - accuracy: 0.7663 - val_loss: 0.4830 - val_accuracy: 0.7652\n",
      "Epoch 413/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4769 - accuracy: 0.7677 - val_loss: 0.4836 - val_accuracy: 0.7670\n",
      "Epoch 414/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.4769 - accuracy: 0.7670 - val_loss: 0.4862 - val_accuracy: 0.7632\n",
      "Epoch 415/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4756 - accuracy: 0.7665 - val_loss: 0.4904 - val_accuracy: 0.7569\n",
      "Epoch 416/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4761 - accuracy: 0.7670 - val_loss: 0.4841 - val_accuracy: 0.7643\n",
      "Epoch 417/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4772 - accuracy: 0.7666 - val_loss: 0.4835 - val_accuracy: 0.7659\n",
      "Epoch 418/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.4776 - accuracy: 0.7664 - val_loss: 0.4855 - val_accuracy: 0.7653\n",
      "Epoch 419/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4798 - accuracy: 0.7630 - val_loss: 0.4844 - val_accuracy: 0.7651\n",
      "Epoch 420/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4729 - accuracy: 0.7688 - val_loss: 0.4863 - val_accuracy: 0.7645\n",
      "Epoch 421/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4770 - accuracy: 0.7683 - val_loss: 0.4892 - val_accuracy: 0.7600\n",
      "Epoch 422/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.4746 - accuracy: 0.7676 - val_loss: 0.4858 - val_accuracy: 0.7673\n",
      "Epoch 423/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.4761 - accuracy: 0.7675 - val_loss: 0.4867 - val_accuracy: 0.7640\n",
      "Epoch 424/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4739 - accuracy: 0.7697 - val_loss: 0.4885 - val_accuracy: 0.7622\n",
      "Epoch 425/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4770 - accuracy: 0.7672 - val_loss: 0.4857 - val_accuracy: 0.7626\n",
      "Epoch 426/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4747 - accuracy: 0.7686 - val_loss: 0.4866 - val_accuracy: 0.7593\n",
      "Epoch 427/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4785 - accuracy: 0.7645 - val_loss: 0.4872 - val_accuracy: 0.7606\n",
      "Epoch 428/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.4734 - accuracy: 0.7667 - val_loss: 0.4883 - val_accuracy: 0.7631\n",
      "Epoch 429/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4767 - accuracy: 0.7679 - val_loss: 0.4869 - val_accuracy: 0.7633\n",
      "Epoch 430/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.4752 - accuracy: 0.7669 - val_loss: 0.4830 - val_accuracy: 0.7646\n",
      "Epoch 431/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4758 - accuracy: 0.7690 - val_loss: 0.4962 - val_accuracy: 0.7583\n",
      "Epoch 432/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.4762 - accuracy: 0.7651 - val_loss: 0.4858 - val_accuracy: 0.7592\n",
      "Epoch 433/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4759 - accuracy: 0.7667 - val_loss: 0.4846 - val_accuracy: 0.7639\n",
      "Epoch 434/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4779 - accuracy: 0.7670 - val_loss: 0.4888 - val_accuracy: 0.7646\n",
      "Epoch 435/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.4773 - accuracy: 0.7677 - val_loss: 0.4911 - val_accuracy: 0.7593\n",
      "Epoch 436/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4795 - accuracy: 0.7670 - val_loss: 0.4889 - val_accuracy: 0.7587\n",
      "Epoch 437/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4797 - accuracy: 0.7641 - val_loss: 0.4903 - val_accuracy: 0.7562\n",
      "Epoch 438/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4747 - accuracy: 0.7675 - val_loss: 0.4852 - val_accuracy: 0.7607\n",
      "Epoch 439/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.4765 - accuracy: 0.7665 - val_loss: 0.4876 - val_accuracy: 0.7631\n",
      "Epoch 440/500\n",
      "2878/2878 [==============================] - 2s 750us/step - loss: 0.4766 - accuracy: 0.7672 - val_loss: 0.4869 - val_accuracy: 0.7604\n",
      "Epoch 441/500\n",
      "2878/2878 [==============================] - 2s 759us/step - loss: 0.4732 - accuracy: 0.7708 - val_loss: 0.4836 - val_accuracy: 0.7643\n",
      "Epoch 442/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4733 - accuracy: 0.7698 - val_loss: 0.4868 - val_accuracy: 0.7639\n",
      "Epoch 443/500\n",
      "2878/2878 [==============================] - 3s 874us/step - loss: 0.4749 - accuracy: 0.7689 - val_loss: 0.4837 - val_accuracy: 0.7663\n",
      "Epoch 444/500\n",
      "2878/2878 [==============================] - 3s 898us/step - loss: 0.4756 - accuracy: 0.7676 - val_loss: 0.4892 - val_accuracy: 0.7644\n",
      "Epoch 445/500\n",
      "2878/2878 [==============================] - 2s 801us/step - loss: 0.4763 - accuracy: 0.7647 - val_loss: 0.4887 - val_accuracy: 0.7632\n",
      "Epoch 446/500\n",
      "2878/2878 [==============================] - 2s 789us/step - loss: 0.4730 - accuracy: 0.7697 - val_loss: 0.4852 - val_accuracy: 0.7642\n",
      "Epoch 447/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4762 - accuracy: 0.7680 - val_loss: 0.4874 - val_accuracy: 0.7651\n",
      "Epoch 448/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4762 - accuracy: 0.7672 - val_loss: 0.4883 - val_accuracy: 0.7646\n",
      "Epoch 449/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.4775 - accuracy: 0.7676 - val_loss: 0.4879 - val_accuracy: 0.7626\n",
      "Epoch 450/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4747 - accuracy: 0.7686 - val_loss: 0.4895 - val_accuracy: 0.7620\n",
      "Epoch 451/500\n",
      "2878/2878 [==============================] - 2s 749us/step - loss: 0.4781 - accuracy: 0.7664 - val_loss: 0.4829 - val_accuracy: 0.7674\n",
      "Epoch 452/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.4736 - accuracy: 0.7698 - val_loss: 0.4852 - val_accuracy: 0.7659\n",
      "Epoch 453/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.4754 - accuracy: 0.7669 - val_loss: 0.4825 - val_accuracy: 0.7650\n",
      "Epoch 454/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.4750 - accuracy: 0.7663 - val_loss: 0.4850 - val_accuracy: 0.7640\n",
      "Epoch 455/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.4866 - val_accuracy: 0.7593\n",
      "Epoch 456/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4770 - accuracy: 0.7656 - val_loss: 0.4885 - val_accuracy: 0.7613\n",
      "Epoch 457/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.4771 - accuracy: 0.7666 - val_loss: 0.4835 - val_accuracy: 0.7632\n",
      "Epoch 458/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4741 - accuracy: 0.7681 - val_loss: 0.4882 - val_accuracy: 0.7585\n",
      "Epoch 459/500\n",
      "2878/2878 [==============================] - 2s 760us/step - loss: 0.4766 - accuracy: 0.7667 - val_loss: 0.4848 - val_accuracy: 0.7655\n",
      "Epoch 460/500\n",
      "2878/2878 [==============================] - 2s 749us/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.4852 - val_accuracy: 0.7674\n",
      "Epoch 461/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.4761 - accuracy: 0.7675 - val_loss: 0.4838 - val_accuracy: 0.7660\n",
      "Epoch 462/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.4761 - accuracy: 0.7657 - val_loss: 0.4855 - val_accuracy: 0.7616\n",
      "Epoch 463/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4736 - accuracy: 0.7684 - val_loss: 0.4846 - val_accuracy: 0.7646\n",
      "Epoch 464/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.4765 - accuracy: 0.7676 - val_loss: 0.4943 - val_accuracy: 0.7526\n",
      "Epoch 465/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.4745 - accuracy: 0.7681 - val_loss: 0.4849 - val_accuracy: 0.7659\n",
      "Epoch 466/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.4725 - accuracy: 0.7708 - val_loss: 0.4907 - val_accuracy: 0.7584\n",
      "Epoch 467/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4745 - accuracy: 0.7666 - val_loss: 0.4879 - val_accuracy: 0.7623\n",
      "Epoch 468/500\n",
      "2878/2878 [==============================] - 2s 745us/step - loss: 0.4710 - accuracy: 0.7708 - val_loss: 0.4871 - val_accuracy: 0.7613\n",
      "Epoch 469/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4755 - accuracy: 0.7681 - val_loss: 0.4856 - val_accuracy: 0.7625\n",
      "Epoch 470/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4743 - accuracy: 0.7676 - val_loss: 0.4850 - val_accuracy: 0.7593\n",
      "Epoch 471/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.4722 - accuracy: 0.7693 - val_loss: 0.4861 - val_accuracy: 0.7646\n",
      "Epoch 472/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4750 - accuracy: 0.7680 - val_loss: 0.4871 - val_accuracy: 0.7626\n",
      "Epoch 473/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.4739 - accuracy: 0.7687 - val_loss: 0.4810 - val_accuracy: 0.7676\n",
      "Epoch 474/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4755 - accuracy: 0.7668 - val_loss: 0.4905 - val_accuracy: 0.7595\n",
      "Epoch 475/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.4746 - accuracy: 0.7685 - val_loss: 0.4868 - val_accuracy: 0.7610\n",
      "Epoch 476/500\n",
      "2878/2878 [==============================] - 2s 749us/step - loss: 0.4707 - accuracy: 0.7706 - val_loss: 0.4879 - val_accuracy: 0.7584\n",
      "Epoch 477/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.4761 - accuracy: 0.7668 - val_loss: 0.4858 - val_accuracy: 0.7620\n",
      "Epoch 478/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.4732 - accuracy: 0.7682 - val_loss: 0.4900 - val_accuracy: 0.7640\n",
      "Epoch 479/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4709 - accuracy: 0.7711 - val_loss: 0.4860 - val_accuracy: 0.7666\n",
      "Epoch 480/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4764 - accuracy: 0.7664 - val_loss: 0.4874 - val_accuracy: 0.7646\n",
      "Epoch 481/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4754 - accuracy: 0.7675 - val_loss: 0.4864 - val_accuracy: 0.7587\n",
      "Epoch 482/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4721 - accuracy: 0.7695 - val_loss: 0.4864 - val_accuracy: 0.7669\n",
      "Epoch 483/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4760 - accuracy: 0.7677 - val_loss: 0.4845 - val_accuracy: 0.7648\n",
      "Epoch 484/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.4750 - accuracy: 0.7696 - val_loss: 0.4871 - val_accuracy: 0.7667\n",
      "Epoch 485/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4760 - accuracy: 0.7670 - val_loss: 0.4844 - val_accuracy: 0.7658\n",
      "Epoch 486/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.4736 - accuracy: 0.7704 - val_loss: 0.4865 - val_accuracy: 0.7606\n",
      "Epoch 487/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4740 - accuracy: 0.7689 - val_loss: 0.4841 - val_accuracy: 0.7670\n",
      "Epoch 488/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.4719 - accuracy: 0.7714 - val_loss: 0.4849 - val_accuracy: 0.7644\n",
      "Epoch 489/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.4743 - accuracy: 0.7686 - val_loss: 0.4834 - val_accuracy: 0.7652\n",
      "Epoch 490/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4747 - accuracy: 0.7673 - val_loss: 0.4819 - val_accuracy: 0.7669\n",
      "Epoch 491/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.4717 - accuracy: 0.7693 - val_loss: 0.4879 - val_accuracy: 0.7586\n",
      "Epoch 492/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.4738 - accuracy: 0.7686 - val_loss: 0.4838 - val_accuracy: 0.7643\n",
      "Epoch 493/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.4745 - accuracy: 0.7668 - val_loss: 0.4892 - val_accuracy: 0.7589\n",
      "Epoch 494/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.4754 - accuracy: 0.7675 - val_loss: 0.4859 - val_accuracy: 0.7649\n",
      "Epoch 495/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.4767 - accuracy: 0.7671 - val_loss: 0.4832 - val_accuracy: 0.7673\n",
      "Epoch 496/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.4749 - accuracy: 0.7661 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 497/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.4751 - accuracy: 0.7678 - val_loss: 0.4828 - val_accuracy: 0.7678\n",
      "Epoch 498/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.4739 - accuracy: 0.7687 - val_loss: 0.4899 - val_accuracy: 0.7556\n",
      "Epoch 499/500\n",
      "2878/2878 [==============================] - 2s 742us/step - loss: 0.4703 - accuracy: 0.7709 - val_loss: 0.4815 - val_accuracy: 0.7673\n",
      "Epoch 500/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.4740 - accuracy: 0.7692 - val_loss: 0.4859 - val_accuracy: 0.7631\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(shuffle(pd.DataFrame(x_train_resampled),random_state=1), shuffle(pd.DataFrame(y_train_resampled),random_state=1), epochs=500,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train_resampled)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_12.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 13\n",
    "-MinMax Scaler & Oversampling & Leaky Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.leaky_relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 362\n",
      "Trainable params: 362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2878/2878 [==============================] - 3s 779us/step - loss: 0.6468 - accuracy: 0.6182 - val_loss: 0.6015 - val_accuracy: 0.6713\n",
      "Epoch 2/500\n",
      "2878/2878 [==============================] - 2s 582us/step - loss: 0.5950 - accuracy: 0.6717 - val_loss: 0.5872 - val_accuracy: 0.6863\n",
      "Epoch 3/500\n",
      "2878/2878 [==============================] - 2s 639us/step - loss: 0.5862 - accuracy: 0.6800 - val_loss: 0.5818 - val_accuracy: 0.6879\n",
      "Epoch 4/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5823 - accuracy: 0.6819 - val_loss: 0.5795 - val_accuracy: 0.6867\n",
      "Epoch 5/500\n",
      "2878/2878 [==============================] - 2s 636us/step - loss: 0.5784 - accuracy: 0.6861 - val_loss: 0.5779 - val_accuracy: 0.6878\n",
      "Epoch 6/500\n",
      "2878/2878 [==============================] - 2s 631us/step - loss: 0.5776 - accuracy: 0.6860 - val_loss: 0.5765 - val_accuracy: 0.6898\n",
      "Epoch 7/500\n",
      "2878/2878 [==============================] - 2s 665us/step - loss: 0.5736 - accuracy: 0.6908 - val_loss: 0.5748 - val_accuracy: 0.6929\n",
      "Epoch 8/500\n",
      "2878/2878 [==============================] - 2s 642us/step - loss: 0.5739 - accuracy: 0.6916 - val_loss: 0.5733 - val_accuracy: 0.6949\n",
      "Epoch 9/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5718 - accuracy: 0.6943 - val_loss: 0.5725 - val_accuracy: 0.6957\n",
      "Epoch 10/500\n",
      "2878/2878 [==============================] - 2s 667us/step - loss: 0.5716 - accuracy: 0.6937 - val_loss: 0.5714 - val_accuracy: 0.6945\n",
      "Epoch 11/500\n",
      "2878/2878 [==============================] - 2s 638us/step - loss: 0.5721 - accuracy: 0.6929 - val_loss: 0.5701 - val_accuracy: 0.6968\n",
      "Epoch 12/500\n",
      "2878/2878 [==============================] - 2s 652us/step - loss: 0.5698 - accuracy: 0.6969 - val_loss: 0.5691 - val_accuracy: 0.6996\n",
      "Epoch 13/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.5702 - accuracy: 0.6961 - val_loss: 0.5673 - val_accuracy: 0.7009\n",
      "Epoch 14/500\n",
      "2878/2878 [==============================] - 2s 629us/step - loss: 0.5676 - accuracy: 0.6994 - val_loss: 0.5683 - val_accuracy: 0.7009\n",
      "Epoch 15/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.5663 - accuracy: 0.6991 - val_loss: 0.5647 - val_accuracy: 0.7026\n",
      "Epoch 16/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5655 - accuracy: 0.6997 - val_loss: 0.5628 - val_accuracy: 0.7051\n",
      "Epoch 17/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5660 - accuracy: 0.7012 - val_loss: 0.5610 - val_accuracy: 0.7057\n",
      "Epoch 18/500\n",
      "2878/2878 [==============================] - 2s 688us/step - loss: 0.5628 - accuracy: 0.7017 - val_loss: 0.5639 - val_accuracy: 0.7028\n",
      "Epoch 19/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5603 - accuracy: 0.7048 - val_loss: 0.5584 - val_accuracy: 0.7070\n",
      "Epoch 20/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.5604 - accuracy: 0.7036 - val_loss: 0.5581 - val_accuracy: 0.7077\n",
      "Epoch 21/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5598 - accuracy: 0.7033 - val_loss: 0.5577 - val_accuracy: 0.7073\n",
      "Epoch 22/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5565 - accuracy: 0.7074 - val_loss: 0.5561 - val_accuracy: 0.7050\n",
      "Epoch 23/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5588 - accuracy: 0.7066 - val_loss: 0.5552 - val_accuracy: 0.7069\n",
      "Epoch 24/500\n",
      "2878/2878 [==============================] - 2s 687us/step - loss: 0.5580 - accuracy: 0.7053 - val_loss: 0.5537 - val_accuracy: 0.7090\n",
      "Epoch 25/500\n",
      "2878/2878 [==============================] - 2s 673us/step - loss: 0.5559 - accuracy: 0.7092 - val_loss: 0.5536 - val_accuracy: 0.7096\n",
      "Epoch 26/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5548 - accuracy: 0.7102 - val_loss: 0.5538 - val_accuracy: 0.7112\n",
      "Epoch 27/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5555 - accuracy: 0.7084 - val_loss: 0.5531 - val_accuracy: 0.7132\n",
      "Epoch 28/500\n",
      "2878/2878 [==============================] - 2s 671us/step - loss: 0.5544 - accuracy: 0.7093 - val_loss: 0.5540 - val_accuracy: 0.7114\n",
      "Epoch 29/500\n",
      "2878/2878 [==============================] - 2s 634us/step - loss: 0.5528 - accuracy: 0.7111 - val_loss: 0.5534 - val_accuracy: 0.7112\n",
      "Epoch 30/500\n",
      "2878/2878 [==============================] - 2s 632us/step - loss: 0.5544 - accuracy: 0.7077 - val_loss: 0.5531 - val_accuracy: 0.7093\n",
      "Epoch 31/500\n",
      "2878/2878 [==============================] - 2s 648us/step - loss: 0.5527 - accuracy: 0.7109 - val_loss: 0.5512 - val_accuracy: 0.7134\n",
      "Epoch 32/500\n",
      "2878/2878 [==============================] - 2s 624us/step - loss: 0.5519 - accuracy: 0.7117 - val_loss: 0.5507 - val_accuracy: 0.7126\n",
      "Epoch 33/500\n",
      "2878/2878 [==============================] - 2s 645us/step - loss: 0.5528 - accuracy: 0.7107 - val_loss: 0.5543 - val_accuracy: 0.7107\n",
      "Epoch 34/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5500 - accuracy: 0.7139 - val_loss: 0.5562 - val_accuracy: 0.7080\n",
      "Epoch 35/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5534 - accuracy: 0.7114 - val_loss: 0.5522 - val_accuracy: 0.7120\n",
      "Epoch 36/500\n",
      "2878/2878 [==============================] - 2s 649us/step - loss: 0.5492 - accuracy: 0.7161 - val_loss: 0.5494 - val_accuracy: 0.7133\n",
      "Epoch 37/500\n",
      "2878/2878 [==============================] - 2s 628us/step - loss: 0.5520 - accuracy: 0.7133 - val_loss: 0.5513 - val_accuracy: 0.7107\n",
      "Epoch 38/500\n",
      "2878/2878 [==============================] - 2s 629us/step - loss: 0.5495 - accuracy: 0.7156 - val_loss: 0.5528 - val_accuracy: 0.7103\n",
      "Epoch 39/500\n",
      "2878/2878 [==============================] - 2s 656us/step - loss: 0.5505 - accuracy: 0.7145 - val_loss: 0.5476 - val_accuracy: 0.7164\n",
      "Epoch 40/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5501 - accuracy: 0.7152 - val_loss: 0.5505 - val_accuracy: 0.7114\n",
      "Epoch 41/500\n",
      "2878/2878 [==============================] - 2s 620us/step - loss: 0.5493 - accuracy: 0.7167 - val_loss: 0.5464 - val_accuracy: 0.7168\n",
      "Epoch 42/500\n",
      "2878/2878 [==============================] - 2s 621us/step - loss: 0.5475 - accuracy: 0.7155 - val_loss: 0.5484 - val_accuracy: 0.7146\n",
      "Epoch 43/500\n",
      "2878/2878 [==============================] - 2s 627us/step - loss: 0.5496 - accuracy: 0.7155 - val_loss: 0.5476 - val_accuracy: 0.7172\n",
      "Epoch 44/500\n",
      "2878/2878 [==============================] - 2s 632us/step - loss: 0.5500 - accuracy: 0.7133 - val_loss: 0.5484 - val_accuracy: 0.7152\n",
      "Epoch 45/500\n",
      "2878/2878 [==============================] - 2s 645us/step - loss: 0.5488 - accuracy: 0.7151 - val_loss: 0.5475 - val_accuracy: 0.7169\n",
      "Epoch 46/500\n",
      "2878/2878 [==============================] - 2s 629us/step - loss: 0.5469 - accuracy: 0.7183 - val_loss: 0.5489 - val_accuracy: 0.7155\n",
      "Epoch 47/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.5480 - accuracy: 0.7179 - val_loss: 0.5478 - val_accuracy: 0.7159\n",
      "Epoch 48/500\n",
      "2878/2878 [==============================] - 2s 656us/step - loss: 0.5462 - accuracy: 0.7173 - val_loss: 0.5484 - val_accuracy: 0.7174\n",
      "Epoch 49/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.5475 - accuracy: 0.7180 - val_loss: 0.5462 - val_accuracy: 0.7188\n",
      "Epoch 50/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.5475 - accuracy: 0.7163 - val_loss: 0.5444 - val_accuracy: 0.7197\n",
      "Epoch 51/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.5480 - accuracy: 0.7159 - val_loss: 0.5463 - val_accuracy: 0.7170\n",
      "Epoch 52/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5459 - accuracy: 0.7193 - val_loss: 0.5461 - val_accuracy: 0.7189\n",
      "Epoch 53/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.5485 - accuracy: 0.7178 - val_loss: 0.5459 - val_accuracy: 0.7185\n",
      "Epoch 54/500\n",
      "2878/2878 [==============================] - 2s 802us/step - loss: 0.5469 - accuracy: 0.7192 - val_loss: 0.5437 - val_accuracy: 0.7209\n",
      "Epoch 55/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.5463 - accuracy: 0.7183 - val_loss: 0.5447 - val_accuracy: 0.7209\n",
      "Epoch 56/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5468 - accuracy: 0.7193 - val_loss: 0.5460 - val_accuracy: 0.7192\n",
      "Epoch 57/500\n",
      "2878/2878 [==============================] - 2s 666us/step - loss: 0.5451 - accuracy: 0.7190 - val_loss: 0.5447 - val_accuracy: 0.7212\n",
      "Epoch 58/500\n",
      "2878/2878 [==============================] - 2s 674us/step - loss: 0.5473 - accuracy: 0.7181 - val_loss: 0.5436 - val_accuracy: 0.7206\n",
      "Epoch 59/500\n",
      "2878/2878 [==============================] - 2s 662us/step - loss: 0.5449 - accuracy: 0.7196 - val_loss: 0.5444 - val_accuracy: 0.7189\n",
      "Epoch 60/500\n",
      "2878/2878 [==============================] - 2s 645us/step - loss: 0.5462 - accuracy: 0.7198 - val_loss: 0.5460 - val_accuracy: 0.7196\n",
      "Epoch 61/500\n",
      "2878/2878 [==============================] - 2s 648us/step - loss: 0.5441 - accuracy: 0.7217 - val_loss: 0.5435 - val_accuracy: 0.7207\n",
      "Epoch 62/500\n",
      "2878/2878 [==============================] - 2s 641us/step - loss: 0.5449 - accuracy: 0.7217 - val_loss: 0.5448 - val_accuracy: 0.7196\n",
      "Epoch 63/500\n",
      "2878/2878 [==============================] - 2s 623us/step - loss: 0.5450 - accuracy: 0.7205 - val_loss: 0.5431 - val_accuracy: 0.7201\n",
      "Epoch 64/500\n",
      "2878/2878 [==============================] - 2s 624us/step - loss: 0.5438 - accuracy: 0.7221 - val_loss: 0.5442 - val_accuracy: 0.7199\n",
      "Epoch 65/500\n",
      "2878/2878 [==============================] - 2s 629us/step - loss: 0.5452 - accuracy: 0.7203 - val_loss: 0.5454 - val_accuracy: 0.7173\n",
      "Epoch 66/500\n",
      "2878/2878 [==============================] - 2s 627us/step - loss: 0.5458 - accuracy: 0.7181 - val_loss: 0.5450 - val_accuracy: 0.7200\n",
      "Epoch 67/500\n",
      "2878/2878 [==============================] - 2s 638us/step - loss: 0.5424 - accuracy: 0.7227 - val_loss: 0.5429 - val_accuracy: 0.7202\n",
      "Epoch 68/500\n",
      "2878/2878 [==============================] - 2s 646us/step - loss: 0.5442 - accuracy: 0.7214 - val_loss: 0.5440 - val_accuracy: 0.7209\n",
      "Epoch 69/500\n",
      "2878/2878 [==============================] - 2s 653us/step - loss: 0.5423 - accuracy: 0.7230 - val_loss: 0.5445 - val_accuracy: 0.7206\n",
      "Epoch 70/500\n",
      "2878/2878 [==============================] - 2s 650us/step - loss: 0.5435 - accuracy: 0.7193 - val_loss: 0.5429 - val_accuracy: 0.7214\n",
      "Epoch 71/500\n",
      "2878/2878 [==============================] - 2s 646us/step - loss: 0.5465 - accuracy: 0.7196 - val_loss: 0.5425 - val_accuracy: 0.7207\n",
      "Epoch 72/500\n",
      "2878/2878 [==============================] - 2s 646us/step - loss: 0.5424 - accuracy: 0.7234 - val_loss: 0.5418 - val_accuracy: 0.7203\n",
      "Epoch 73/500\n",
      "2878/2878 [==============================] - 2s 649us/step - loss: 0.5442 - accuracy: 0.7201 - val_loss: 0.5441 - val_accuracy: 0.7200\n",
      "Epoch 74/500\n",
      "2878/2878 [==============================] - 2s 645us/step - loss: 0.5427 - accuracy: 0.7229 - val_loss: 0.5422 - val_accuracy: 0.7225\n",
      "Epoch 75/500\n",
      "2878/2878 [==============================] - 2s 646us/step - loss: 0.5420 - accuracy: 0.7228 - val_loss: 0.5448 - val_accuracy: 0.7163\n",
      "Epoch 76/500\n",
      "2878/2878 [==============================] - 2s 647us/step - loss: 0.5437 - accuracy: 0.7214 - val_loss: 0.5411 - val_accuracy: 0.7232\n",
      "Epoch 77/500\n",
      "2878/2878 [==============================] - 2s 650us/step - loss: 0.5427 - accuracy: 0.7211 - val_loss: 0.5414 - val_accuracy: 0.7228\n",
      "Epoch 78/500\n",
      "2878/2878 [==============================] - 2s 645us/step - loss: 0.5427 - accuracy: 0.7221 - val_loss: 0.5414 - val_accuracy: 0.7219\n",
      "Epoch 79/500\n",
      "2878/2878 [==============================] - 2s 644us/step - loss: 0.5426 - accuracy: 0.7205 - val_loss: 0.5416 - val_accuracy: 0.7246\n",
      "Epoch 80/500\n",
      "2878/2878 [==============================] - 2s 662us/step - loss: 0.5442 - accuracy: 0.7195 - val_loss: 0.5460 - val_accuracy: 0.7189\n",
      "Epoch 81/500\n",
      "2878/2878 [==============================] - 2s 648us/step - loss: 0.5423 - accuracy: 0.7225 - val_loss: 0.5404 - val_accuracy: 0.7244\n",
      "Epoch 82/500\n",
      "2878/2878 [==============================] - 2s 654us/step - loss: 0.5416 - accuracy: 0.7226 - val_loss: 0.5433 - val_accuracy: 0.7216\n",
      "Epoch 83/500\n",
      "2878/2878 [==============================] - 2s 670us/step - loss: 0.5426 - accuracy: 0.7212 - val_loss: 0.5463 - val_accuracy: 0.7205\n",
      "Epoch 84/500\n",
      "2878/2878 [==============================] - 2s 651us/step - loss: 0.5433 - accuracy: 0.7219 - val_loss: 0.5414 - val_accuracy: 0.7228\n",
      "Epoch 85/500\n",
      "2878/2878 [==============================] - 2s 653us/step - loss: 0.5406 - accuracy: 0.7242 - val_loss: 0.5426 - val_accuracy: 0.7194\n",
      "Epoch 86/500\n",
      "2878/2878 [==============================] - 2s 656us/step - loss: 0.5452 - accuracy: 0.7207 - val_loss: 0.5411 - val_accuracy: 0.7191\n",
      "Epoch 87/500\n",
      "2878/2878 [==============================] - 2s 650us/step - loss: 0.5426 - accuracy: 0.7222 - val_loss: 0.5406 - val_accuracy: 0.7234\n",
      "Epoch 88/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5439 - accuracy: 0.7221 - val_loss: 0.5423 - val_accuracy: 0.7205\n",
      "Epoch 89/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5411 - accuracy: 0.7246 - val_loss: 0.5439 - val_accuracy: 0.7202\n",
      "Epoch 90/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5423 - accuracy: 0.7223 - val_loss: 0.5409 - val_accuracy: 0.7215\n",
      "Epoch 91/500\n",
      "2878/2878 [==============================] - 2s 659us/step - loss: 0.5435 - accuracy: 0.7195 - val_loss: 0.5418 - val_accuracy: 0.7209\n",
      "Epoch 92/500\n",
      "2878/2878 [==============================] - 2s 649us/step - loss: 0.5405 - accuracy: 0.7237 - val_loss: 0.5399 - val_accuracy: 0.7243\n",
      "Epoch 93/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5445 - accuracy: 0.7199 - val_loss: 0.5399 - val_accuracy: 0.7235\n",
      "Epoch 94/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.5429 - accuracy: 0.7210 - val_loss: 0.5398 - val_accuracy: 0.7240\n",
      "Epoch 95/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5381 - accuracy: 0.7258 - val_loss: 0.5397 - val_accuracy: 0.7238\n",
      "Epoch 96/500\n",
      "2878/2878 [==============================] - 2s 759us/step - loss: 0.5407 - accuracy: 0.7224 - val_loss: 0.5404 - val_accuracy: 0.7219\n",
      "Epoch 97/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5405 - accuracy: 0.7227 - val_loss: 0.5403 - val_accuracy: 0.7224\n",
      "Epoch 98/500\n",
      "2878/2878 [==============================] - 2s 746us/step - loss: 0.5412 - accuracy: 0.7222 - val_loss: 0.5498 - val_accuracy: 0.7167\n",
      "Epoch 99/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5418 - accuracy: 0.7221 - val_loss: 0.5471 - val_accuracy: 0.7159\n",
      "Epoch 100/500\n",
      "2878/2878 [==============================] - 2s 750us/step - loss: 0.5397 - accuracy: 0.7243 - val_loss: 0.5432 - val_accuracy: 0.7181\n",
      "Epoch 101/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.5409 - accuracy: 0.7243 - val_loss: 0.5396 - val_accuracy: 0.7240\n",
      "Epoch 102/500\n",
      "2878/2878 [==============================] - 2s 738us/step - loss: 0.5411 - accuracy: 0.7234 - val_loss: 0.5398 - val_accuracy: 0.7216\n",
      "Epoch 103/500\n",
      "2878/2878 [==============================] - 2s 672us/step - loss: 0.5418 - accuracy: 0.7228 - val_loss: 0.5383 - val_accuracy: 0.7258\n",
      "Epoch 104/500\n",
      "2878/2878 [==============================] - 3s 871us/step - loss: 0.5418 - accuracy: 0.7234 - val_loss: 0.5397 - val_accuracy: 0.7236\n",
      "Epoch 105/500\n",
      "2878/2878 [==============================] - 3s 876us/step - loss: 0.5410 - accuracy: 0.7258 - val_loss: 0.5428 - val_accuracy: 0.7208\n",
      "Epoch 106/500\n",
      "2878/2878 [==============================] - 3s 935us/step - loss: 0.5420 - accuracy: 0.7225 - val_loss: 0.5390 - val_accuracy: 0.7233\n",
      "Epoch 107/500\n",
      "2878/2878 [==============================] - 2s 792us/step - loss: 0.5382 - accuracy: 0.7269 - val_loss: 0.5391 - val_accuracy: 0.7245\n",
      "Epoch 108/500\n",
      "2878/2878 [==============================] - 3s 944us/step - loss: 0.5407 - accuracy: 0.7239 - val_loss: 0.5386 - val_accuracy: 0.7260\n",
      "Epoch 109/500\n",
      "2878/2878 [==============================] - 2s 864us/step - loss: 0.5395 - accuracy: 0.7239 - val_loss: 0.5381 - val_accuracy: 0.7254\n",
      "Epoch 110/500\n",
      "2878/2878 [==============================] - 2s 810us/step - loss: 0.5396 - accuracy: 0.7271 - val_loss: 0.5521 - val_accuracy: 0.7156\n",
      "Epoch 111/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.5417 - accuracy: 0.7241 - val_loss: 0.5387 - val_accuracy: 0.7232\n",
      "Epoch 112/500\n",
      "2878/2878 [==============================] - 2s 772us/step - loss: 0.5396 - accuracy: 0.7255 - val_loss: 0.5393 - val_accuracy: 0.7253\n",
      "Epoch 113/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.5411 - accuracy: 0.7238 - val_loss: 0.5382 - val_accuracy: 0.7233\n",
      "Epoch 114/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.5389 - accuracy: 0.7245 - val_loss: 0.5449 - val_accuracy: 0.7204\n",
      "Epoch 115/500\n",
      "2878/2878 [==============================] - 2s 855us/step - loss: 0.5424 - accuracy: 0.7248 - val_loss: 0.5404 - val_accuracy: 0.7215\n",
      "Epoch 116/500\n",
      "2878/2878 [==============================] - 2s 838us/step - loss: 0.5413 - accuracy: 0.7231 - val_loss: 0.5387 - val_accuracy: 0.7244\n",
      "Epoch 117/500\n",
      "2878/2878 [==============================] - 2s 830us/step - loss: 0.5387 - accuracy: 0.7258 - val_loss: 0.5385 - val_accuracy: 0.7262\n",
      "Epoch 118/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.5411 - accuracy: 0.7240 - val_loss: 0.5398 - val_accuracy: 0.7230\n",
      "Epoch 119/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5387 - accuracy: 0.7253 - val_loss: 0.5400 - val_accuracy: 0.7219\n",
      "Epoch 120/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5402 - accuracy: 0.7250 - val_loss: 0.5378 - val_accuracy: 0.7251\n",
      "Epoch 121/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5360 - accuracy: 0.7260 - val_loss: 0.5393 - val_accuracy: 0.7234\n",
      "Epoch 122/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5389 - accuracy: 0.7263 - val_loss: 0.5414 - val_accuracy: 0.7190\n",
      "Epoch 123/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5380 - accuracy: 0.7270 - val_loss: 0.5379 - val_accuracy: 0.7231\n",
      "Epoch 124/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5416 - accuracy: 0.7240 - val_loss: 0.5386 - val_accuracy: 0.7257\n",
      "Epoch 125/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5398 - accuracy: 0.7247 - val_loss: 0.5384 - val_accuracy: 0.7229\n",
      "Epoch 126/500\n",
      "2878/2878 [==============================] - 2s 659us/step - loss: 0.5411 - accuracy: 0.7225 - val_loss: 0.5400 - val_accuracy: 0.7234\n",
      "Epoch 127/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5374 - accuracy: 0.7262 - val_loss: 0.5373 - val_accuracy: 0.7247\n",
      "Epoch 128/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5391 - accuracy: 0.7251 - val_loss: 0.5471 - val_accuracy: 0.7181\n",
      "Epoch 129/500\n",
      "2878/2878 [==============================] - 3s 882us/step - loss: 0.5438 - accuracy: 0.7218 - val_loss: 0.5386 - val_accuracy: 0.7260\n",
      "Epoch 130/500\n",
      "2878/2878 [==============================] - 2s 818us/step - loss: 0.5418 - accuracy: 0.7240 - val_loss: 0.5371 - val_accuracy: 0.7238\n",
      "Epoch 131/500\n",
      "2878/2878 [==============================] - 3s 925us/step - loss: 0.5406 - accuracy: 0.7252 - val_loss: 0.5419 - val_accuracy: 0.7206\n",
      "Epoch 132/500\n",
      "2878/2878 [==============================] - 2s 774us/step - loss: 0.5372 - accuracy: 0.7257 - val_loss: 0.5376 - val_accuracy: 0.7253\n",
      "Epoch 133/500\n",
      "2878/2878 [==============================] - 2s 814us/step - loss: 0.5389 - accuracy: 0.7229 - val_loss: 0.5388 - val_accuracy: 0.7269\n",
      "Epoch 134/500\n",
      "2878/2878 [==============================] - 3s 926us/step - loss: 0.5391 - accuracy: 0.7252 - val_loss: 0.5374 - val_accuracy: 0.7250\n",
      "Epoch 135/500\n",
      "2878/2878 [==============================] - 2s 794us/step - loss: 0.5370 - accuracy: 0.7258 - val_loss: 0.5447 - val_accuracy: 0.7189\n",
      "Epoch 136/500\n",
      "2878/2878 [==============================] - 2s 847us/step - loss: 0.5382 - accuracy: 0.7257 - val_loss: 0.5369 - val_accuracy: 0.7245\n",
      "Epoch 137/500\n",
      "2878/2878 [==============================] - 2s 745us/step - loss: 0.5381 - accuracy: 0.7259 - val_loss: 0.5374 - val_accuracy: 0.7239\n",
      "Epoch 138/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.5382 - accuracy: 0.7264 - val_loss: 0.5443 - val_accuracy: 0.7204\n",
      "Epoch 139/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.5413 - accuracy: 0.7230 - val_loss: 0.5363 - val_accuracy: 0.7287\n",
      "Epoch 140/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5393 - accuracy: 0.7239 - val_loss: 0.5385 - val_accuracy: 0.7260\n",
      "Epoch 141/500\n",
      "2878/2878 [==============================] - 2s 677us/step - loss: 0.5344 - accuracy: 0.7300 - val_loss: 0.5374 - val_accuracy: 0.7256\n",
      "Epoch 142/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5382 - accuracy: 0.7246 - val_loss: 0.5388 - val_accuracy: 0.7239\n",
      "Epoch 143/500\n",
      "2878/2878 [==============================] - 2s 783us/step - loss: 0.5377 - accuracy: 0.7268 - val_loss: 0.5400 - val_accuracy: 0.7233\n",
      "Epoch 144/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.5392 - accuracy: 0.7250 - val_loss: 0.5358 - val_accuracy: 0.7274\n",
      "Epoch 145/500\n",
      "2878/2878 [==============================] - 2s 753us/step - loss: 0.5367 - accuracy: 0.7268 - val_loss: 0.5399 - val_accuracy: 0.7245\n",
      "Epoch 146/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5406 - accuracy: 0.7244 - val_loss: 0.5394 - val_accuracy: 0.7219\n",
      "Epoch 147/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.5381 - accuracy: 0.7249 - val_loss: 0.5373 - val_accuracy: 0.7265\n",
      "Epoch 148/500\n",
      "2878/2878 [==============================] - 2s 681us/step - loss: 0.5396 - accuracy: 0.7252 - val_loss: 0.5362 - val_accuracy: 0.7267\n",
      "Epoch 149/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5364 - accuracy: 0.7270 - val_loss: 0.5381 - val_accuracy: 0.7249\n",
      "Epoch 150/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5389 - accuracy: 0.7244 - val_loss: 0.5391 - val_accuracy: 0.7244\n",
      "Epoch 151/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.5387 - accuracy: 0.7248 - val_loss: 0.5382 - val_accuracy: 0.7234\n",
      "Epoch 152/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.5340 - accuracy: 0.7304 - val_loss: 0.5357 - val_accuracy: 0.7280\n",
      "Epoch 153/500\n",
      "2878/2878 [==============================] - 2s 676us/step - loss: 0.5370 - accuracy: 0.7258 - val_loss: 0.5380 - val_accuracy: 0.7247\n",
      "Epoch 154/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5382 - accuracy: 0.7238 - val_loss: 0.5385 - val_accuracy: 0.7226\n",
      "Epoch 155/500\n",
      "2878/2878 [==============================] - 2s 753us/step - loss: 0.5392 - accuracy: 0.7265 - val_loss: 0.5370 - val_accuracy: 0.7287\n",
      "Epoch 156/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5386 - accuracy: 0.7269 - val_loss: 0.5357 - val_accuracy: 0.7276\n",
      "Epoch 157/500\n",
      "2878/2878 [==============================] - 2s 793us/step - loss: 0.5395 - accuracy: 0.7254 - val_loss: 0.5389 - val_accuracy: 0.7239\n",
      "Epoch 158/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5392 - accuracy: 0.7252 - val_loss: 0.5406 - val_accuracy: 0.7203\n",
      "Epoch 159/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.5378 - accuracy: 0.7254 - val_loss: 0.5364 - val_accuracy: 0.7281\n",
      "Epoch 160/500\n",
      "2878/2878 [==============================] - 2s 796us/step - loss: 0.5370 - accuracy: 0.7259 - val_loss: 0.5375 - val_accuracy: 0.7246\n",
      "Epoch 161/500\n",
      "2878/2878 [==============================] - 3s 920us/step - loss: 0.5378 - accuracy: 0.7258 - val_loss: 0.5361 - val_accuracy: 0.7271\n",
      "Epoch 162/500\n",
      "2878/2878 [==============================] - 2s 860us/step - loss: 0.5384 - accuracy: 0.7261 - val_loss: 0.5371 - val_accuracy: 0.7255\n",
      "Epoch 163/500\n",
      "2878/2878 [==============================] - 3s 887us/step - loss: 0.5381 - accuracy: 0.7239 - val_loss: 0.5392 - val_accuracy: 0.7243\n",
      "Epoch 164/500\n",
      "2878/2878 [==============================] - 3s 881us/step - loss: 0.5342 - accuracy: 0.7292 - val_loss: 0.5375 - val_accuracy: 0.7271\n",
      "Epoch 165/500\n",
      "2878/2878 [==============================] - 2s 768us/step - loss: 0.5382 - accuracy: 0.7261 - val_loss: 0.5370 - val_accuracy: 0.7240\n",
      "Epoch 166/500\n",
      "2878/2878 [==============================] - 2s 800us/step - loss: 0.5370 - accuracy: 0.7246 - val_loss: 0.5369 - val_accuracy: 0.7242\n",
      "Epoch 167/500\n",
      "2878/2878 [==============================] - 2s 812us/step - loss: 0.5348 - accuracy: 0.7290 - val_loss: 0.5360 - val_accuracy: 0.7271\n",
      "Epoch 168/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5338 - accuracy: 0.7298 - val_loss: 0.5372 - val_accuracy: 0.7245\n",
      "Epoch 169/500\n",
      "2878/2878 [==============================] - 2s 675us/step - loss: 0.5408 - accuracy: 0.7230 - val_loss: 0.5364 - val_accuracy: 0.7260\n",
      "Epoch 170/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.5385 - accuracy: 0.7243 - val_loss: 0.5368 - val_accuracy: 0.7252\n",
      "Epoch 171/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5353 - accuracy: 0.7257 - val_loss: 0.5350 - val_accuracy: 0.7267\n",
      "Epoch 172/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.5371 - accuracy: 0.7265 - val_loss: 0.5353 - val_accuracy: 0.7297\n",
      "Epoch 173/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5368 - accuracy: 0.7288 - val_loss: 0.5397 - val_accuracy: 0.7244\n",
      "Epoch 174/500\n",
      "2878/2878 [==============================] - 2s 753us/step - loss: 0.5363 - accuracy: 0.7280 - val_loss: 0.5364 - val_accuracy: 0.7237\n",
      "Epoch 175/500\n",
      "2878/2878 [==============================] - 2s 835us/step - loss: 0.5361 - accuracy: 0.7277 - val_loss: 0.5384 - val_accuracy: 0.7253\n",
      "Epoch 176/500\n",
      "2878/2878 [==============================] - 2s 770us/step - loss: 0.5376 - accuracy: 0.7251 - val_loss: 0.5369 - val_accuracy: 0.7253\n",
      "Epoch 177/500\n",
      "2878/2878 [==============================] - 2s 821us/step - loss: 0.5386 - accuracy: 0.7248 - val_loss: 0.5357 - val_accuracy: 0.7267\n",
      "Epoch 178/500\n",
      "2878/2878 [==============================] - 2s 765us/step - loss: 0.5380 - accuracy: 0.7262 - val_loss: 0.5362 - val_accuracy: 0.7261\n",
      "Epoch 179/500\n",
      "2878/2878 [==============================] - 2s 762us/step - loss: 0.5373 - accuracy: 0.7267 - val_loss: 0.5363 - val_accuracy: 0.7268\n",
      "Epoch 180/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.5361 - accuracy: 0.7259 - val_loss: 0.5444 - val_accuracy: 0.7215\n",
      "Epoch 181/500\n",
      "2878/2878 [==============================] - 3s 954us/step - loss: 0.5344 - accuracy: 0.7275 - val_loss: 0.5448 - val_accuracy: 0.7170\n",
      "Epoch 182/500\n",
      "2878/2878 [==============================] - 3s 932us/step - loss: 0.5378 - accuracy: 0.7269 - val_loss: 0.5455 - val_accuracy: 0.7205\n",
      "Epoch 183/500\n",
      "2878/2878 [==============================] - 3s 978us/step - loss: 0.5367 - accuracy: 0.7271 - val_loss: 0.5357 - val_accuracy: 0.7277\n",
      "Epoch 184/500\n",
      "2878/2878 [==============================] - 3s 950us/step - loss: 0.5372 - accuracy: 0.7249 - val_loss: 0.5404 - val_accuracy: 0.7224\n",
      "Epoch 185/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.5387 - accuracy: 0.7256 - val_loss: 0.5372 - val_accuracy: 0.7280\n",
      "Epoch 186/500\n",
      "2878/2878 [==============================] - 2s 794us/step - loss: 0.5374 - accuracy: 0.7267 - val_loss: 0.5364 - val_accuracy: 0.7255\n",
      "Epoch 187/500\n",
      "2878/2878 [==============================] - 2s 807us/step - loss: 0.5355 - accuracy: 0.7280 - val_loss: 0.5363 - val_accuracy: 0.7251\n",
      "Epoch 188/500\n",
      "2878/2878 [==============================] - 2s 749us/step - loss: 0.5373 - accuracy: 0.7260 - val_loss: 0.5426 - val_accuracy: 0.7202\n",
      "Epoch 189/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5369 - accuracy: 0.7242 - val_loss: 0.5378 - val_accuracy: 0.7268\n",
      "Epoch 190/500\n",
      "2878/2878 [==============================] - 2s 747us/step - loss: 0.5340 - accuracy: 0.7275 - val_loss: 0.5403 - val_accuracy: 0.7223\n",
      "Epoch 191/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.5339 - accuracy: 0.7291 - val_loss: 0.5361 - val_accuracy: 0.7243\n",
      "Epoch 192/500\n",
      "2878/2878 [==============================] - 2s 772us/step - loss: 0.5375 - accuracy: 0.7266 - val_loss: 0.5361 - val_accuracy: 0.7268\n",
      "Epoch 193/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5345 - accuracy: 0.7286 - val_loss: 0.5442 - val_accuracy: 0.7206\n",
      "Epoch 194/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5377 - accuracy: 0.7260 - val_loss: 0.5368 - val_accuracy: 0.7282\n",
      "Epoch 195/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.5352 - accuracy: 0.7288 - val_loss: 0.5354 - val_accuracy: 0.7270\n",
      "Epoch 196/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5369 - accuracy: 0.7271 - val_loss: 0.5461 - val_accuracy: 0.7165\n",
      "Epoch 197/500\n",
      "2878/2878 [==============================] - 2s 774us/step - loss: 0.5353 - accuracy: 0.7274 - val_loss: 0.5350 - val_accuracy: 0.7299\n",
      "Epoch 198/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.5365 - accuracy: 0.7272 - val_loss: 0.5382 - val_accuracy: 0.7286\n",
      "Epoch 199/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.5389 - accuracy: 0.7250 - val_loss: 0.5344 - val_accuracy: 0.7282\n",
      "Epoch 200/500\n",
      "2878/2878 [==============================] - 3s 869us/step - loss: 0.5359 - accuracy: 0.7265 - val_loss: 0.5373 - val_accuracy: 0.7264\n",
      "Epoch 201/500\n",
      "2878/2878 [==============================] - 2s 749us/step - loss: 0.5355 - accuracy: 0.7269 - val_loss: 0.5396 - val_accuracy: 0.7234\n",
      "Epoch 202/500\n",
      "2878/2878 [==============================] - 2s 747us/step - loss: 0.5369 - accuracy: 0.7280 - val_loss: 0.5440 - val_accuracy: 0.7198\n",
      "Epoch 203/500\n",
      "2878/2878 [==============================] - 2s 761us/step - loss: 0.5355 - accuracy: 0.7260 - val_loss: 0.5386 - val_accuracy: 0.7260\n",
      "Epoch 204/500\n",
      "2878/2878 [==============================] - 2s 776us/step - loss: 0.5338 - accuracy: 0.7294 - val_loss: 0.5365 - val_accuracy: 0.7271\n",
      "Epoch 205/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.5348 - accuracy: 0.7281 - val_loss: 0.5413 - val_accuracy: 0.7230\n",
      "Epoch 206/500\n",
      "2878/2878 [==============================] - 4s 1ms/step - loss: 0.5376 - accuracy: 0.7254 - val_loss: 0.5363 - val_accuracy: 0.7269\n",
      "Epoch 207/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.5366 - accuracy: 0.7253 - val_loss: 0.5390 - val_accuracy: 0.7252\n",
      "Epoch 208/500\n",
      "2878/2878 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7297 - val_loss: 0.5402 - val_accuracy: 0.7244\n",
      "Epoch 209/500\n",
      "2878/2878 [==============================] - 3s 887us/step - loss: 0.5354 - accuracy: 0.7284 - val_loss: 0.5380 - val_accuracy: 0.7268\n",
      "Epoch 210/500\n",
      "2878/2878 [==============================] - 2s 837us/step - loss: 0.5359 - accuracy: 0.7272 - val_loss: 0.5338 - val_accuracy: 0.7285\n",
      "Epoch 211/500\n",
      "2878/2878 [==============================] - 2s 763us/step - loss: 0.5344 - accuracy: 0.7282 - val_loss: 0.5367 - val_accuracy: 0.7295\n",
      "Epoch 212/500\n",
      "2878/2878 [==============================] - 2s 780us/step - loss: 0.5334 - accuracy: 0.7290 - val_loss: 0.5339 - val_accuracy: 0.7298\n",
      "Epoch 213/500\n",
      "2878/2878 [==============================] - 2s 823us/step - loss: 0.5343 - accuracy: 0.7286 - val_loss: 0.5380 - val_accuracy: 0.7278\n",
      "Epoch 214/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.5354 - accuracy: 0.7283 - val_loss: 0.5450 - val_accuracy: 0.7175\n",
      "Epoch 215/500\n",
      "2878/2878 [==============================] - 3s 893us/step - loss: 0.5347 - accuracy: 0.7277 - val_loss: 0.5352 - val_accuracy: 0.7288\n",
      "Epoch 216/500\n",
      "2878/2878 [==============================] - 3s 879us/step - loss: 0.5353 - accuracy: 0.7270 - val_loss: 0.5376 - val_accuracy: 0.7232\n",
      "Epoch 217/500\n",
      "2878/2878 [==============================] - 2s 772us/step - loss: 0.5335 - accuracy: 0.7289 - val_loss: 0.5342 - val_accuracy: 0.7270\n",
      "Epoch 218/500\n",
      "2878/2878 [==============================] - 2s 752us/step - loss: 0.5369 - accuracy: 0.7261 - val_loss: 0.5337 - val_accuracy: 0.7276\n",
      "Epoch 219/500\n",
      "2878/2878 [==============================] - 2s 819us/step - loss: 0.5361 - accuracy: 0.7263 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 220/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5339 - accuracy: 0.7271 - val_loss: 0.5398 - val_accuracy: 0.7220\n",
      "Epoch 221/500\n",
      "2878/2878 [==============================] - 2s 680us/step - loss: 0.5351 - accuracy: 0.7270 - val_loss: 0.5386 - val_accuracy: 0.7255\n",
      "Epoch 222/500\n",
      "2878/2878 [==============================] - 2s 670us/step - loss: 0.5372 - accuracy: 0.7253 - val_loss: 0.5385 - val_accuracy: 0.7278\n",
      "Epoch 223/500\n",
      "2878/2878 [==============================] - 2s 684us/step - loss: 0.5352 - accuracy: 0.7265 - val_loss: 0.5373 - val_accuracy: 0.7261\n",
      "Epoch 224/500\n",
      "2878/2878 [==============================] - 2s 678us/step - loss: 0.5355 - accuracy: 0.7281 - val_loss: 0.5422 - val_accuracy: 0.7186\n",
      "Epoch 225/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.5389 - accuracy: 0.7249 - val_loss: 0.5353 - val_accuracy: 0.7284\n",
      "Epoch 226/500\n",
      "2878/2878 [==============================] - 2s 837us/step - loss: 0.5336 - accuracy: 0.7298 - val_loss: 0.5361 - val_accuracy: 0.7285\n",
      "Epoch 227/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.5351 - accuracy: 0.7271 - val_loss: 0.5365 - val_accuracy: 0.7258\n",
      "Epoch 228/500\n",
      "2878/2878 [==============================] - 2s 807us/step - loss: 0.5345 - accuracy: 0.7292 - val_loss: 0.5377 - val_accuracy: 0.7263\n",
      "Epoch 229/500\n",
      "2878/2878 [==============================] - 2s 845us/step - loss: 0.5334 - accuracy: 0.7295 - val_loss: 0.5482 - val_accuracy: 0.7129\n",
      "Epoch 230/500\n",
      "2878/2878 [==============================] - 2s 855us/step - loss: 0.5344 - accuracy: 0.7274 - val_loss: 0.5336 - val_accuracy: 0.7275\n",
      "Epoch 231/500\n",
      "2878/2878 [==============================] - 3s 879us/step - loss: 0.5381 - accuracy: 0.7243 - val_loss: 0.5334 - val_accuracy: 0.7292\n",
      "Epoch 232/500\n",
      "2878/2878 [==============================] - 3s 938us/step - loss: 0.5344 - accuracy: 0.7296 - val_loss: 0.5475 - val_accuracy: 0.7189\n",
      "Epoch 233/500\n",
      "2878/2878 [==============================] - 2s 814us/step - loss: 0.5349 - accuracy: 0.7271 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
      "Epoch 234/500\n",
      "2878/2878 [==============================] - 3s 899us/step - loss: 0.5354 - accuracy: 0.7265 - val_loss: 0.5348 - val_accuracy: 0.7271\n",
      "Epoch 235/500\n",
      "2878/2878 [==============================] - 2s 797us/step - loss: 0.5358 - accuracy: 0.7272 - val_loss: 0.5438 - val_accuracy: 0.7242\n",
      "Epoch 236/500\n",
      "2878/2878 [==============================] - 2s 757us/step - loss: 0.5369 - accuracy: 0.7263 - val_loss: 0.5348 - val_accuracy: 0.7296\n",
      "Epoch 237/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.5324 - accuracy: 0.7313 - val_loss: 0.5400 - val_accuracy: 0.7240\n",
      "Epoch 238/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5360 - accuracy: 0.7274 - val_loss: 0.5438 - val_accuracy: 0.7196\n",
      "Epoch 239/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.5394 - accuracy: 0.7243 - val_loss: 0.5346 - val_accuracy: 0.7283\n",
      "Epoch 240/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5326 - accuracy: 0.7316 - val_loss: 0.5388 - val_accuracy: 0.7226\n",
      "Epoch 241/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5347 - accuracy: 0.7273 - val_loss: 0.5369 - val_accuracy: 0.7268\n",
      "Epoch 242/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5349 - accuracy: 0.7284 - val_loss: 0.5329 - val_accuracy: 0.7290\n",
      "Epoch 243/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.5358 - accuracy: 0.7278 - val_loss: 0.5375 - val_accuracy: 0.7267\n",
      "Epoch 244/500\n",
      "2878/2878 [==============================] - 2s 790us/step - loss: 0.5350 - accuracy: 0.7267 - val_loss: 0.5337 - val_accuracy: 0.7303\n",
      "Epoch 245/500\n",
      "2878/2878 [==============================] - 2s 794us/step - loss: 0.5363 - accuracy: 0.7249 - val_loss: 0.5342 - val_accuracy: 0.7304\n",
      "Epoch 246/500\n",
      "2878/2878 [==============================] - 2s 762us/step - loss: 0.5356 - accuracy: 0.7269 - val_loss: 0.5337 - val_accuracy: 0.7311\n",
      "Epoch 247/500\n",
      "2878/2878 [==============================] - 2s 759us/step - loss: 0.5357 - accuracy: 0.7293 - val_loss: 0.5335 - val_accuracy: 0.7306\n",
      "Epoch 248/500\n",
      "2878/2878 [==============================] - 2s 819us/step - loss: 0.5347 - accuracy: 0.7278 - val_loss: 0.5364 - val_accuracy: 0.7263\n",
      "Epoch 249/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.5353 - accuracy: 0.7277 - val_loss: 0.5413 - val_accuracy: 0.7216\n",
      "Epoch 250/500\n",
      "2878/2878 [==============================] - 3s 982us/step - loss: 0.5364 - accuracy: 0.7265 - val_loss: 0.5352 - val_accuracy: 0.7263\n",
      "Epoch 251/500\n",
      "2878/2878 [==============================] - 2s 776us/step - loss: 0.5357 - accuracy: 0.7271 - val_loss: 0.5331 - val_accuracy: 0.7280\n",
      "Epoch 252/500\n",
      "2878/2878 [==============================] - 2s 760us/step - loss: 0.5344 - accuracy: 0.7270 - val_loss: 0.5362 - val_accuracy: 0.7305\n",
      "Epoch 253/500\n",
      "2878/2878 [==============================] - 2s 735us/step - loss: 0.5320 - accuracy: 0.7284 - val_loss: 0.5361 - val_accuracy: 0.7277\n",
      "Epoch 254/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5349 - accuracy: 0.7278 - val_loss: 0.5338 - val_accuracy: 0.7305\n",
      "Epoch 255/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.5334 - accuracy: 0.7285 - val_loss: 0.5344 - val_accuracy: 0.7283\n",
      "Epoch 256/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.5332 - accuracy: 0.7283 - val_loss: 0.5356 - val_accuracy: 0.7274\n",
      "Epoch 257/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.5367 - accuracy: 0.7267 - val_loss: 0.5333 - val_accuracy: 0.7295\n",
      "Epoch 258/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5344 - accuracy: 0.7280 - val_loss: 0.5378 - val_accuracy: 0.7247\n",
      "Epoch 259/500\n",
      "2878/2878 [==============================] - 2s 786us/step - loss: 0.5345 - accuracy: 0.7280 - val_loss: 0.5362 - val_accuracy: 0.7249\n",
      "Epoch 260/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.5316 - accuracy: 0.7301 - val_loss: 0.5338 - val_accuracy: 0.7277\n",
      "Epoch 261/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5356 - accuracy: 0.7275 - val_loss: 0.5354 - val_accuracy: 0.7298\n",
      "Epoch 262/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5367 - accuracy: 0.7274 - val_loss: 0.5360 - val_accuracy: 0.7275\n",
      "Epoch 263/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.5343 - accuracy: 0.7288 - val_loss: 0.5361 - val_accuracy: 0.7250\n",
      "Epoch 264/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5324 - accuracy: 0.7287 - val_loss: 0.5369 - val_accuracy: 0.7264\n",
      "Epoch 265/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.5356 - accuracy: 0.7264 - val_loss: 0.5378 - val_accuracy: 0.7233\n",
      "Epoch 266/500\n",
      "2878/2878 [==============================] - 2s 725us/step - loss: 0.5356 - accuracy: 0.7263 - val_loss: 0.5364 - val_accuracy: 0.7288\n",
      "Epoch 267/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5359 - accuracy: 0.7274 - val_loss: 0.5340 - val_accuracy: 0.7294\n",
      "Epoch 268/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5338 - accuracy: 0.7297 - val_loss: 0.5440 - val_accuracy: 0.7187\n",
      "Epoch 269/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5342 - accuracy: 0.7297 - val_loss: 0.5320 - val_accuracy: 0.7283\n",
      "Epoch 270/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5313 - accuracy: 0.7298 - val_loss: 0.5455 - val_accuracy: 0.7194\n",
      "Epoch 271/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5300 - accuracy: 0.7312 - val_loss: 0.5392 - val_accuracy: 0.7256\n",
      "Epoch 272/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5341 - accuracy: 0.7284 - val_loss: 0.5363 - val_accuracy: 0.7288\n",
      "Epoch 273/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.5342 - accuracy: 0.7287 - val_loss: 0.5354 - val_accuracy: 0.7275\n",
      "Epoch 274/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5335 - accuracy: 0.7299 - val_loss: 0.5340 - val_accuracy: 0.7274\n",
      "Epoch 275/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5357 - accuracy: 0.7281 - val_loss: 0.5370 - val_accuracy: 0.7272\n",
      "Epoch 276/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.5319 - accuracy: 0.7314 - val_loss: 0.5360 - val_accuracy: 0.7262\n",
      "Epoch 277/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.5337 - accuracy: 0.7297 - val_loss: 0.5373 - val_accuracy: 0.7248\n",
      "Epoch 278/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.5319 - accuracy: 0.7298 - val_loss: 0.5328 - val_accuracy: 0.7288\n",
      "Epoch 279/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.5364 - accuracy: 0.7277 - val_loss: 0.5327 - val_accuracy: 0.7294\n",
      "Epoch 280/500\n",
      "2878/2878 [==============================] - 2s 727us/step - loss: 0.5326 - accuracy: 0.7287 - val_loss: 0.5340 - val_accuracy: 0.7279\n",
      "Epoch 281/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.5331 - accuracy: 0.7311 - val_loss: 0.5349 - val_accuracy: 0.7286\n",
      "Epoch 282/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5326 - accuracy: 0.7280 - val_loss: 0.5344 - val_accuracy: 0.7272\n",
      "Epoch 283/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5357 - accuracy: 0.7263 - val_loss: 0.5333 - val_accuracy: 0.7285\n",
      "Epoch 284/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5340 - accuracy: 0.7271 - val_loss: 0.5323 - val_accuracy: 0.7303\n",
      "Epoch 285/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5374 - accuracy: 0.7239 - val_loss: 0.5325 - val_accuracy: 0.7284\n",
      "Epoch 286/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5330 - accuracy: 0.7289 - val_loss: 0.5344 - val_accuracy: 0.7262\n",
      "Epoch 287/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5336 - accuracy: 0.7264 - val_loss: 0.5331 - val_accuracy: 0.7296\n",
      "Epoch 288/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5322 - accuracy: 0.7301 - val_loss: 0.5330 - val_accuracy: 0.7259\n",
      "Epoch 289/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5328 - accuracy: 0.7288 - val_loss: 0.5325 - val_accuracy: 0.7271\n",
      "Epoch 290/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.5333 - accuracy: 0.7279 - val_loss: 0.5337 - val_accuracy: 0.7287\n",
      "Epoch 291/500\n",
      "2878/2878 [==============================] - 2s 726us/step - loss: 0.5343 - accuracy: 0.7266 - val_loss: 0.5337 - val_accuracy: 0.7275\n",
      "Epoch 292/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5324 - accuracy: 0.7306 - val_loss: 0.5371 - val_accuracy: 0.7252\n",
      "Epoch 293/500\n",
      "2878/2878 [==============================] - 2s 733us/step - loss: 0.5348 - accuracy: 0.7277 - val_loss: 0.5320 - val_accuracy: 0.7295\n",
      "Epoch 294/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5332 - accuracy: 0.7289 - val_loss: 0.5349 - val_accuracy: 0.7249\n",
      "Epoch 295/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5339 - accuracy: 0.7283 - val_loss: 0.5325 - val_accuracy: 0.7305\n",
      "Epoch 296/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5324 - accuracy: 0.7289 - val_loss: 0.5331 - val_accuracy: 0.7288\n",
      "Epoch 297/500\n",
      "2878/2878 [==============================] - 2s 796us/step - loss: 0.5325 - accuracy: 0.7299 - val_loss: 0.5342 - val_accuracy: 0.7262\n",
      "Epoch 298/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5324 - accuracy: 0.7302 - val_loss: 0.5339 - val_accuracy: 0.7304\n",
      "Epoch 299/500\n",
      "2878/2878 [==============================] - 2s 769us/step - loss: 0.5356 - accuracy: 0.7267 - val_loss: 0.5567 - val_accuracy: 0.7127\n",
      "Epoch 300/500\n",
      "2878/2878 [==============================] - 2s 846us/step - loss: 0.5323 - accuracy: 0.7299 - val_loss: 0.5315 - val_accuracy: 0.7309\n",
      "Epoch 301/500\n",
      "2878/2878 [==============================] - 2s 850us/step - loss: 0.5340 - accuracy: 0.7287 - val_loss: 0.5342 - val_accuracy: 0.7248\n",
      "Epoch 302/500\n",
      "2878/2878 [==============================] - 2s 863us/step - loss: 0.5330 - accuracy: 0.7281 - val_loss: 0.5378 - val_accuracy: 0.7228\n",
      "Epoch 303/500\n",
      "2878/2878 [==============================] - 3s 900us/step - loss: 0.5338 - accuracy: 0.7292 - val_loss: 0.5369 - val_accuracy: 0.7246\n",
      "Epoch 304/500\n",
      "2878/2878 [==============================] - 3s 879us/step - loss: 0.5311 - accuracy: 0.7299 - val_loss: 0.5330 - val_accuracy: 0.7282\n",
      "Epoch 305/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.5292 - accuracy: 0.7327 - val_loss: 0.5358 - val_accuracy: 0.7257\n",
      "Epoch 306/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5324 - accuracy: 0.7290 - val_loss: 0.5325 - val_accuracy: 0.7267\n",
      "Epoch 307/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5350 - accuracy: 0.7270 - val_loss: 0.5349 - val_accuracy: 0.7248\n",
      "Epoch 308/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5314 - accuracy: 0.7299 - val_loss: 0.5319 - val_accuracy: 0.7292\n",
      "Epoch 309/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5344 - accuracy: 0.7286 - val_loss: 0.5395 - val_accuracy: 0.7240\n",
      "Epoch 310/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5343 - accuracy: 0.7271 - val_loss: 0.5458 - val_accuracy: 0.7140\n",
      "Epoch 311/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5346 - accuracy: 0.7296 - val_loss: 0.5340 - val_accuracy: 0.7240\n",
      "Epoch 312/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5315 - accuracy: 0.7304 - val_loss: 0.5365 - val_accuracy: 0.7239\n",
      "Epoch 313/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5328 - accuracy: 0.7280 - val_loss: 0.5398 - val_accuracy: 0.7246\n",
      "Epoch 314/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5356 - accuracy: 0.7271 - val_loss: 0.5334 - val_accuracy: 0.7252\n",
      "Epoch 315/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5331 - accuracy: 0.7306 - val_loss: 0.5420 - val_accuracy: 0.7163\n",
      "Epoch 316/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.5343 - accuracy: 0.7283 - val_loss: 0.5324 - val_accuracy: 0.7286\n",
      "Epoch 317/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.5330 - accuracy: 0.7293 - val_loss: 0.5348 - val_accuracy: 0.7299\n",
      "Epoch 318/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.5334 - accuracy: 0.7267 - val_loss: 0.5539 - val_accuracy: 0.7103\n",
      "Epoch 319/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.5344 - accuracy: 0.7284 - val_loss: 0.5406 - val_accuracy: 0.7226\n",
      "Epoch 320/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5312 - accuracy: 0.7286 - val_loss: 0.5324 - val_accuracy: 0.7282\n",
      "Epoch 321/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5322 - accuracy: 0.7297 - val_loss: 0.5328 - val_accuracy: 0.7290\n",
      "Epoch 322/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5338 - accuracy: 0.7276 - val_loss: 0.5355 - val_accuracy: 0.7253\n",
      "Epoch 323/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5311 - accuracy: 0.7309 - val_loss: 0.5331 - val_accuracy: 0.7287\n",
      "Epoch 324/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5334 - accuracy: 0.7287 - val_loss: 0.5315 - val_accuracy: 0.7300\n",
      "Epoch 325/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5324 - accuracy: 0.7300 - val_loss: 0.5336 - val_accuracy: 0.7274\n",
      "Epoch 326/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5306 - accuracy: 0.7319 - val_loss: 0.5332 - val_accuracy: 0.7289\n",
      "Epoch 327/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5321 - accuracy: 0.7309 - val_loss: 0.5342 - val_accuracy: 0.7265\n",
      "Epoch 328/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5292 - accuracy: 0.7314 - val_loss: 0.5360 - val_accuracy: 0.7265\n",
      "Epoch 329/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5348 - accuracy: 0.7278 - val_loss: 0.5343 - val_accuracy: 0.7276\n",
      "Epoch 330/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.5338 - accuracy: 0.7273 - val_loss: 0.5328 - val_accuracy: 0.7278\n",
      "Epoch 331/500\n",
      "2878/2878 [==============================] - 2s 736us/step - loss: 0.5336 - accuracy: 0.7284 - val_loss: 0.5358 - val_accuracy: 0.7275\n",
      "Epoch 332/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.5340 - accuracy: 0.7285 - val_loss: 0.5372 - val_accuracy: 0.7233\n",
      "Epoch 333/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5343 - accuracy: 0.7273 - val_loss: 0.5385 - val_accuracy: 0.7253\n",
      "Epoch 334/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5322 - accuracy: 0.7299 - val_loss: 0.5327 - val_accuracy: 0.7298\n",
      "Epoch 335/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5333 - accuracy: 0.7294 - val_loss: 0.5355 - val_accuracy: 0.7255\n",
      "Epoch 336/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5326 - accuracy: 0.7285 - val_loss: 0.5345 - val_accuracy: 0.7269\n",
      "Epoch 337/500\n",
      "2878/2878 [==============================] - 2s 705us/step - loss: 0.5353 - accuracy: 0.7268 - val_loss: 0.5321 - val_accuracy: 0.7269\n",
      "Epoch 338/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5318 - accuracy: 0.7287 - val_loss: 0.5331 - val_accuracy: 0.7302\n",
      "Epoch 339/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5313 - accuracy: 0.7275 - val_loss: 0.5323 - val_accuracy: 0.7263\n",
      "Epoch 340/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5337 - accuracy: 0.7274 - val_loss: 0.5455 - val_accuracy: 0.7238\n",
      "Epoch 341/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5329 - accuracy: 0.7288 - val_loss: 0.5363 - val_accuracy: 0.7263\n",
      "Epoch 342/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5294 - accuracy: 0.7320 - val_loss: 0.5324 - val_accuracy: 0.7268\n",
      "Epoch 343/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5319 - accuracy: 0.7288 - val_loss: 0.5456 - val_accuracy: 0.7167\n",
      "Epoch 344/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5324 - accuracy: 0.7283 - val_loss: 0.5329 - val_accuracy: 0.7286\n",
      "Epoch 345/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5356 - accuracy: 0.7256 - val_loss: 0.5356 - val_accuracy: 0.7281\n",
      "Epoch 346/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5294 - accuracy: 0.7321 - val_loss: 0.5334 - val_accuracy: 0.7299\n",
      "Epoch 347/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5340 - accuracy: 0.7297 - val_loss: 0.5335 - val_accuracy: 0.7302\n",
      "Epoch 348/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.5305 - accuracy: 0.7322 - val_loss: 0.5330 - val_accuracy: 0.7284\n",
      "Epoch 349/500\n",
      "2878/2878 [==============================] - 2s 722us/step - loss: 0.5336 - accuracy: 0.7285 - val_loss: 0.5319 - val_accuracy: 0.7262\n",
      "Epoch 350/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.5326 - accuracy: 0.7298 - val_loss: 0.5345 - val_accuracy: 0.7253\n",
      "Epoch 351/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5335 - accuracy: 0.7283 - val_loss: 0.5319 - val_accuracy: 0.7298\n",
      "Epoch 352/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.5340 - accuracy: 0.7275 - val_loss: 0.5344 - val_accuracy: 0.7276\n",
      "Epoch 353/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5321 - accuracy: 0.7299 - val_loss: 0.5324 - val_accuracy: 0.7257\n",
      "Epoch 354/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5304 - accuracy: 0.7289 - val_loss: 0.5327 - val_accuracy: 0.7287\n",
      "Epoch 355/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5345 - accuracy: 0.7275 - val_loss: 0.5322 - val_accuracy: 0.7291\n",
      "Epoch 356/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5348 - accuracy: 0.7258 - val_loss: 0.5320 - val_accuracy: 0.7289\n",
      "Epoch 357/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5328 - accuracy: 0.7285 - val_loss: 0.5330 - val_accuracy: 0.7269\n",
      "Epoch 358/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5337 - accuracy: 0.7261 - val_loss: 0.5329 - val_accuracy: 0.7295\n",
      "Epoch 359/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5315 - accuracy: 0.7292 - val_loss: 0.5342 - val_accuracy: 0.7275\n",
      "Epoch 360/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5312 - accuracy: 0.7307 - val_loss: 0.5326 - val_accuracy: 0.7279\n",
      "Epoch 361/500\n",
      "2878/2878 [==============================] - 2s 716us/step - loss: 0.5305 - accuracy: 0.7314 - val_loss: 0.5330 - val_accuracy: 0.7274\n",
      "Epoch 362/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.5315 - accuracy: 0.7305 - val_loss: 0.5349 - val_accuracy: 0.7251\n",
      "Epoch 363/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5353 - accuracy: 0.7276 - val_loss: 0.5335 - val_accuracy: 0.7292\n",
      "Epoch 364/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.5315 - accuracy: 0.7293 - val_loss: 0.5313 - val_accuracy: 0.7299\n",
      "Epoch 365/500\n",
      "2878/2878 [==============================] - 2s 719us/step - loss: 0.5318 - accuracy: 0.7292 - val_loss: 0.5354 - val_accuracy: 0.7276\n",
      "Epoch 366/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5328 - accuracy: 0.7284 - val_loss: 0.5377 - val_accuracy: 0.7253\n",
      "Epoch 367/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5303 - accuracy: 0.7307 - val_loss: 0.5336 - val_accuracy: 0.7242\n",
      "Epoch 368/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5302 - accuracy: 0.7324 - val_loss: 0.5424 - val_accuracy: 0.7237\n",
      "Epoch 369/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5323 - accuracy: 0.7298 - val_loss: 0.5333 - val_accuracy: 0.7262\n",
      "Epoch 370/500\n",
      "2878/2878 [==============================] - 2s 692us/step - loss: 0.5310 - accuracy: 0.7303 - val_loss: 0.5329 - val_accuracy: 0.7289\n",
      "Epoch 371/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5338 - accuracy: 0.7278 - val_loss: 0.5323 - val_accuracy: 0.7274\n",
      "Epoch 372/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5318 - accuracy: 0.7289 - val_loss: 0.5374 - val_accuracy: 0.7240\n",
      "Epoch 373/500\n",
      "2878/2878 [==============================] - 2s 712us/step - loss: 0.5340 - accuracy: 0.7285 - val_loss: 0.5315 - val_accuracy: 0.7293\n",
      "Epoch 374/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5328 - accuracy: 0.7275 - val_loss: 0.5305 - val_accuracy: 0.7292\n",
      "Epoch 375/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.5347 - accuracy: 0.7257 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
      "Epoch 376/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.5329 - accuracy: 0.7271 - val_loss: 0.5339 - val_accuracy: 0.7247\n",
      "Epoch 377/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.5333 - accuracy: 0.7293 - val_loss: 0.5321 - val_accuracy: 0.7289\n",
      "Epoch 378/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5322 - accuracy: 0.7270 - val_loss: 0.5384 - val_accuracy: 0.7219\n",
      "Epoch 379/500\n",
      "2878/2878 [==============================] - 2s 714us/step - loss: 0.5334 - accuracy: 0.7272 - val_loss: 0.5319 - val_accuracy: 0.7265\n",
      "Epoch 380/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5303 - accuracy: 0.7303 - val_loss: 0.5338 - val_accuracy: 0.7272\n",
      "Epoch 381/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5301 - accuracy: 0.7305 - val_loss: 0.5331 - val_accuracy: 0.7295\n",
      "Epoch 382/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5335 - accuracy: 0.7288 - val_loss: 0.5323 - val_accuracy: 0.7299\n",
      "Epoch 383/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5325 - accuracy: 0.7292 - val_loss: 0.5317 - val_accuracy: 0.7272\n",
      "Epoch 384/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5317 - accuracy: 0.7289 - val_loss: 0.5342 - val_accuracy: 0.7227\n",
      "Epoch 385/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5326 - accuracy: 0.7281 - val_loss: 0.5380 - val_accuracy: 0.7245\n",
      "Epoch 386/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5318 - accuracy: 0.7293 - val_loss: 0.5340 - val_accuracy: 0.7262\n",
      "Epoch 387/500\n",
      "2878/2878 [==============================] - 2s 702us/step - loss: 0.5350 - accuracy: 0.7271 - val_loss: 0.5309 - val_accuracy: 0.7298\n",
      "Epoch 388/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5333 - accuracy: 0.7274 - val_loss: 0.5358 - val_accuracy: 0.7261\n",
      "Epoch 389/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5287 - accuracy: 0.7327 - val_loss: 0.5341 - val_accuracy: 0.7268\n",
      "Epoch 390/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5336 - accuracy: 0.7287 - val_loss: 0.5324 - val_accuracy: 0.7282\n",
      "Epoch 391/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5354 - accuracy: 0.7267 - val_loss: 0.5320 - val_accuracy: 0.7277\n",
      "Epoch 392/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5337 - accuracy: 0.7264 - val_loss: 0.5327 - val_accuracy: 0.7295\n",
      "Epoch 393/500\n",
      "2878/2878 [==============================] - 2s 718us/step - loss: 0.5309 - accuracy: 0.7310 - val_loss: 0.5337 - val_accuracy: 0.7285\n",
      "Epoch 394/500\n",
      "2878/2878 [==============================] - 2s 824us/step - loss: 0.5316 - accuracy: 0.7291 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 395/500\n",
      "2878/2878 [==============================] - 2s 728us/step - loss: 0.5321 - accuracy: 0.7292 - val_loss: 0.5321 - val_accuracy: 0.7300\n",
      "Epoch 396/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.5307 - accuracy: 0.7303 - val_loss: 0.5336 - val_accuracy: 0.7288\n",
      "Epoch 397/500\n",
      "2878/2878 [==============================] - 2s 737us/step - loss: 0.5296 - accuracy: 0.7315 - val_loss: 0.5325 - val_accuracy: 0.7300\n",
      "Epoch 398/500\n",
      "2878/2878 [==============================] - 2s 730us/step - loss: 0.5340 - accuracy: 0.7279 - val_loss: 0.5410 - val_accuracy: 0.7209\n",
      "Epoch 399/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.5310 - accuracy: 0.7293 - val_loss: 0.5387 - val_accuracy: 0.7213\n",
      "Epoch 400/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5332 - accuracy: 0.7287 - val_loss: 0.5311 - val_accuracy: 0.7290\n",
      "Epoch 401/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5330 - accuracy: 0.7272 - val_loss: 0.5319 - val_accuracy: 0.7313\n",
      "Epoch 402/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5319 - accuracy: 0.7291 - val_loss: 0.5379 - val_accuracy: 0.7243\n",
      "Epoch 403/500\n",
      "2878/2878 [==============================] - 2s 846us/step - loss: 0.5326 - accuracy: 0.7301 - val_loss: 0.5345 - val_accuracy: 0.7262\n",
      "Epoch 404/500\n",
      "2878/2878 [==============================] - 3s 921us/step - loss: 0.5288 - accuracy: 0.7316 - val_loss: 0.5327 - val_accuracy: 0.7254\n",
      "Epoch 405/500\n",
      "2878/2878 [==============================] - 3s 877us/step - loss: 0.5361 - accuracy: 0.7253 - val_loss: 0.5311 - val_accuracy: 0.7289\n",
      "Epoch 406/500\n",
      "2878/2878 [==============================] - 2s 849us/step - loss: 0.5294 - accuracy: 0.7309 - val_loss: 0.5344 - val_accuracy: 0.7252\n",
      "Epoch 407/500\n",
      "2878/2878 [==============================] - 2s 752us/step - loss: 0.5323 - accuracy: 0.7273 - val_loss: 0.5326 - val_accuracy: 0.7281\n",
      "Epoch 408/500\n",
      "2878/2878 [==============================] - 2s 784us/step - loss: 0.5326 - accuracy: 0.7275 - val_loss: 0.5375 - val_accuracy: 0.7259\n",
      "Epoch 409/500\n",
      "2878/2878 [==============================] - 2s 740us/step - loss: 0.5314 - accuracy: 0.7289 - val_loss: 0.5351 - val_accuracy: 0.7253\n",
      "Epoch 410/500\n",
      "2878/2878 [==============================] - 2s 708us/step - loss: 0.5324 - accuracy: 0.7296 - val_loss: 0.5367 - val_accuracy: 0.7255\n",
      "Epoch 411/500\n",
      "2878/2878 [==============================] - 2s 696us/step - loss: 0.5334 - accuracy: 0.7274 - val_loss: 0.5308 - val_accuracy: 0.7310\n",
      "Epoch 412/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5351 - accuracy: 0.7270 - val_loss: 0.5357 - val_accuracy: 0.7272\n",
      "Epoch 413/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5310 - accuracy: 0.7293 - val_loss: 0.5336 - val_accuracy: 0.7251\n",
      "Epoch 414/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5332 - accuracy: 0.7293 - val_loss: 0.5316 - val_accuracy: 0.7269\n",
      "Epoch 415/500\n",
      "2878/2878 [==============================] - 2s 704us/step - loss: 0.5335 - accuracy: 0.7283 - val_loss: 0.5309 - val_accuracy: 0.7279\n",
      "Epoch 416/500\n",
      "2878/2878 [==============================] - 2s 717us/step - loss: 0.5317 - accuracy: 0.7288 - val_loss: 0.5331 - val_accuracy: 0.7282\n",
      "Epoch 417/500\n",
      "2878/2878 [==============================] - 2s 713us/step - loss: 0.5324 - accuracy: 0.7283 - val_loss: 0.5316 - val_accuracy: 0.7290\n",
      "Epoch 418/500\n",
      "2878/2878 [==============================] - 2s 758us/step - loss: 0.5317 - accuracy: 0.7283 - val_loss: 0.5315 - val_accuracy: 0.7280\n",
      "Epoch 419/500\n",
      "2878/2878 [==============================] - 2s 771us/step - loss: 0.5320 - accuracy: 0.7283 - val_loss: 0.5319 - val_accuracy: 0.7277\n",
      "Epoch 420/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.5315 - accuracy: 0.7314 - val_loss: 0.5331 - val_accuracy: 0.7298\n",
      "Epoch 421/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5300 - accuracy: 0.7292 - val_loss: 0.5488 - val_accuracy: 0.7217\n",
      "Epoch 422/500\n",
      "2878/2878 [==============================] - 2s 769us/step - loss: 0.5310 - accuracy: 0.7300 - val_loss: 0.5323 - val_accuracy: 0.7302\n",
      "Epoch 423/500\n",
      "2878/2878 [==============================] - 2s 809us/step - loss: 0.5332 - accuracy: 0.7294 - val_loss: 0.5354 - val_accuracy: 0.7266\n",
      "Epoch 424/500\n",
      "2878/2878 [==============================] - 2s 779us/step - loss: 0.5335 - accuracy: 0.7301 - val_loss: 0.5338 - val_accuracy: 0.7289\n",
      "Epoch 425/500\n",
      "2878/2878 [==============================] - 2s 788us/step - loss: 0.5309 - accuracy: 0.7323 - val_loss: 0.5384 - val_accuracy: 0.7250\n",
      "Epoch 426/500\n",
      "2878/2878 [==============================] - 2s 861us/step - loss: 0.5294 - accuracy: 0.7315 - val_loss: 0.5328 - val_accuracy: 0.7265\n",
      "Epoch 427/500\n",
      "2878/2878 [==============================] - 2s 796us/step - loss: 0.5318 - accuracy: 0.7275 - val_loss: 0.5360 - val_accuracy: 0.7255\n",
      "Epoch 428/500\n",
      "2878/2878 [==============================] - 2s 848us/step - loss: 0.5309 - accuracy: 0.7300 - val_loss: 0.5329 - val_accuracy: 0.7263\n",
      "Epoch 429/500\n",
      "2878/2878 [==============================] - 2s 788us/step - loss: 0.5335 - accuracy: 0.7281 - val_loss: 0.5313 - val_accuracy: 0.7274\n",
      "Epoch 430/500\n",
      "2878/2878 [==============================] - 3s 967us/step - loss: 0.5319 - accuracy: 0.7294 - val_loss: 0.5350 - val_accuracy: 0.7266\n",
      "Epoch 431/500\n",
      "2878/2878 [==============================] - 2s 840us/step - loss: 0.5324 - accuracy: 0.7282 - val_loss: 0.5367 - val_accuracy: 0.7241\n",
      "Epoch 432/500\n",
      "2878/2878 [==============================] - 3s 918us/step - loss: 0.5293 - accuracy: 0.7306 - val_loss: 0.5354 - val_accuracy: 0.7255\n",
      "Epoch 433/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5344 - accuracy: 0.7282 - val_loss: 0.5402 - val_accuracy: 0.7233\n",
      "Epoch 434/500\n",
      "2878/2878 [==============================] - 2s 784us/step - loss: 0.5325 - accuracy: 0.7281 - val_loss: 0.5366 - val_accuracy: 0.7219\n",
      "Epoch 435/500\n",
      "2878/2878 [==============================] - 2s 807us/step - loss: 0.5313 - accuracy: 0.7287 - val_loss: 0.5347 - val_accuracy: 0.7267\n",
      "Epoch 436/500\n",
      "2878/2878 [==============================] - 2s 751us/step - loss: 0.5317 - accuracy: 0.7312 - val_loss: 0.5353 - val_accuracy: 0.7268\n",
      "Epoch 437/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5326 - accuracy: 0.7300 - val_loss: 0.5351 - val_accuracy: 0.7284\n",
      "Epoch 438/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5293 - accuracy: 0.7318 - val_loss: 0.5425 - val_accuracy: 0.7208\n",
      "Epoch 439/500\n",
      "2878/2878 [==============================] - 2s 695us/step - loss: 0.5292 - accuracy: 0.7325 - val_loss: 0.5371 - val_accuracy: 0.7272\n",
      "Epoch 440/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5296 - accuracy: 0.7279 - val_loss: 0.5365 - val_accuracy: 0.7287\n",
      "Epoch 441/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5309 - accuracy: 0.7298 - val_loss: 0.5319 - val_accuracy: 0.7295\n",
      "Epoch 442/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5297 - accuracy: 0.7299 - val_loss: 0.5323 - val_accuracy: 0.7278\n",
      "Epoch 443/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5311 - accuracy: 0.7293 - val_loss: 0.5331 - val_accuracy: 0.7276\n",
      "Epoch 444/500\n",
      "2878/2878 [==============================] - 2s 700us/step - loss: 0.5316 - accuracy: 0.7301 - val_loss: 0.5321 - val_accuracy: 0.7281\n",
      "Epoch 445/500\n",
      "2878/2878 [==============================] - 2s 711us/step - loss: 0.5325 - accuracy: 0.7283 - val_loss: 0.5332 - val_accuracy: 0.7286\n",
      "Epoch 446/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5300 - accuracy: 0.7296 - val_loss: 0.5339 - val_accuracy: 0.7292\n",
      "Epoch 447/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.5300 - accuracy: 0.7312 - val_loss: 0.5317 - val_accuracy: 0.7281\n",
      "Epoch 448/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5280 - accuracy: 0.7329 - val_loss: 0.5323 - val_accuracy: 0.7278\n",
      "Epoch 449/500\n",
      "2878/2878 [==============================] - 2s 720us/step - loss: 0.5323 - accuracy: 0.7287 - val_loss: 0.5319 - val_accuracy: 0.7293\n",
      "Epoch 450/500\n",
      "2878/2878 [==============================] - 2s 703us/step - loss: 0.5289 - accuracy: 0.7308 - val_loss: 0.5337 - val_accuracy: 0.7276\n",
      "Epoch 451/500\n",
      "2878/2878 [==============================] - 2s 744us/step - loss: 0.5319 - accuracy: 0.7290 - val_loss: 0.5314 - val_accuracy: 0.7281\n",
      "Epoch 452/500\n",
      "2878/2878 [==============================] - 2s 743us/step - loss: 0.5329 - accuracy: 0.7277 - val_loss: 0.5437 - val_accuracy: 0.7199\n",
      "Epoch 453/500\n",
      "2878/2878 [==============================] - 2s 834us/step - loss: 0.5326 - accuracy: 0.7279 - val_loss: 0.5336 - val_accuracy: 0.7266\n",
      "Epoch 454/500\n",
      "2878/2878 [==============================] - 2s 856us/step - loss: 0.5315 - accuracy: 0.7295 - val_loss: 0.5308 - val_accuracy: 0.7287\n",
      "Epoch 455/500\n",
      "2878/2878 [==============================] - 2s 809us/step - loss: 0.5311 - accuracy: 0.7301 - val_loss: 0.5341 - val_accuracy: 0.7279\n",
      "Epoch 456/500\n",
      "2878/2878 [==============================] - 3s 897us/step - loss: 0.5311 - accuracy: 0.7296 - val_loss: 0.5344 - val_accuracy: 0.7283\n",
      "Epoch 457/500\n",
      "2878/2878 [==============================] - 2s 856us/step - loss: 0.5317 - accuracy: 0.7299 - val_loss: 0.5323 - val_accuracy: 0.7269\n",
      "Epoch 458/500\n",
      "2878/2878 [==============================] - 2s 807us/step - loss: 0.5313 - accuracy: 0.7266 - val_loss: 0.5314 - val_accuracy: 0.7278\n",
      "Epoch 459/500\n",
      "2878/2878 [==============================] - 2s 855us/step - loss: 0.5337 - accuracy: 0.7273 - val_loss: 0.5341 - val_accuracy: 0.7242\n",
      "Epoch 460/500\n",
      "2878/2878 [==============================] - 2s 734us/step - loss: 0.5323 - accuracy: 0.7273 - val_loss: 0.5321 - val_accuracy: 0.7278\n",
      "Epoch 461/500\n",
      "2878/2878 [==============================] - 2s 707us/step - loss: 0.5285 - accuracy: 0.7330 - val_loss: 0.5386 - val_accuracy: 0.7226\n",
      "Epoch 462/500\n",
      "2878/2878 [==============================] - 2s 683us/step - loss: 0.5318 - accuracy: 0.7281 - val_loss: 0.5317 - val_accuracy: 0.7288\n",
      "Epoch 463/500\n",
      "2878/2878 [==============================] - 2s 690us/step - loss: 0.5326 - accuracy: 0.7287 - val_loss: 0.5306 - val_accuracy: 0.7282\n",
      "Epoch 464/500\n",
      "2878/2878 [==============================] - 2s 682us/step - loss: 0.5302 - accuracy: 0.7311 - val_loss: 0.5310 - val_accuracy: 0.7291\n",
      "Epoch 465/500\n",
      "2878/2878 [==============================] - 2s 679us/step - loss: 0.5319 - accuracy: 0.7292 - val_loss: 0.5307 - val_accuracy: 0.7274\n",
      "Epoch 466/500\n",
      "2878/2878 [==============================] - 2s 760us/step - loss: 0.5351 - accuracy: 0.7281 - val_loss: 0.5379 - val_accuracy: 0.7241\n",
      "Epoch 467/500\n",
      "2878/2878 [==============================] - 2s 706us/step - loss: 0.5299 - accuracy: 0.7312 - val_loss: 0.5329 - val_accuracy: 0.7282\n",
      "Epoch 468/500\n",
      "2878/2878 [==============================] - 2s 739us/step - loss: 0.5322 - accuracy: 0.7282 - val_loss: 0.5341 - val_accuracy: 0.7287\n",
      "Epoch 469/500\n",
      "2878/2878 [==============================] - 2s 694us/step - loss: 0.5316 - accuracy: 0.7290 - val_loss: 0.5319 - val_accuracy: 0.7272\n",
      "Epoch 470/500\n",
      "2878/2878 [==============================] - 2s 697us/step - loss: 0.5330 - accuracy: 0.7302 - val_loss: 0.5343 - val_accuracy: 0.7299\n",
      "Epoch 471/500\n",
      "2878/2878 [==============================] - 2s 732us/step - loss: 0.5320 - accuracy: 0.7304 - val_loss: 0.5319 - val_accuracy: 0.7292\n",
      "Epoch 472/500\n",
      "2878/2878 [==============================] - 2s 729us/step - loss: 0.5324 - accuracy: 0.7298 - val_loss: 0.5314 - val_accuracy: 0.7299\n",
      "Epoch 473/500\n",
      "2878/2878 [==============================] - 2s 723us/step - loss: 0.5312 - accuracy: 0.7281 - val_loss: 0.5327 - val_accuracy: 0.7287\n",
      "Epoch 474/500\n",
      "2878/2878 [==============================] - 2s 731us/step - loss: 0.5319 - accuracy: 0.7284 - val_loss: 0.5313 - val_accuracy: 0.7315\n",
      "Epoch 475/500\n",
      "2878/2878 [==============================] - 2s 747us/step - loss: 0.5338 - accuracy: 0.7273 - val_loss: 0.5318 - val_accuracy: 0.7266\n",
      "Epoch 476/500\n",
      "2878/2878 [==============================] - 2s 721us/step - loss: 0.5324 - accuracy: 0.7281 - val_loss: 0.5396 - val_accuracy: 0.7201\n",
      "Epoch 477/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5325 - accuracy: 0.7269 - val_loss: 0.5312 - val_accuracy: 0.7273\n",
      "Epoch 478/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5316 - accuracy: 0.7311 - val_loss: 0.5327 - val_accuracy: 0.7276\n",
      "Epoch 479/500\n",
      "2878/2878 [==============================] - 2s 701us/step - loss: 0.5348 - accuracy: 0.7288 - val_loss: 0.5313 - val_accuracy: 0.7295\n",
      "Epoch 480/500\n",
      "2878/2878 [==============================] - 2s 748us/step - loss: 0.5331 - accuracy: 0.7276 - val_loss: 0.5318 - val_accuracy: 0.7295\n",
      "Epoch 481/500\n",
      "2878/2878 [==============================] - 2s 698us/step - loss: 0.5310 - accuracy: 0.7307 - val_loss: 0.5324 - val_accuracy: 0.7285\n",
      "Epoch 482/500\n",
      "2878/2878 [==============================] - 2s 693us/step - loss: 0.5296 - accuracy: 0.7305 - val_loss: 0.5316 - val_accuracy: 0.7293\n",
      "Epoch 483/500\n",
      "2878/2878 [==============================] - 2s 699us/step - loss: 0.5290 - accuracy: 0.7331 - val_loss: 0.5316 - val_accuracy: 0.7263\n",
      "Epoch 484/500\n",
      "2878/2878 [==============================] - 2s 724us/step - loss: 0.5319 - accuracy: 0.7306 - val_loss: 0.5308 - val_accuracy: 0.7311\n",
      "Epoch 485/500\n",
      "2878/2878 [==============================] - 3s 922us/step - loss: 0.5300 - accuracy: 0.7300 - val_loss: 0.5404 - val_accuracy: 0.7244\n",
      "Epoch 486/500\n",
      "2878/2878 [==============================] - 2s 850us/step - loss: 0.5295 - accuracy: 0.7323 - val_loss: 0.5334 - val_accuracy: 0.7252\n",
      "Epoch 487/500\n",
      "2878/2878 [==============================] - 2s 761us/step - loss: 0.5269 - accuracy: 0.7343 - val_loss: 0.5347 - val_accuracy: 0.7248\n",
      "Epoch 488/500\n",
      "2878/2878 [==============================] - 2s 741us/step - loss: 0.5300 - accuracy: 0.7317 - val_loss: 0.5313 - val_accuracy: 0.7308\n",
      "Epoch 489/500\n",
      "2878/2878 [==============================] - 2s 710us/step - loss: 0.5321 - accuracy: 0.7297 - val_loss: 0.5314 - val_accuracy: 0.7321\n",
      "Epoch 490/500\n",
      "2878/2878 [==============================] - 2s 685us/step - loss: 0.5276 - accuracy: 0.7311 - val_loss: 0.5347 - val_accuracy: 0.7243\n",
      "Epoch 491/500\n",
      "2878/2878 [==============================] - 2s 686us/step - loss: 0.5293 - accuracy: 0.7324 - val_loss: 0.5315 - val_accuracy: 0.7298\n",
      "Epoch 492/500\n",
      "2878/2878 [==============================] - 2s 689us/step - loss: 0.5298 - accuracy: 0.7315 - val_loss: 0.5318 - val_accuracy: 0.7297\n",
      "Epoch 493/500\n",
      "2878/2878 [==============================] - 2s 691us/step - loss: 0.5327 - accuracy: 0.7280 - val_loss: 0.5476 - val_accuracy: 0.7117\n",
      "Epoch 494/500\n",
      "2878/2878 [==============================] - 2s 709us/step - loss: 0.5297 - accuracy: 0.7299 - val_loss: 0.5319 - val_accuracy: 0.7302\n",
      "Epoch 495/500\n",
      "2878/2878 [==============================] - 2s 801us/step - loss: 0.5293 - accuracy: 0.7314 - val_loss: 0.5322 - val_accuracy: 0.7303\n",
      "Epoch 496/500\n",
      "2878/2878 [==============================] - 2s 837us/step - loss: 0.5301 - accuracy: 0.7312 - val_loss: 0.5424 - val_accuracy: 0.7239\n",
      "Epoch 497/500\n",
      "2878/2878 [==============================] - 2s 775us/step - loss: 0.5299 - accuracy: 0.7297 - val_loss: 0.5339 - val_accuracy: 0.7247\n",
      "Epoch 498/500\n",
      "2878/2878 [==============================] - 2s 757us/step - loss: 0.5325 - accuracy: 0.7294 - val_loss: 0.5302 - val_accuracy: 0.7304\n",
      "Epoch 499/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5304 - accuracy: 0.7296 - val_loss: 0.5351 - val_accuracy: 0.7271\n",
      "Epoch 500/500\n",
      "2878/2878 [==============================] - 2s 715us/step - loss: 0.5311 - accuracy: 0.7288 - val_loss: 0.5317 - val_accuracy: 0.7299\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(shuffle(pd.DataFrame(x_train_resampled),random_state=1), shuffle(pd.DataFrame(y_train_resampled),random_state=1), epochs=500,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train_resampled)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_13.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MlChallenge3",
   "language": "python",
   "name": "mlchallenge3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
