{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,RobustScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "train                 = pd.read_csv('Data/train.csv')\n",
    "test                  = pd.read_csv('Data/test.csv')\n",
    "monthly_expenditures  = pd.read_csv('Data/monthly_expenditures.csv')\n",
    "sample_submission     = pd.read_csv('Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_egitim                       = LabelEncoder().fit(train['egitim'])\n",
    "train['egitim']                 = le_egitim.transform(train['egitim'])\n",
    "test['egitim']                  = le_egitim.transform(test['egitim'])\n",
    "\n",
    "\n",
    "le_is_durumu                    = LabelEncoder().fit(train['is_durumu'])\n",
    "train['is_durumu']              = le_is_durumu.transform(train['is_durumu'])\n",
    "test['is_durumu']               = le_is_durumu.transform(test['is_durumu'])\n",
    "\n",
    "le_meslek_grubu                 = LabelEncoder().fit(train['meslek_grubu'])\n",
    "train['meslek_grubu']           = le_meslek_grubu.transform(train['meslek_grubu'])\n",
    "test['meslek_grubu']            = le_meslek_grubu.transform(test['meslek_grubu'])\n",
    "\n",
    "le_musteri                      = LabelEncoder().fit(monthly_expenditures['musteri'])\n",
    "train['musteri']                = le_musteri.transform(train['musteri'])\n",
    "test['musteri']                 = le_musteri.transform(test['musteri'])\n",
    "monthly_expenditures['musteri'] = le_musteri.transform(monthly_expenditures['musteri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplam_islem_adedi = monthly_expenditures.groupby('musteri',as_index=False)[['islem_adedi']].sum().rename(columns={'islem_adedi':'toplam_islem_adedi'})\n",
    "\n",
    "toplam_islem_tutari = monthly_expenditures.groupby('musteri',as_index=False)[['aylik_toplam_tutar']].sum().rename(columns={'aylik_toplam_tutar':'toplam_islem_tutari'})\n",
    "\n",
    "aylik_ortalama_islem_adedi = monthly_expenditures.groupby(['musteri','tarih'],as_index=False)[['islem_adedi']].sum().groupby('musteri',as_index=False)[['islem_adedi']].mean().rename(columns={'islem_adedi':'aylik_ortalama_islem_adedi'})\n",
    "\n",
    "aylik_ortalama_islem_tutari = monthly_expenditures.groupby(['musteri','tarih'],as_index=False)[['aylik_toplam_tutar']].sum().groupby('musteri',as_index=False)[['aylik_toplam_tutar']].mean().rename(columns={'aylik_toplam_tutar':'aylik_ortalama_islem_tutari'})\n",
    "\n",
    "\n",
    "musteri_bilgileri = pd.merge(pd.merge(toplam_islem_adedi,toplam_islem_tutari,on='musteri'),pd.merge(aylik_ortalama_islem_adedi,aylik_ortalama_islem_tutari,on='musteri'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.merge(train,musteri_bilgileri,on='musteri').drop(columns=['target','musteri','tarih'])\n",
    "y_train = pd.merge(train,musteri_bilgileri,on='musteri')[['target']]\n",
    "\n",
    "x_test  = pd.merge(test,musteri_bilgileri,on='musteri').drop(columns=['tarih','musteri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = train.drop(columns=['musteri']).corr()\n",
    "sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"Set3\",fmt='.1f',annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = 0\n",
    "sample_submission.to_csv('Submission/Submission_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler  = StandardScaler().fit(x_train)\n",
    "\n",
    "scaled_x_train   = standard_scaler.transform(x_train)\n",
    "scaled_x_test    = standard_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler  = RobustScaler().fit(x_train)\n",
    "\n",
    "scaled_x_train = robust_scaler.transform(x_train)\n",
    "scaled_x_test = robust_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler  = MinMaxScaler().fit(x_train)\n",
    "\n",
    "scaled_x_train = minmax_scaler.transform(x_train)\n",
    "scaled_x_test = minmax_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_over_sampling = SMOTE(random_state=1)\n",
    "x_train_resampled, y_train_resampled = smote_over_sampling.fit_sample(scaled_x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/İşBankası ML Challenge TR 3/venv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/sufyan/Desktop/İşBankası ML Challenge TR 3/venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:15:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(x_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9683592981452003"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train_resampled, xgb_classifier.predict(x_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = xgb_classifier.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-316-aee262032cd6>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_classifier.fit(x_train_resampled, y_train_resampled)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(x_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999982626522351"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train_resampled, rf_classifier.predict(x_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = rf_classifier.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\"balanced\",np.unique(y_train['target']), y_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52119527, 12.29508197])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-342-d30d36755bc2>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_classifier.fit(scaled_x_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.52119527, 1: 12.29508197})"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(class_weight={1:12.29508197, 0:0.52119527})\n",
    "\n",
    "rf_classifier.fit(scaled_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995903318312167"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, rf_classifier.predict(scaled_x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = rf_classifier.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(scaled_x_train.shape[1],)),\n",
    "keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "keras.layers.Dense(90, activation=tf.nn.relu),\n",
    "keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "keras.layers.Dense(30, activation=tf.nn.relu),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 60)                1860      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 90)                5490      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 15,002\n",
      "Trainable params: 15,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "47168/48000 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/İşBankası ML Challenge TR 3/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1634 - accuracy: 0.9588 - val_loss: 0.1596 - val_accuracy: 0.9596\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1570 - accuracy: 0.9593 - val_loss: 0.1549 - val_accuracy: 0.9596\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1566 - accuracy: 0.9593 - val_loss: 0.1544 - val_accuracy: 0.9596\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 2s 31us/sample - loss: 0.1563 - accuracy: 0.9593 - val_loss: 0.1547 - val_accuracy: 0.9596\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1556 - accuracy: 0.9593 - val_loss: 0.1561 - val_accuracy: 0.9596\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1554 - accuracy: 0.9593 - val_loss: 0.1549 - val_accuracy: 0.9596\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1551 - accuracy: 0.9593 - val_loss: 0.1547 - val_accuracy: 0.9596\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1550 - accuracy: 0.9593 - val_loss: 0.1546 - val_accuracy: 0.9596\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1543 - accuracy: 0.9593 - val_loss: 0.1564 - val_accuracy: 0.9596\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1542 - accuracy: 0.9593 - val_loss: 0.1546 - val_accuracy: 0.9596\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1541 - accuracy: 0.9593 - val_loss: 0.1542 - val_accuracy: 0.9596\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.1539 - accuracy: 0.9593 - val_loss: 0.1545 - val_accuracy: 0.9596\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1535 - accuracy: 0.9593 - val_loss: 0.1544 - val_accuracy: 0.9596\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1533 - accuracy: 0.9593 - val_loss: 0.1547 - val_accuracy: 0.9596\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1531 - accuracy: 0.9593 - val_loss: 0.1554 - val_accuracy: 0.9596\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1530 - accuracy: 0.9593 - val_loss: 0.1562 - val_accuracy: 0.9596\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1525 - accuracy: 0.9593 - val_loss: 0.1564 - val_accuracy: 0.9596\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1526 - accuracy: 0.9593 - val_loss: 0.1547 - val_accuracy: 0.9596\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.1521 - accuracy: 0.9593 - val_loss: 0.1549 - val_accuracy: 0.9596\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1517 - accuracy: 0.9593 - val_loss: 0.1553 - val_accuracy: 0.9596\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1516 - accuracy: 0.9593 - val_loss: 0.1555 - val_accuracy: 0.9596\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1513 - accuracy: 0.9593 - val_loss: 0.1554 - val_accuracy: 0.9596\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1512 - accuracy: 0.9593 - val_loss: 0.1557 - val_accuracy: 0.9596\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1509 - accuracy: 0.9593 - val_loss: 0.1568 - val_accuracy: 0.9596\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1505 - accuracy: 0.9592 - val_loss: 0.1579 - val_accuracy: 0.9588\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.1505 - accuracy: 0.9593 - val_loss: 0.1568 - val_accuracy: 0.9596\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1500 - accuracy: 0.9592 - val_loss: 0.1558 - val_accuracy: 0.9596\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1499 - accuracy: 0.9593 - val_loss: 0.1583 - val_accuracy: 0.9596\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1494 - accuracy: 0.9593 - val_loss: 0.1581 - val_accuracy: 0.9596\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1493 - accuracy: 0.9592 - val_loss: 0.1582 - val_accuracy: 0.9594\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1493 - accuracy: 0.9593 - val_loss: 0.1622 - val_accuracy: 0.9595\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1491 - accuracy: 0.9592 - val_loss: 0.1577 - val_accuracy: 0.9594\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1487 - accuracy: 0.9593 - val_loss: 0.1602 - val_accuracy: 0.9591\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1487 - accuracy: 0.9592 - val_loss: 0.1599 - val_accuracy: 0.9593\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1481 - accuracy: 0.9593 - val_loss: 0.1594 - val_accuracy: 0.9593\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1481 - accuracy: 0.9593 - val_loss: 0.1579 - val_accuracy: 0.9594\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1477 - accuracy: 0.9593 - val_loss: 0.1604 - val_accuracy: 0.9596\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1473 - accuracy: 0.9595 - val_loss: 0.1593 - val_accuracy: 0.9593\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1470 - accuracy: 0.9592 - val_loss: 0.1629 - val_accuracy: 0.9595\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1467 - accuracy: 0.9593 - val_loss: 0.1607 - val_accuracy: 0.9590\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1464 - accuracy: 0.9595 - val_loss: 0.1612 - val_accuracy: 0.9586\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1462 - accuracy: 0.9594 - val_loss: 0.1609 - val_accuracy: 0.9593\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1458 - accuracy: 0.9593 - val_loss: 0.1645 - val_accuracy: 0.9590\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.1459 - accuracy: 0.9594 - val_loss: 0.1640 - val_accuracy: 0.9592\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1453 - accuracy: 0.9595 - val_loss: 0.1628 - val_accuracy: 0.9584\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 2s 43us/sample - loss: 0.1451 - accuracy: 0.9594 - val_loss: 0.1660 - val_accuracy: 0.9582\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1450 - accuracy: 0.9597 - val_loss: 0.1627 - val_accuracy: 0.9590\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.1447 - accuracy: 0.9595 - val_loss: 0.1644 - val_accuracy: 0.9593\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1446 - accuracy: 0.9597 - val_loss: 0.1628 - val_accuracy: 0.9589\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1439 - accuracy: 0.9596 - val_loss: 0.1662 - val_accuracy: 0.9582\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 2s 43us/sample - loss: 0.1443 - accuracy: 0.9597 - val_loss: 0.1660 - val_accuracy: 0.9579\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1439 - accuracy: 0.9595 - val_loss: 0.1638 - val_accuracy: 0.9586\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1434 - accuracy: 0.9597 - val_loss: 0.1648 - val_accuracy: 0.9580\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1432 - accuracy: 0.9597 - val_loss: 0.1645 - val_accuracy: 0.9586\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.1431 - accuracy: 0.9596 - val_loss: 0.1684 - val_accuracy: 0.9586\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1424 - accuracy: 0.9597 - val_loss: 0.1675 - val_accuracy: 0.9581\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1429 - accuracy: 0.9597 - val_loss: 0.1667 - val_accuracy: 0.9577\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1422 - accuracy: 0.9599 - val_loss: 0.1726 - val_accuracy: 0.9591\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1417 - accuracy: 0.9599 - val_loss: 0.1660 - val_accuracy: 0.9576\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1418 - accuracy: 0.9598 - val_loss: 0.1676 - val_accuracy: 0.9589\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1413 - accuracy: 0.9600 - val_loss: 0.1705 - val_accuracy: 0.9577\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1410 - accuracy: 0.9599 - val_loss: 0.1698 - val_accuracy: 0.9588\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1407 - accuracy: 0.9600 - val_loss: 0.1705 - val_accuracy: 0.9582\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1407 - accuracy: 0.9601 - val_loss: 0.1728 - val_accuracy: 0.9582\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1406 - accuracy: 0.9600 - val_loss: 0.1702 - val_accuracy: 0.9585\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1405 - accuracy: 0.9600 - val_loss: 0.1701 - val_accuracy: 0.9584\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1399 - accuracy: 0.9600 - val_loss: 0.1732 - val_accuracy: 0.9579\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1397 - accuracy: 0.9601 - val_loss: 0.1696 - val_accuracy: 0.9577\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 2s 46us/sample - loss: 0.1389 - accuracy: 0.9601 - val_loss: 0.1696 - val_accuracy: 0.9588\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1391 - accuracy: 0.9602 - val_loss: 0.1687 - val_accuracy: 0.9589\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.1387 - accuracy: 0.9603 - val_loss: 0.1754 - val_accuracy: 0.9574\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1388 - accuracy: 0.9602 - val_loss: 0.1762 - val_accuracy: 0.9584\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 2s 48us/sample - loss: 0.1385 - accuracy: 0.9603 - val_loss: 0.1711 - val_accuracy: 0.9586\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.1377 - accuracy: 0.9603 - val_loss: 0.1761 - val_accuracy: 0.9582\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1374 - accuracy: 0.9603 - val_loss: 0.1755 - val_accuracy: 0.9576\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.1372 - accuracy: 0.9603 - val_loss: 0.1791 - val_accuracy: 0.9578\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1369 - accuracy: 0.9604 - val_loss: 0.1758 - val_accuracy: 0.9577\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1373 - accuracy: 0.9604 - val_loss: 0.1724 - val_accuracy: 0.9586\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1368 - accuracy: 0.9605 - val_loss: 0.1755 - val_accuracy: 0.9570\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 2s 48us/sample - loss: 0.1366 - accuracy: 0.9604 - val_loss: 0.1752 - val_accuracy: 0.9578\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.1360 - accuracy: 0.9606 - val_loss: 0.1759 - val_accuracy: 0.9575\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 3s 54us/sample - loss: 0.1357 - accuracy: 0.9606 - val_loss: 0.1807 - val_accuracy: 0.9577\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 2s 46us/sample - loss: 0.1360 - accuracy: 0.9606 - val_loss: 0.1781 - val_accuracy: 0.9572\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1358 - accuracy: 0.9604 - val_loss: 0.1772 - val_accuracy: 0.9576\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 2s 43us/sample - loss: 0.1356 - accuracy: 0.9607 - val_loss: 0.1736 - val_accuracy: 0.9577\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1352 - accuracy: 0.9609 - val_loss: 0.1768 - val_accuracy: 0.9582\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.1350 - accuracy: 0.9607 - val_loss: 0.1807 - val_accuracy: 0.9578\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1349 - accuracy: 0.9607 - val_loss: 0.1806 - val_accuracy: 0.9573\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1342 - accuracy: 0.9607 - val_loss: 0.1779 - val_accuracy: 0.9568\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1347 - accuracy: 0.9606 - val_loss: 0.1830 - val_accuracy: 0.9573\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.1340 - accuracy: 0.9607 - val_loss: 0.1795 - val_accuracy: 0.9578\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1337 - accuracy: 0.9608 - val_loss: 0.1841 - val_accuracy: 0.9586\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 2s 45us/sample - loss: 0.1339 - accuracy: 0.9606 - val_loss: 0.1914 - val_accuracy: 0.9581\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1335 - accuracy: 0.9609 - val_loss: 0.1885 - val_accuracy: 0.9576\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 0.1333 - accuracy: 0.9608 - val_loss: 0.1851 - val_accuracy: 0.9578\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 2s 48us/sample - loss: 0.1333 - accuracy: 0.9610 - val_loss: 0.1817 - val_accuracy: 0.9580\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 2s 49us/sample - loss: 0.1334 - accuracy: 0.9608 - val_loss: 0.1824 - val_accuracy: 0.9573\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 2s 48us/sample - loss: 0.1327 - accuracy: 0.9611 - val_loss: 0.1836 - val_accuracy: 0.9575\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1332 - accuracy: 0.9608 - val_loss: 0.1783 - val_accuracy: 0.9573\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.1318 - accuracy: 0.9612 - val_loss: 0.1850 - val_accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(scaled_x_train, y_train['target'].values, epochs=100,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(scaled_x_train)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_5.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "keras.layers.Dense(90, activation=tf.nn.relu),\n",
    "keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "keras.layers.Dense(30, activation=tf.nn.relu),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 60)                1860      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 90)                5490      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 15,002\n",
      "Trainable params: 15,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92096 samples, validate on 23024 samples\n",
      "Epoch 1/100\n",
      "91648/92096 [============================>.] - ETA: 0s - loss: 0.5618 - accuracy: 0.7032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/İşBankası ML Challenge TR 3/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92096/92096 [==============================] - 4s 40us/sample - loss: 0.5618 - accuracy: 0.7033 - val_loss: 0.5419 - val_accuracy: 0.7187\n",
      "Epoch 2/100\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5360 - accuracy: 0.7212 - val_loss: 0.5317 - val_accuracy: 0.7272\n",
      "Epoch 3/100\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.5173 - accuracy: 0.7345 - val_loss: 0.5056 - val_accuracy: 0.7432\n",
      "Epoch 4/100\n",
      "92096/92096 [==============================] - 4s 38us/sample - loss: 0.4980 - accuracy: 0.7457 - val_loss: 0.4891 - val_accuracy: 0.7522\n",
      "Epoch 5/100\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4834 - accuracy: 0.7553 - val_loss: 0.4842 - val_accuracy: 0.7532\n",
      "Epoch 6/100\n",
      "92096/92096 [==============================] - 4s 40us/sample - loss: 0.4674 - accuracy: 0.7664 - val_loss: 0.4631 - val_accuracy: 0.7718\n",
      "Epoch 7/100\n",
      "92096/92096 [==============================] - 3s 38us/sample - loss: 0.4522 - accuracy: 0.7773 - val_loss: 0.4528 - val_accuracy: 0.7779\n",
      "Epoch 8/100\n",
      "92096/92096 [==============================] - 4s 39us/sample - loss: 0.4382 - accuracy: 0.7866 - val_loss: 0.4412 - val_accuracy: 0.7874\n",
      "Epoch 9/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.4248 - accuracy: 0.7957 - val_loss: 0.4281 - val_accuracy: 0.7950\n",
      "Epoch 10/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.4145 - accuracy: 0.8024 - val_loss: 0.4196 - val_accuracy: 0.8043\n",
      "Epoch 11/100\n",
      "92096/92096 [==============================] - 4s 41us/sample - loss: 0.4032 - accuracy: 0.8095 - val_loss: 0.4052 - val_accuracy: 0.8122\n",
      "Epoch 12/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.3940 - accuracy: 0.8168 - val_loss: 0.4093 - val_accuracy: 0.8110\n",
      "Epoch 13/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.3837 - accuracy: 0.8218 - val_loss: 0.4024 - val_accuracy: 0.8136\n",
      "Epoch 14/100\n",
      "92096/92096 [==============================] - 4s 42us/sample - loss: 0.3747 - accuracy: 0.8279 - val_loss: 0.3885 - val_accuracy: 0.8212\n",
      "Epoch 15/100\n",
      "92096/92096 [==============================] - 4s 49us/sample - loss: 0.3675 - accuracy: 0.8329 - val_loss: 0.3892 - val_accuracy: 0.8240\n",
      "Epoch 16/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.3600 - accuracy: 0.8367 - val_loss: 0.3824 - val_accuracy: 0.8250\n",
      "Epoch 17/100\n",
      "92096/92096 [==============================] - 4s 42us/sample - loss: 0.3531 - accuracy: 0.8420 - val_loss: 0.3614 - val_accuracy: 0.8396\n",
      "Epoch 18/100\n",
      "92096/92096 [==============================] - 3s 38us/sample - loss: 0.3465 - accuracy: 0.8450 - val_loss: 0.3771 - val_accuracy: 0.8292\n",
      "Epoch 19/100\n",
      "92096/92096 [==============================] - 4s 38us/sample - loss: 0.3383 - accuracy: 0.8497 - val_loss: 0.3640 - val_accuracy: 0.8364\n",
      "Epoch 20/100\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.3348 - accuracy: 0.8514 - val_loss: 0.3650 - val_accuracy: 0.8399\n",
      "Epoch 21/100\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.3268 - accuracy: 0.8556 - val_loss: 0.3513 - val_accuracy: 0.8455\n",
      "Epoch 22/100\n",
      "92096/92096 [==============================] - 4s 40us/sample - loss: 0.3239 - accuracy: 0.8576 - val_loss: 0.3752 - val_accuracy: 0.8327\n",
      "Epoch 23/100\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.3190 - accuracy: 0.8608 - val_loss: 0.3631 - val_accuracy: 0.8425\n",
      "Epoch 24/100\n",
      "92096/92096 [==============================] - 3s 33us/sample - loss: 0.3153 - accuracy: 0.8621 - val_loss: 0.3587 - val_accuracy: 0.8440\n",
      "Epoch 25/100\n",
      "92096/92096 [==============================] - 3s 36us/sample - loss: 0.3098 - accuracy: 0.8652 - val_loss: 0.3492 - val_accuracy: 0.8476\n",
      "Epoch 26/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.3060 - accuracy: 0.8686 - val_loss: 0.3513 - val_accuracy: 0.8482\n",
      "Epoch 27/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.3015 - accuracy: 0.8700 - val_loss: 0.3446 - val_accuracy: 0.8492\n",
      "Epoch 28/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.2979 - accuracy: 0.8715 - val_loss: 0.3477 - val_accuracy: 0.8525\n",
      "Epoch 29/100\n",
      "92096/92096 [==============================] - 4s 42us/sample - loss: 0.2946 - accuracy: 0.8738 - val_loss: 0.3432 - val_accuracy: 0.8524\n",
      "Epoch 30/100\n",
      "92096/92096 [==============================] - 5s 53us/sample - loss: 0.2906 - accuracy: 0.8762 - val_loss: 0.3382 - val_accuracy: 0.8592\n",
      "Epoch 31/100\n",
      "92096/92096 [==============================] - 4s 49us/sample - loss: 0.2885 - accuracy: 0.8768 - val_loss: 0.3410 - val_accuracy: 0.8566\n",
      "Epoch 32/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2851 - accuracy: 0.8796 - val_loss: 0.3233 - val_accuracy: 0.8665\n",
      "Epoch 33/100\n",
      "92096/92096 [==============================] - 5s 50us/sample - loss: 0.2806 - accuracy: 0.8812 - val_loss: 0.3339 - val_accuracy: 0.8593\n",
      "Epoch 34/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.2786 - accuracy: 0.8825 - val_loss: 0.3258 - val_accuracy: 0.8633\n",
      "Epoch 35/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2777 - accuracy: 0.8823 - val_loss: 0.3265 - val_accuracy: 0.8631\n",
      "Epoch 36/100\n",
      "92096/92096 [==============================] - 4s 44us/sample - loss: 0.2717 - accuracy: 0.8862 - val_loss: 0.3202 - val_accuracy: 0.8652\n",
      "Epoch 37/100\n",
      "92096/92096 [==============================] - 4s 44us/sample - loss: 0.2715 - accuracy: 0.8864 - val_loss: 0.3284 - val_accuracy: 0.8646\n",
      "Epoch 38/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.2699 - accuracy: 0.8866 - val_loss: 0.3182 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2670 - accuracy: 0.8874 - val_loss: 0.3154 - val_accuracy: 0.8688\n",
      "Epoch 40/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2647 - accuracy: 0.8894 - val_loss: 0.3116 - val_accuracy: 0.8694\n",
      "Epoch 41/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.2618 - accuracy: 0.8910 - val_loss: 0.3246 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.2596 - accuracy: 0.8917 - val_loss: 0.3205 - val_accuracy: 0.8671\n",
      "Epoch 43/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2579 - accuracy: 0.8919 - val_loss: 0.3090 - val_accuracy: 0.8720\n",
      "Epoch 44/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.2561 - accuracy: 0.8934 - val_loss: 0.3197 - val_accuracy: 0.8696\n",
      "Epoch 45/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.2524 - accuracy: 0.8958 - val_loss: 0.3124 - val_accuracy: 0.8730\n",
      "Epoch 46/100\n",
      "92096/92096 [==============================] - 5s 50us/sample - loss: 0.2522 - accuracy: 0.8953 - val_loss: 0.3197 - val_accuracy: 0.8697\n",
      "Epoch 47/100\n",
      "92096/92096 [==============================] - 5s 53us/sample - loss: 0.2505 - accuracy: 0.8963 - val_loss: 0.3270 - val_accuracy: 0.8673\n",
      "Epoch 48/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2498 - accuracy: 0.8966 - val_loss: 0.3140 - val_accuracy: 0.8732\n",
      "Epoch 49/100\n",
      "92096/92096 [==============================] - 5s 59us/sample - loss: 0.2457 - accuracy: 0.8981 - val_loss: 0.3135 - val_accuracy: 0.8763\n",
      "Epoch 50/100\n",
      "92096/92096 [==============================] - 4s 49us/sample - loss: 0.2454 - accuracy: 0.8984 - val_loss: 0.3138 - val_accuracy: 0.8765\n",
      "Epoch 51/100\n",
      "92096/92096 [==============================] - 5s 54us/sample - loss: 0.2430 - accuracy: 0.8991 - val_loss: 0.3087 - val_accuracy: 0.8769\n",
      "Epoch 52/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2415 - accuracy: 0.9007 - val_loss: 0.3002 - val_accuracy: 0.8796\n",
      "Epoch 53/100\n",
      "92096/92096 [==============================] - 5s 56us/sample - loss: 0.2388 - accuracy: 0.9021 - val_loss: 0.3176 - val_accuracy: 0.8744\n",
      "Epoch 54/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2394 - accuracy: 0.9020 - val_loss: 0.3078 - val_accuracy: 0.8790\n",
      "Epoch 55/100\n",
      "92096/92096 [==============================] - 6s 60us/sample - loss: 0.2375 - accuracy: 0.9018 - val_loss: 0.3082 - val_accuracy: 0.8792\n",
      "Epoch 56/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2330 - accuracy: 0.9043 - val_loss: 0.3122 - val_accuracy: 0.8771\n",
      "Epoch 57/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2360 - accuracy: 0.9024 - val_loss: 0.3093 - val_accuracy: 0.8791\n",
      "Epoch 58/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2311 - accuracy: 0.9054 - val_loss: 0.3084 - val_accuracy: 0.8783\n",
      "Epoch 59/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2307 - accuracy: 0.9057 - val_loss: 0.3094 - val_accuracy: 0.8813\n",
      "Epoch 60/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.2302 - accuracy: 0.9061 - val_loss: 0.3021 - val_accuracy: 0.8842\n",
      "Epoch 61/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2283 - accuracy: 0.9072 - val_loss: 0.3001 - val_accuracy: 0.8816\n",
      "Epoch 62/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2286 - accuracy: 0.9063 - val_loss: 0.3054 - val_accuracy: 0.8788\n",
      "Epoch 63/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.2254 - accuracy: 0.9085 - val_loss: 0.3074 - val_accuracy: 0.8796\n",
      "Epoch 64/100\n",
      "92096/92096 [==============================] - 5s 50us/sample - loss: 0.2238 - accuracy: 0.9089 - val_loss: 0.3049 - val_accuracy: 0.8807\n",
      "Epoch 65/100\n",
      "92096/92096 [==============================] - 5s 51us/sample - loss: 0.2218 - accuracy: 0.9098 - val_loss: 0.3020 - val_accuracy: 0.8839\n",
      "Epoch 66/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2228 - accuracy: 0.9093 - val_loss: 0.3212 - val_accuracy: 0.8770\n",
      "Epoch 67/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2187 - accuracy: 0.9111 - val_loss: 0.3077 - val_accuracy: 0.8807\n",
      "Epoch 68/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.2182 - accuracy: 0.9120 - val_loss: 0.3105 - val_accuracy: 0.8773\n",
      "Epoch 69/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.2180 - accuracy: 0.9124 - val_loss: 0.3036 - val_accuracy: 0.8839\n",
      "Epoch 70/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.2170 - accuracy: 0.9123 - val_loss: 0.3011 - val_accuracy: 0.8839\n",
      "Epoch 71/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.2160 - accuracy: 0.9126 - val_loss: 0.2946 - val_accuracy: 0.8848\n",
      "Epoch 72/100\n",
      "92096/92096 [==============================] - 5s 49us/sample - loss: 0.2162 - accuracy: 0.9121 - val_loss: 0.2903 - val_accuracy: 0.8873\n",
      "Epoch 73/100\n",
      "92096/92096 [==============================] - 5s 59us/sample - loss: 0.2126 - accuracy: 0.9137 - val_loss: 0.3005 - val_accuracy: 0.8864\n",
      "Epoch 74/100\n",
      "92096/92096 [==============================] - 5s 56us/sample - loss: 0.2116 - accuracy: 0.9143 - val_loss: 0.2989 - val_accuracy: 0.8896\n",
      "Epoch 75/100\n",
      "92096/92096 [==============================] - 6s 64us/sample - loss: 0.2125 - accuracy: 0.9149 - val_loss: 0.3013 - val_accuracy: 0.8851\n",
      "Epoch 76/100\n",
      "92096/92096 [==============================] - 5s 54us/sample - loss: 0.2099 - accuracy: 0.9160 - val_loss: 0.3025 - val_accuracy: 0.8873\n",
      "Epoch 77/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.2093 - accuracy: 0.9160 - val_loss: 0.2891 - val_accuracy: 0.8911\n",
      "Epoch 78/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.2100 - accuracy: 0.9151 - val_loss: 0.2995 - val_accuracy: 0.8880\n",
      "Epoch 79/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.2090 - accuracy: 0.9162 - val_loss: 0.2917 - val_accuracy: 0.8900\n",
      "Epoch 80/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.2064 - accuracy: 0.9172 - val_loss: 0.2916 - val_accuracy: 0.8901\n",
      "Epoch 81/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.2044 - accuracy: 0.9177 - val_loss: 0.2953 - val_accuracy: 0.8887\n",
      "Epoch 82/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.2047 - accuracy: 0.9178 - val_loss: 0.2947 - val_accuracy: 0.8931\n",
      "Epoch 83/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.2021 - accuracy: 0.9194 - val_loss: 0.3024 - val_accuracy: 0.8854\n",
      "Epoch 84/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2031 - accuracy: 0.9189 - val_loss: 0.3118 - val_accuracy: 0.8850\n",
      "Epoch 85/100\n",
      "92096/92096 [==============================] - 5s 52us/sample - loss: 0.2025 - accuracy: 0.9198 - val_loss: 0.2950 - val_accuracy: 0.8882\n",
      "Epoch 86/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.1992 - accuracy: 0.9194 - val_loss: 0.2903 - val_accuracy: 0.8912\n",
      "Epoch 87/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.1988 - accuracy: 0.9201 - val_loss: 0.3118 - val_accuracy: 0.8872\n",
      "Epoch 88/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.1989 - accuracy: 0.9201 - val_loss: 0.2981 - val_accuracy: 0.8893\n",
      "Epoch 89/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.1986 - accuracy: 0.9212 - val_loss: 0.2951 - val_accuracy: 0.8917\n",
      "Epoch 90/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.1971 - accuracy: 0.9218 - val_loss: 0.2979 - val_accuracy: 0.8915\n",
      "Epoch 91/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.1984 - accuracy: 0.9203 - val_loss: 0.3069 - val_accuracy: 0.8865\n",
      "Epoch 92/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.1954 - accuracy: 0.9217 - val_loss: 0.2939 - val_accuracy: 0.8917\n",
      "Epoch 93/100\n",
      "92096/92096 [==============================] - 4s 45us/sample - loss: 0.1939 - accuracy: 0.9219 - val_loss: 0.3000 - val_accuracy: 0.8884\n",
      "Epoch 94/100\n",
      "92096/92096 [==============================] - 4s 44us/sample - loss: 0.1930 - accuracy: 0.9224 - val_loss: 0.2899 - val_accuracy: 0.8932\n",
      "Epoch 95/100\n",
      "92096/92096 [==============================] - 4s 44us/sample - loss: 0.1928 - accuracy: 0.9228 - val_loss: 0.3002 - val_accuracy: 0.8915\n",
      "Epoch 96/100\n",
      "92096/92096 [==============================] - 4s 48us/sample - loss: 0.1928 - accuracy: 0.9226 - val_loss: 0.2934 - val_accuracy: 0.8895\n",
      "Epoch 97/100\n",
      "92096/92096 [==============================] - 4s 47us/sample - loss: 0.1912 - accuracy: 0.9249 - val_loss: 0.3048 - val_accuracy: 0.8875\n",
      "Epoch 98/100\n",
      "92096/92096 [==============================] - 4s 49us/sample - loss: 0.1897 - accuracy: 0.9251 - val_loss: 0.2993 - val_accuracy: 0.8919\n",
      "Epoch 99/100\n",
      "92096/92096 [==============================] - 4s 46us/sample - loss: 0.1912 - accuracy: 0.9244 - val_loss: 0.2994 - val_accuracy: 0.8943\n",
      "Epoch 100/100\n",
      "92096/92096 [==============================] - 4s 43us/sample - loss: 0.1900 - accuracy: 0.9245 - val_loss: 0.2942 - val_accuracy: 0.8915\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(shuffle(pd.DataFrame(x_train_resampled),random_state=1), shuffle(pd.DataFrame(y_train_resampled),random_state=1), epochs=100,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/İşBankası ML Challenge TR 3/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "train_predictions = model.predict(x_train_resampled)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_6.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(30, activation=tf.nn.relu,input_shape=(x_train_resampled.shape[1],)),\n",
    "keras.layers.Dense(30, activation=tf.nn.relu),\n",
    "keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 30)                300       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 1,292\n",
      "Trainable params: 1,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92096 samples, validate on 23024 samples\n",
      "Epoch 1/500\n",
      "90944/92096 [============================>.] - ETA: 0s - loss: 0.5734 - accuracy: 0.6922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sufyan/Desktop/İşBankası ML Challenge TR 3/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.5732 - accuracy: 0.6925 - val_loss: 0.5591 - val_accuracy: 0.7070\n",
      "Epoch 2/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5548 - accuracy: 0.7093 - val_loss: 0.5484 - val_accuracy: 0.7138\n",
      "Epoch 3/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5484 - accuracy: 0.7146 - val_loss: 0.5445 - val_accuracy: 0.7179\n",
      "Epoch 4/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5432 - accuracy: 0.7182 - val_loss: 0.5430 - val_accuracy: 0.7191\n",
      "Epoch 5/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5390 - accuracy: 0.7205 - val_loss: 0.5351 - val_accuracy: 0.7204\n",
      "Epoch 6/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5350 - accuracy: 0.7226 - val_loss: 0.5315 - val_accuracy: 0.7256\n",
      "Epoch 7/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5315 - accuracy: 0.7261 - val_loss: 0.5320 - val_accuracy: 0.7249\n",
      "Epoch 8/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5278 - accuracy: 0.7293 - val_loss: 0.5278 - val_accuracy: 0.7302\n",
      "Epoch 9/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5248 - accuracy: 0.7304 - val_loss: 0.5222 - val_accuracy: 0.7371\n",
      "Epoch 10/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5218 - accuracy: 0.7332 - val_loss: 0.5204 - val_accuracy: 0.7365\n",
      "Epoch 11/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5190 - accuracy: 0.7357 - val_loss: 0.5222 - val_accuracy: 0.7331\n",
      "Epoch 12/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.5162 - accuracy: 0.7379 - val_loss: 0.5178 - val_accuracy: 0.7372\n",
      "Epoch 13/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.5137 - accuracy: 0.7397 - val_loss: 0.5189 - val_accuracy: 0.7354\n",
      "Epoch 14/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5113 - accuracy: 0.7403 - val_loss: 0.5163 - val_accuracy: 0.7426\n",
      "Epoch 15/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5096 - accuracy: 0.7421 - val_loss: 0.5111 - val_accuracy: 0.7433\n",
      "Epoch 16/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5069 - accuracy: 0.7435 - val_loss: 0.5096 - val_accuracy: 0.7436\n",
      "Epoch 17/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5048 - accuracy: 0.7458 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 18/500\n",
      "92096/92096 [==============================] - 2s 24us/sample - loss: 0.5027 - accuracy: 0.7463 - val_loss: 0.5065 - val_accuracy: 0.7483\n",
      "Epoch 19/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.5004 - accuracy: 0.7482 - val_loss: 0.5045 - val_accuracy: 0.7508\n",
      "Epoch 20/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4984 - accuracy: 0.7516 - val_loss: 0.5033 - val_accuracy: 0.7492\n",
      "Epoch 21/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4967 - accuracy: 0.7520 - val_loss: 0.5007 - val_accuracy: 0.7530\n",
      "Epoch 22/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4947 - accuracy: 0.7530 - val_loss: 0.4998 - val_accuracy: 0.7513\n",
      "Epoch 23/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4934 - accuracy: 0.7553 - val_loss: 0.4964 - val_accuracy: 0.7571\n",
      "Epoch 24/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4926 - accuracy: 0.7556 - val_loss: 0.4937 - val_accuracy: 0.7596\n",
      "Epoch 25/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4900 - accuracy: 0.7566 - val_loss: 0.4954 - val_accuracy: 0.7565\n",
      "Epoch 26/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4896 - accuracy: 0.7569 - val_loss: 0.4966 - val_accuracy: 0.7545\n",
      "Epoch 27/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4881 - accuracy: 0.7583 - val_loss: 0.4954 - val_accuracy: 0.7516\n",
      "Epoch 28/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4872 - accuracy: 0.7584 - val_loss: 0.4921 - val_accuracy: 0.7598\n",
      "Epoch 29/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4864 - accuracy: 0.7593 - val_loss: 0.4884 - val_accuracy: 0.7605\n",
      "Epoch 30/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4850 - accuracy: 0.7605 - val_loss: 0.4881 - val_accuracy: 0.7596\n",
      "Epoch 31/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4840 - accuracy: 0.7603 - val_loss: 0.4877 - val_accuracy: 0.7623\n",
      "Epoch 32/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4833 - accuracy: 0.7612 - val_loss: 0.4909 - val_accuracy: 0.7580\n",
      "Epoch 33/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4818 - accuracy: 0.7618 - val_loss: 0.4901 - val_accuracy: 0.7556\n",
      "Epoch 34/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4808 - accuracy: 0.7624 - val_loss: 0.4886 - val_accuracy: 0.7583\n",
      "Epoch 35/500\n",
      "92096/92096 [==============================] - 2s 25us/sample - loss: 0.4806 - accuracy: 0.7627 - val_loss: 0.4881 - val_accuracy: 0.7609\n",
      "Epoch 36/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4803 - accuracy: 0.7630 - val_loss: 0.4877 - val_accuracy: 0.7616\n",
      "Epoch 37/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4783 - accuracy: 0.7638 - val_loss: 0.4862 - val_accuracy: 0.7597\n",
      "Epoch 38/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.4786 - accuracy: 0.7642 - val_loss: 0.4819 - val_accuracy: 0.7660\n",
      "Epoch 39/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4775 - accuracy: 0.7647 - val_loss: 0.4859 - val_accuracy: 0.7620\n",
      "Epoch 40/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4764 - accuracy: 0.7653 - val_loss: 0.4811 - val_accuracy: 0.7609\n",
      "Epoch 41/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4763 - accuracy: 0.7651 - val_loss: 0.4819 - val_accuracy: 0.7613\n",
      "Epoch 42/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.4755 - accuracy: 0.7655 - val_loss: 0.4836 - val_accuracy: 0.7615\n",
      "Epoch 43/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4748 - accuracy: 0.7656 - val_loss: 0.4783 - val_accuracy: 0.7659\n",
      "Epoch 44/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4742 - accuracy: 0.7665 - val_loss: 0.4781 - val_accuracy: 0.7662\n",
      "Epoch 45/500\n",
      "92096/92096 [==============================] - 3s 27us/sample - loss: 0.4736 - accuracy: 0.7663 - val_loss: 0.4823 - val_accuracy: 0.7651\n",
      "Epoch 46/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4732 - accuracy: 0.7669 - val_loss: 0.4758 - val_accuracy: 0.7701\n",
      "Epoch 47/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4716 - accuracy: 0.7680 - val_loss: 0.4792 - val_accuracy: 0.7685\n",
      "Epoch 48/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4718 - accuracy: 0.7683 - val_loss: 0.4781 - val_accuracy: 0.7688\n",
      "Epoch 49/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.4708 - accuracy: 0.7701 - val_loss: 0.4770 - val_accuracy: 0.7681\n",
      "Epoch 50/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.4705 - accuracy: 0.7698 - val_loss: 0.4790 - val_accuracy: 0.7647\n",
      "Epoch 51/500\n",
      "92096/92096 [==============================] - 3s 28us/sample - loss: 0.4703 - accuracy: 0.7694 - val_loss: 0.4814 - val_accuracy: 0.7657\n",
      "Epoch 52/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4696 - accuracy: 0.7695 - val_loss: 0.4828 - val_accuracy: 0.7622\n",
      "Epoch 53/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4694 - accuracy: 0.7684 - val_loss: 0.4755 - val_accuracy: 0.7675\n",
      "Epoch 54/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4688 - accuracy: 0.7707 - val_loss: 0.4769 - val_accuracy: 0.7696\n",
      "Epoch 55/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4681 - accuracy: 0.7704 - val_loss: 0.4754 - val_accuracy: 0.7705\n",
      "Epoch 56/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4681 - accuracy: 0.7706 - val_loss: 0.4745 - val_accuracy: 0.7692\n",
      "Epoch 57/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4678 - accuracy: 0.7704 - val_loss: 0.4731 - val_accuracy: 0.7721\n",
      "Epoch 58/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4669 - accuracy: 0.7723 - val_loss: 0.4738 - val_accuracy: 0.7725\n",
      "Epoch 59/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4666 - accuracy: 0.7721 - val_loss: 0.4766 - val_accuracy: 0.7674\n",
      "Epoch 60/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4669 - accuracy: 0.7712 - val_loss: 0.4798 - val_accuracy: 0.7659\n",
      "Epoch 61/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4659 - accuracy: 0.7712 - val_loss: 0.4727 - val_accuracy: 0.7698\n",
      "Epoch 62/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4653 - accuracy: 0.7730 - val_loss: 0.4767 - val_accuracy: 0.7718\n",
      "Epoch 63/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4651 - accuracy: 0.7733 - val_loss: 0.4747 - val_accuracy: 0.7693\n",
      "Epoch 64/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4649 - accuracy: 0.7732 - val_loss: 0.4687 - val_accuracy: 0.7734\n",
      "Epoch 65/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4646 - accuracy: 0.7734 - val_loss: 0.4678 - val_accuracy: 0.7747\n",
      "Epoch 66/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4643 - accuracy: 0.7741 - val_loss: 0.4754 - val_accuracy: 0.7726\n",
      "Epoch 67/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.4721 - val_accuracy: 0.7730\n",
      "Epoch 68/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4636 - accuracy: 0.7740 - val_loss: 0.4695 - val_accuracy: 0.7697\n",
      "Epoch 69/500\n",
      "92096/92096 [==============================] - 2s 27us/sample - loss: 0.4637 - accuracy: 0.7734 - val_loss: 0.4795 - val_accuracy: 0.7634\n",
      "Epoch 70/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4635 - accuracy: 0.7750 - val_loss: 0.4697 - val_accuracy: 0.7735\n",
      "Epoch 71/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4622 - accuracy: 0.7746 - val_loss: 0.4747 - val_accuracy: 0.7704\n",
      "Epoch 72/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4699 - val_accuracy: 0.7699\n",
      "Epoch 73/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4632 - accuracy: 0.7759 - val_loss: 0.4705 - val_accuracy: 0.7739\n",
      "Epoch 74/500\n",
      "92096/92096 [==============================] - 2s 26us/sample - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4727 - val_accuracy: 0.7691\n",
      "Epoch 75/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4617 - accuracy: 0.7754 - val_loss: 0.4770 - val_accuracy: 0.7641\n",
      "Epoch 76/500\n",
      "92096/92096 [==============================] - 3s 35us/sample - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4730 - val_accuracy: 0.7715\n",
      "Epoch 77/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4609 - accuracy: 0.7768 - val_loss: 0.4667 - val_accuracy: 0.7776\n",
      "Epoch 78/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4601 - accuracy: 0.7761 - val_loss: 0.4735 - val_accuracy: 0.7729\n",
      "Epoch 79/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4605 - accuracy: 0.7767 - val_loss: 0.4675 - val_accuracy: 0.7720\n",
      "Epoch 80/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4602 - accuracy: 0.7766 - val_loss: 0.4648 - val_accuracy: 0.7772\n",
      "Epoch 81/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4601 - accuracy: 0.7773 - val_loss: 0.4681 - val_accuracy: 0.7727\n",
      "Epoch 82/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4599 - accuracy: 0.7770 - val_loss: 0.4683 - val_accuracy: 0.7719\n",
      "Epoch 83/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4598 - accuracy: 0.7777 - val_loss: 0.4666 - val_accuracy: 0.7751\n",
      "Epoch 84/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4594 - accuracy: 0.7764 - val_loss: 0.4666 - val_accuracy: 0.7745\n",
      "Epoch 85/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4588 - accuracy: 0.7776 - val_loss: 0.4686 - val_accuracy: 0.7708\n",
      "Epoch 86/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4590 - accuracy: 0.7783 - val_loss: 0.4731 - val_accuracy: 0.7743\n",
      "Epoch 87/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4583 - accuracy: 0.7776 - val_loss: 0.4690 - val_accuracy: 0.7773\n",
      "Epoch 88/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4577 - accuracy: 0.7784 - val_loss: 0.4700 - val_accuracy: 0.7689\n",
      "Epoch 89/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4584 - accuracy: 0.7781 - val_loss: 0.4721 - val_accuracy: 0.7756\n",
      "Epoch 90/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4579 - accuracy: 0.7787 - val_loss: 0.4679 - val_accuracy: 0.7761\n",
      "Epoch 91/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4572 - accuracy: 0.7788 - val_loss: 0.4632 - val_accuracy: 0.7758\n",
      "Epoch 92/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4572 - accuracy: 0.7781 - val_loss: 0.4828 - val_accuracy: 0.7709\n",
      "Epoch 93/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4566 - accuracy: 0.7801 - val_loss: 0.4757 - val_accuracy: 0.7710\n",
      "Epoch 94/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4572 - accuracy: 0.7796 - val_loss: 0.4634 - val_accuracy: 0.7768\n",
      "Epoch 95/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4568 - accuracy: 0.7785 - val_loss: 0.4782 - val_accuracy: 0.7718\n",
      "Epoch 96/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4564 - accuracy: 0.7793 - val_loss: 0.4714 - val_accuracy: 0.7752\n",
      "Epoch 97/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4561 - accuracy: 0.7775 - val_loss: 0.4641 - val_accuracy: 0.7775\n",
      "Epoch 98/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4568 - accuracy: 0.7793 - val_loss: 0.4713 - val_accuracy: 0.7693\n",
      "Epoch 99/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4559 - accuracy: 0.7801 - val_loss: 0.4636 - val_accuracy: 0.7738\n",
      "Epoch 100/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4561 - accuracy: 0.7782 - val_loss: 0.4651 - val_accuracy: 0.7766\n",
      "Epoch 101/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4560 - accuracy: 0.7793 - val_loss: 0.4676 - val_accuracy: 0.7767\n",
      "Epoch 102/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4554 - accuracy: 0.7804 - val_loss: 0.4645 - val_accuracy: 0.7786\n",
      "Epoch 103/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4550 - accuracy: 0.7804 - val_loss: 0.4650 - val_accuracy: 0.7710\n",
      "Epoch 104/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4553 - accuracy: 0.7793 - val_loss: 0.4668 - val_accuracy: 0.7712\n",
      "Epoch 105/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4558 - accuracy: 0.7797 - val_loss: 0.4645 - val_accuracy: 0.7771\n",
      "Epoch 106/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.4660 - val_accuracy: 0.7755\n",
      "Epoch 107/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4541 - accuracy: 0.7813 - val_loss: 0.4635 - val_accuracy: 0.7778\n",
      "Epoch 108/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4541 - accuracy: 0.7804 - val_loss: 0.4663 - val_accuracy: 0.7738\n",
      "Epoch 109/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4545 - accuracy: 0.7810 - val_loss: 0.4648 - val_accuracy: 0.7809\n",
      "Epoch 110/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4538 - accuracy: 0.7811 - val_loss: 0.4705 - val_accuracy: 0.7740\n",
      "Epoch 111/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4543 - accuracy: 0.7808 - val_loss: 0.4604 - val_accuracy: 0.7787\n",
      "Epoch 112/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4545 - accuracy: 0.7814 - val_loss: 0.4574 - val_accuracy: 0.7810\n",
      "Epoch 113/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4539 - accuracy: 0.7816 - val_loss: 0.4626 - val_accuracy: 0.7774\n",
      "Epoch 114/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4539 - accuracy: 0.7815 - val_loss: 0.4712 - val_accuracy: 0.7729\n",
      "Epoch 115/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4541 - accuracy: 0.7809 - val_loss: 0.4707 - val_accuracy: 0.7669\n",
      "Epoch 116/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4534 - accuracy: 0.7811 - val_loss: 0.4729 - val_accuracy: 0.7744\n",
      "Epoch 117/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4532 - accuracy: 0.7814 - val_loss: 0.4605 - val_accuracy: 0.7803\n",
      "Epoch 118/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4535 - accuracy: 0.7825 - val_loss: 0.4654 - val_accuracy: 0.7728\n",
      "Epoch 119/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4529 - accuracy: 0.7825 - val_loss: 0.4624 - val_accuracy: 0.7765\n",
      "Epoch 120/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4527 - accuracy: 0.7832 - val_loss: 0.4724 - val_accuracy: 0.7690\n",
      "Epoch 121/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4531 - accuracy: 0.7827 - val_loss: 0.4625 - val_accuracy: 0.7794\n",
      "Epoch 122/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4524 - accuracy: 0.7820 - val_loss: 0.4635 - val_accuracy: 0.7787\n",
      "Epoch 123/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4524 - accuracy: 0.7828 - val_loss: 0.4641 - val_accuracy: 0.7791\n",
      "Epoch 124/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4528 - accuracy: 0.7832 - val_loss: 0.4779 - val_accuracy: 0.7671\n",
      "Epoch 125/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4522 - accuracy: 0.7827 - val_loss: 0.4676 - val_accuracy: 0.7707\n",
      "Epoch 126/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4524 - accuracy: 0.7824 - val_loss: 0.4702 - val_accuracy: 0.7727\n",
      "Epoch 127/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4519 - accuracy: 0.7821 - val_loss: 0.4573 - val_accuracy: 0.7817\n",
      "Epoch 128/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4525 - accuracy: 0.7823 - val_loss: 0.4630 - val_accuracy: 0.7774\n",
      "Epoch 129/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4519 - accuracy: 0.7826 - val_loss: 0.4634 - val_accuracy: 0.7795\n",
      "Epoch 130/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4514 - accuracy: 0.7831 - val_loss: 0.4606 - val_accuracy: 0.7814\n",
      "Epoch 131/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4511 - accuracy: 0.7833 - val_loss: 0.4650 - val_accuracy: 0.7749\n",
      "Epoch 132/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4516 - accuracy: 0.7825 - val_loss: 0.4636 - val_accuracy: 0.7825\n",
      "Epoch 133/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4516 - accuracy: 0.7816 - val_loss: 0.4604 - val_accuracy: 0.7800\n",
      "Epoch 134/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4509 - accuracy: 0.7843 - val_loss: 0.4691 - val_accuracy: 0.7757\n",
      "Epoch 135/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4516 - accuracy: 0.7838 - val_loss: 0.4688 - val_accuracy: 0.7725\n",
      "Epoch 136/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4511 - accuracy: 0.7833 - val_loss: 0.4606 - val_accuracy: 0.7786\n",
      "Epoch 137/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4512 - accuracy: 0.7831 - val_loss: 0.4627 - val_accuracy: 0.7799\n",
      "Epoch 138/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.4595 - val_accuracy: 0.7805\n",
      "Epoch 139/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4501 - accuracy: 0.7837 - val_loss: 0.4675 - val_accuracy: 0.7728\n",
      "Epoch 140/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4508 - accuracy: 0.7839 - val_loss: 0.4637 - val_accuracy: 0.7792\n",
      "Epoch 141/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4499 - accuracy: 0.7834 - val_loss: 0.4699 - val_accuracy: 0.7745\n",
      "Epoch 142/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4501 - accuracy: 0.7844 - val_loss: 0.4618 - val_accuracy: 0.7771\n",
      "Epoch 143/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4499 - accuracy: 0.7858 - val_loss: 0.4587 - val_accuracy: 0.7790\n",
      "Epoch 144/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4501 - accuracy: 0.7843 - val_loss: 0.4614 - val_accuracy: 0.7820\n",
      "Epoch 145/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4496 - accuracy: 0.7850 - val_loss: 0.4588 - val_accuracy: 0.7819\n",
      "Epoch 146/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4493 - accuracy: 0.7836 - val_loss: 0.4624 - val_accuracy: 0.7786\n",
      "Epoch 147/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4500 - accuracy: 0.7853 - val_loss: 0.4625 - val_accuracy: 0.7785\n",
      "Epoch 148/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4495 - accuracy: 0.7852 - val_loss: 0.4647 - val_accuracy: 0.7835\n",
      "Epoch 149/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4494 - accuracy: 0.7857 - val_loss: 0.4641 - val_accuracy: 0.7778\n",
      "Epoch 150/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.4622 - val_accuracy: 0.7822\n",
      "Epoch 151/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4493 - accuracy: 0.7849 - val_loss: 0.4588 - val_accuracy: 0.7791\n",
      "Epoch 152/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4489 - accuracy: 0.7852 - val_loss: 0.4619 - val_accuracy: 0.7774\n",
      "Epoch 153/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4489 - accuracy: 0.7852 - val_loss: 0.4556 - val_accuracy: 0.7841\n",
      "Epoch 154/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4486 - accuracy: 0.7859 - val_loss: 0.4552 - val_accuracy: 0.7803\n",
      "Epoch 155/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4483 - accuracy: 0.7861 - val_loss: 0.4570 - val_accuracy: 0.7840\n",
      "Epoch 156/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4480 - accuracy: 0.7857 - val_loss: 0.4662 - val_accuracy: 0.7797\n",
      "Epoch 157/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4482 - accuracy: 0.7848 - val_loss: 0.4607 - val_accuracy: 0.7778\n",
      "Epoch 158/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4481 - accuracy: 0.7852 - val_loss: 0.4652 - val_accuracy: 0.7776\n",
      "Epoch 159/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4478 - accuracy: 0.7859 - val_loss: 0.4657 - val_accuracy: 0.7820\n",
      "Epoch 160/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4481 - accuracy: 0.7862 - val_loss: 0.4588 - val_accuracy: 0.7807\n",
      "Epoch 161/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4479 - accuracy: 0.7860 - val_loss: 0.4640 - val_accuracy: 0.7741\n",
      "Epoch 162/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4478 - accuracy: 0.7860 - val_loss: 0.4570 - val_accuracy: 0.7832\n",
      "Epoch 163/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4479 - accuracy: 0.7862 - val_loss: 0.4619 - val_accuracy: 0.7779\n",
      "Epoch 164/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4473 - accuracy: 0.7866 - val_loss: 0.4587 - val_accuracy: 0.7820\n",
      "Epoch 165/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4474 - accuracy: 0.7863 - val_loss: 0.4630 - val_accuracy: 0.7770\n",
      "Epoch 166/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4471 - accuracy: 0.7870 - val_loss: 0.4565 - val_accuracy: 0.7837\n",
      "Epoch 167/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4471 - accuracy: 0.7864 - val_loss: 0.4597 - val_accuracy: 0.7783\n",
      "Epoch 168/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4476 - accuracy: 0.7860 - val_loss: 0.4583 - val_accuracy: 0.7828\n",
      "Epoch 169/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.4578 - val_accuracy: 0.7849\n",
      "Epoch 170/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4466 - accuracy: 0.7873 - val_loss: 0.4719 - val_accuracy: 0.7728\n",
      "Epoch 171/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4467 - accuracy: 0.7870 - val_loss: 0.4620 - val_accuracy: 0.7804\n",
      "Epoch 172/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4470 - accuracy: 0.7863 - val_loss: 0.4610 - val_accuracy: 0.7805\n",
      "Epoch 173/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4467 - accuracy: 0.7867 - val_loss: 0.4580 - val_accuracy: 0.7850\n",
      "Epoch 174/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4475 - accuracy: 0.7871 - val_loss: 0.4670 - val_accuracy: 0.7738\n",
      "Epoch 175/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4464 - accuracy: 0.7870 - val_loss: 0.4576 - val_accuracy: 0.7788\n",
      "Epoch 176/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4469 - accuracy: 0.7868 - val_loss: 0.4560 - val_accuracy: 0.7846\n",
      "Epoch 177/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4466 - accuracy: 0.7878 - val_loss: 0.4559 - val_accuracy: 0.7839\n",
      "Epoch 178/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4468 - accuracy: 0.7865 - val_loss: 0.4575 - val_accuracy: 0.7854\n",
      "Epoch 179/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4470 - accuracy: 0.7855 - val_loss: 0.4560 - val_accuracy: 0.7848\n",
      "Epoch 180/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4464 - accuracy: 0.7872 - val_loss: 0.4563 - val_accuracy: 0.7817\n",
      "Epoch 181/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4460 - accuracy: 0.7878 - val_loss: 0.4586 - val_accuracy: 0.7797\n",
      "Epoch 182/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4458 - accuracy: 0.7861 - val_loss: 0.4583 - val_accuracy: 0.7835\n",
      "Epoch 183/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4458 - accuracy: 0.7872 - val_loss: 0.4556 - val_accuracy: 0.7842\n",
      "Epoch 184/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4458 - accuracy: 0.7887 - val_loss: 0.4614 - val_accuracy: 0.7812\n",
      "Epoch 185/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4460 - accuracy: 0.7863 - val_loss: 0.4572 - val_accuracy: 0.7816\n",
      "Epoch 186/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4454 - accuracy: 0.7873 - val_loss: 0.4553 - val_accuracy: 0.7829\n",
      "Epoch 187/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4454 - accuracy: 0.7885 - val_loss: 0.4571 - val_accuracy: 0.7821\n",
      "Epoch 188/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4602 - val_accuracy: 0.7817\n",
      "Epoch 189/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4456 - accuracy: 0.7878 - val_loss: 0.4626 - val_accuracy: 0.7812\n",
      "Epoch 190/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4452 - accuracy: 0.7875 - val_loss: 0.4587 - val_accuracy: 0.7799\n",
      "Epoch 191/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4453 - accuracy: 0.7891 - val_loss: 0.4650 - val_accuracy: 0.7745\n",
      "Epoch 192/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4447 - accuracy: 0.7875 - val_loss: 0.4611 - val_accuracy: 0.7828\n",
      "Epoch 193/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4454 - accuracy: 0.7878 - val_loss: 0.4645 - val_accuracy: 0.7803\n",
      "Epoch 194/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4456 - accuracy: 0.7878 - val_loss: 0.4636 - val_accuracy: 0.7757\n",
      "Epoch 195/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4453 - accuracy: 0.7866 - val_loss: 0.4541 - val_accuracy: 0.7854\n",
      "Epoch 196/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4445 - accuracy: 0.7881 - val_loss: 0.4537 - val_accuracy: 0.7841\n",
      "Epoch 197/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4454 - accuracy: 0.7881 - val_loss: 0.4656 - val_accuracy: 0.7777\n",
      "Epoch 198/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4450 - accuracy: 0.7881 - val_loss: 0.4564 - val_accuracy: 0.7824\n",
      "Epoch 199/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4452 - accuracy: 0.7877 - val_loss: 0.4752 - val_accuracy: 0.7715\n",
      "Epoch 200/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4449 - accuracy: 0.7888 - val_loss: 0.4566 - val_accuracy: 0.7816\n",
      "Epoch 201/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4446 - accuracy: 0.7880 - val_loss: 0.4612 - val_accuracy: 0.7787\n",
      "Epoch 202/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4444 - accuracy: 0.7885 - val_loss: 0.4620 - val_accuracy: 0.7816\n",
      "Epoch 203/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4450 - accuracy: 0.7877 - val_loss: 0.4596 - val_accuracy: 0.7811\n",
      "Epoch 204/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4448 - accuracy: 0.7872 - val_loss: 0.4552 - val_accuracy: 0.7856\n",
      "Epoch 205/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4442 - accuracy: 0.7889 - val_loss: 0.4557 - val_accuracy: 0.7827\n",
      "Epoch 206/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4444 - accuracy: 0.7875 - val_loss: 0.4603 - val_accuracy: 0.7791\n",
      "Epoch 207/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4443 - accuracy: 0.7886 - val_loss: 0.4548 - val_accuracy: 0.7840\n",
      "Epoch 208/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4445 - accuracy: 0.7881 - val_loss: 0.4547 - val_accuracy: 0.7855\n",
      "Epoch 209/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4442 - accuracy: 0.7877 - val_loss: 0.4555 - val_accuracy: 0.7867\n",
      "Epoch 210/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4444 - accuracy: 0.7881 - val_loss: 0.4534 - val_accuracy: 0.7874\n",
      "Epoch 211/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4443 - accuracy: 0.7883 - val_loss: 0.4510 - val_accuracy: 0.7870\n",
      "Epoch 212/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4437 - accuracy: 0.7885 - val_loss: 0.4511 - val_accuracy: 0.7843\n",
      "Epoch 213/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4444 - accuracy: 0.7874 - val_loss: 0.4536 - val_accuracy: 0.7827\n",
      "Epoch 214/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4440 - accuracy: 0.7895 - val_loss: 0.4639 - val_accuracy: 0.7836\n",
      "Epoch 215/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4436 - accuracy: 0.7887 - val_loss: 0.4526 - val_accuracy: 0.7871\n",
      "Epoch 216/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4440 - accuracy: 0.7878 - val_loss: 0.4640 - val_accuracy: 0.7731\n",
      "Epoch 217/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4430 - accuracy: 0.7886 - val_loss: 0.4641 - val_accuracy: 0.7789\n",
      "Epoch 218/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4436 - accuracy: 0.7886 - val_loss: 0.4625 - val_accuracy: 0.7723\n",
      "Epoch 219/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4436 - accuracy: 0.7885 - val_loss: 0.4598 - val_accuracy: 0.7817\n",
      "Epoch 220/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4432 - accuracy: 0.7891 - val_loss: 0.4586 - val_accuracy: 0.7850\n",
      "Epoch 221/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4438 - accuracy: 0.7886 - val_loss: 0.4540 - val_accuracy: 0.7824\n",
      "Epoch 222/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4426 - accuracy: 0.7901 - val_loss: 0.4530 - val_accuracy: 0.7827\n",
      "Epoch 223/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4431 - accuracy: 0.7892 - val_loss: 0.4533 - val_accuracy: 0.7852\n",
      "Epoch 224/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4432 - accuracy: 0.7893 - val_loss: 0.4597 - val_accuracy: 0.7781\n",
      "Epoch 225/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4428 - accuracy: 0.7898 - val_loss: 0.4609 - val_accuracy: 0.7827\n",
      "Epoch 226/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4431 - accuracy: 0.7883 - val_loss: 0.4559 - val_accuracy: 0.7813\n",
      "Epoch 227/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4431 - accuracy: 0.7891 - val_loss: 0.4634 - val_accuracy: 0.7778\n",
      "Epoch 228/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4426 - accuracy: 0.7895 - val_loss: 0.4516 - val_accuracy: 0.7869\n",
      "Epoch 229/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4423 - accuracy: 0.7891 - val_loss: 0.4540 - val_accuracy: 0.7813\n",
      "Epoch 230/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4430 - accuracy: 0.7888 - val_loss: 0.4537 - val_accuracy: 0.7847\n",
      "Epoch 231/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4427 - accuracy: 0.7890 - val_loss: 0.4579 - val_accuracy: 0.7847\n",
      "Epoch 232/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4422 - accuracy: 0.7894 - val_loss: 0.4511 - val_accuracy: 0.7847\n",
      "Epoch 233/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4430 - accuracy: 0.7894 - val_loss: 0.4527 - val_accuracy: 0.7873\n",
      "Epoch 234/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4430 - accuracy: 0.7896 - val_loss: 0.4679 - val_accuracy: 0.7751\n",
      "Epoch 235/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4428 - accuracy: 0.7901 - val_loss: 0.4524 - val_accuracy: 0.7858\n",
      "Epoch 236/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4426 - accuracy: 0.7888 - val_loss: 0.4564 - val_accuracy: 0.7829\n",
      "Epoch 237/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4419 - accuracy: 0.7893 - val_loss: 0.4585 - val_accuracy: 0.7834\n",
      "Epoch 238/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4424 - accuracy: 0.7887 - val_loss: 0.4479 - val_accuracy: 0.7889\n",
      "Epoch 239/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4429 - accuracy: 0.7896 - val_loss: 0.4509 - val_accuracy: 0.7859\n",
      "Epoch 240/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4426 - accuracy: 0.7904 - val_loss: 0.4532 - val_accuracy: 0.7844\n",
      "Epoch 241/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4528 - val_accuracy: 0.7869\n",
      "Epoch 242/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4418 - accuracy: 0.7908 - val_loss: 0.4529 - val_accuracy: 0.7842\n",
      "Epoch 243/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4423 - accuracy: 0.7896 - val_loss: 0.4652 - val_accuracy: 0.7851\n",
      "Epoch 244/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4420 - accuracy: 0.7891 - val_loss: 0.4572 - val_accuracy: 0.7846\n",
      "Epoch 245/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4428 - accuracy: 0.7886 - val_loss: 0.4482 - val_accuracy: 0.7886\n",
      "Epoch 246/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4426 - accuracy: 0.7908 - val_loss: 0.4594 - val_accuracy: 0.7821\n",
      "Epoch 247/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4418 - accuracy: 0.7892 - val_loss: 0.4538 - val_accuracy: 0.7871\n",
      "Epoch 248/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4425 - accuracy: 0.7888 - val_loss: 0.4544 - val_accuracy: 0.7868\n",
      "Epoch 249/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4416 - accuracy: 0.7909 - val_loss: 0.4516 - val_accuracy: 0.7863\n",
      "Epoch 250/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4420 - accuracy: 0.7907 - val_loss: 0.4488 - val_accuracy: 0.7891\n",
      "Epoch 251/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4421 - accuracy: 0.7893 - val_loss: 0.4554 - val_accuracy: 0.7892\n",
      "Epoch 252/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4412 - accuracy: 0.7906 - val_loss: 0.4558 - val_accuracy: 0.7814\n",
      "Epoch 253/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4409 - accuracy: 0.7906 - val_loss: 0.4519 - val_accuracy: 0.7870\n",
      "Epoch 254/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4416 - accuracy: 0.7901 - val_loss: 0.4559 - val_accuracy: 0.7833\n",
      "Epoch 255/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4419 - accuracy: 0.7895 - val_loss: 0.4516 - val_accuracy: 0.7887\n",
      "Epoch 256/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4410 - accuracy: 0.7911 - val_loss: 0.4538 - val_accuracy: 0.7839\n",
      "Epoch 257/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4415 - accuracy: 0.7898 - val_loss: 0.4614 - val_accuracy: 0.7851\n",
      "Epoch 258/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4412 - accuracy: 0.7907 - val_loss: 0.4495 - val_accuracy: 0.7894\n",
      "Epoch 259/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4411 - accuracy: 0.7904 - val_loss: 0.4563 - val_accuracy: 0.7837\n",
      "Epoch 260/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4408 - accuracy: 0.7908 - val_loss: 0.4521 - val_accuracy: 0.7873\n",
      "Epoch 261/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4415 - accuracy: 0.7902 - val_loss: 0.4594 - val_accuracy: 0.7794\n",
      "Epoch 262/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4413 - accuracy: 0.7900 - val_loss: 0.4554 - val_accuracy: 0.7851\n",
      "Epoch 263/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4414 - accuracy: 0.7910 - val_loss: 0.4495 - val_accuracy: 0.7891\n",
      "Epoch 264/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4406 - accuracy: 0.7898 - val_loss: 0.4608 - val_accuracy: 0.7831\n",
      "Epoch 265/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4408 - accuracy: 0.7907 - val_loss: 0.4538 - val_accuracy: 0.7851\n",
      "Epoch 266/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4405 - accuracy: 0.7912 - val_loss: 0.4510 - val_accuracy: 0.7876\n",
      "Epoch 267/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4414 - accuracy: 0.7900 - val_loss: 0.4519 - val_accuracy: 0.7850\n",
      "Epoch 268/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4410 - accuracy: 0.7914 - val_loss: 0.4531 - val_accuracy: 0.7836\n",
      "Epoch 269/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4405 - accuracy: 0.7913 - val_loss: 0.4585 - val_accuracy: 0.7864\n",
      "Epoch 270/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4408 - accuracy: 0.7911 - val_loss: 0.4511 - val_accuracy: 0.7893\n",
      "Epoch 271/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4398 - accuracy: 0.7922 - val_loss: 0.4556 - val_accuracy: 0.7825\n",
      "Epoch 272/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4405 - accuracy: 0.7910 - val_loss: 0.4540 - val_accuracy: 0.7844\n",
      "Epoch 273/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4405 - accuracy: 0.7912 - val_loss: 0.4544 - val_accuracy: 0.7851\n",
      "Epoch 274/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4402 - accuracy: 0.7905 - val_loss: 0.4537 - val_accuracy: 0.7887\n",
      "Epoch 275/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4399 - accuracy: 0.7907 - val_loss: 0.4582 - val_accuracy: 0.7883\n",
      "Epoch 276/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4399 - accuracy: 0.7918 - val_loss: 0.4568 - val_accuracy: 0.7881\n",
      "Epoch 277/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4406 - accuracy: 0.7905 - val_loss: 0.4534 - val_accuracy: 0.7825\n",
      "Epoch 278/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4407 - accuracy: 0.7905 - val_loss: 0.4508 - val_accuracy: 0.7868\n",
      "Epoch 279/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4395 - accuracy: 0.7914 - val_loss: 0.4535 - val_accuracy: 0.7857\n",
      "Epoch 280/500\n",
      "92096/92096 [==============================] - 3s 32us/sample - loss: 0.4402 - accuracy: 0.7916 - val_loss: 0.4519 - val_accuracy: 0.7862\n",
      "Epoch 281/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.4586 - val_accuracy: 0.7834\n",
      "Epoch 282/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4401 - accuracy: 0.7912 - val_loss: 0.4577 - val_accuracy: 0.7860\n",
      "Epoch 283/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4401 - accuracy: 0.7908 - val_loss: 0.4599 - val_accuracy: 0.7819\n",
      "Epoch 284/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4398 - accuracy: 0.7906 - val_loss: 0.4511 - val_accuracy: 0.7883\n",
      "Epoch 285/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4397 - accuracy: 0.7922 - val_loss: 0.4522 - val_accuracy: 0.7856\n",
      "Epoch 286/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4393 - accuracy: 0.7920 - val_loss: 0.4536 - val_accuracy: 0.7871\n",
      "Epoch 287/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4394 - accuracy: 0.7918 - val_loss: 0.4514 - val_accuracy: 0.7877\n",
      "Epoch 288/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4393 - accuracy: 0.7919 - val_loss: 0.4553 - val_accuracy: 0.7834\n",
      "Epoch 289/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4397 - accuracy: 0.7909 - val_loss: 0.4505 - val_accuracy: 0.7887\n",
      "Epoch 290/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4393 - accuracy: 0.7914 - val_loss: 0.4526 - val_accuracy: 0.7864\n",
      "Epoch 291/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4398 - accuracy: 0.7908 - val_loss: 0.4529 - val_accuracy: 0.7857\n",
      "Epoch 292/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4396 - accuracy: 0.7920 - val_loss: 0.4553 - val_accuracy: 0.7813\n",
      "Epoch 293/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4395 - accuracy: 0.7917 - val_loss: 0.4549 - val_accuracy: 0.7830\n",
      "Epoch 294/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4400 - accuracy: 0.7903 - val_loss: 0.4639 - val_accuracy: 0.7835\n",
      "Epoch 295/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4396 - accuracy: 0.7906 - val_loss: 0.4520 - val_accuracy: 0.7885\n",
      "Epoch 296/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4392 - accuracy: 0.7906 - val_loss: 0.4531 - val_accuracy: 0.7859\n",
      "Epoch 297/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4395 - accuracy: 0.7915 - val_loss: 0.4487 - val_accuracy: 0.7896\n",
      "Epoch 298/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4391 - accuracy: 0.7914 - val_loss: 0.4502 - val_accuracy: 0.7857\n",
      "Epoch 299/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4389 - accuracy: 0.7930 - val_loss: 0.4485 - val_accuracy: 0.7896\n",
      "Epoch 300/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4387 - accuracy: 0.7923 - val_loss: 0.4571 - val_accuracy: 0.7843\n",
      "Epoch 301/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4391 - accuracy: 0.7919 - val_loss: 0.4467 - val_accuracy: 0.7898\n",
      "Epoch 302/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4391 - accuracy: 0.7918 - val_loss: 0.4499 - val_accuracy: 0.7881\n",
      "Epoch 303/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4398 - accuracy: 0.7911 - val_loss: 0.4503 - val_accuracy: 0.7857\n",
      "Epoch 304/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4384 - accuracy: 0.7914 - val_loss: 0.4471 - val_accuracy: 0.7904\n",
      "Epoch 305/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4390 - accuracy: 0.7916 - val_loss: 0.4522 - val_accuracy: 0.7882\n",
      "Epoch 306/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4383 - accuracy: 0.7926 - val_loss: 0.4531 - val_accuracy: 0.7860\n",
      "Epoch 307/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4389 - accuracy: 0.7914 - val_loss: 0.4516 - val_accuracy: 0.7868\n",
      "Epoch 308/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4379 - accuracy: 0.7925 - val_loss: 0.4507 - val_accuracy: 0.7887\n",
      "Epoch 309/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4385 - accuracy: 0.7916 - val_loss: 0.4581 - val_accuracy: 0.7828\n",
      "Epoch 310/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4382 - accuracy: 0.7931 - val_loss: 0.4515 - val_accuracy: 0.7877\n",
      "Epoch 311/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4383 - accuracy: 0.7927 - val_loss: 0.4529 - val_accuracy: 0.7901\n",
      "Epoch 312/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4388 - accuracy: 0.7916 - val_loss: 0.4495 - val_accuracy: 0.7890\n",
      "Epoch 313/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4386 - accuracy: 0.7915 - val_loss: 0.4515 - val_accuracy: 0.7925\n",
      "Epoch 314/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4381 - accuracy: 0.7933 - val_loss: 0.4641 - val_accuracy: 0.7788\n",
      "Epoch 315/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4395 - accuracy: 0.7918 - val_loss: 0.4498 - val_accuracy: 0.7878\n",
      "Epoch 316/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.4548 - val_accuracy: 0.7848\n",
      "Epoch 317/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4381 - accuracy: 0.7926 - val_loss: 0.4532 - val_accuracy: 0.7885\n",
      "Epoch 318/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4381 - accuracy: 0.7923 - val_loss: 0.4506 - val_accuracy: 0.7875\n",
      "Epoch 319/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4380 - accuracy: 0.7928 - val_loss: 0.4501 - val_accuracy: 0.7885\n",
      "Epoch 320/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4384 - accuracy: 0.7925 - val_loss: 0.4488 - val_accuracy: 0.7898\n",
      "Epoch 321/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4386 - accuracy: 0.7919 - val_loss: 0.4505 - val_accuracy: 0.7890\n",
      "Epoch 322/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4377 - accuracy: 0.7924 - val_loss: 0.4500 - val_accuracy: 0.7901\n",
      "Epoch 323/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4384 - accuracy: 0.7933 - val_loss: 0.4471 - val_accuracy: 0.7905\n",
      "Epoch 324/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4382 - accuracy: 0.7924 - val_loss: 0.4591 - val_accuracy: 0.7809\n",
      "Epoch 325/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4381 - accuracy: 0.7927 - val_loss: 0.4528 - val_accuracy: 0.7907\n",
      "Epoch 326/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4380 - accuracy: 0.7927 - val_loss: 0.4491 - val_accuracy: 0.7885\n",
      "Epoch 327/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4379 - accuracy: 0.7935 - val_loss: 0.4560 - val_accuracy: 0.7813\n",
      "Epoch 328/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4383 - accuracy: 0.7932 - val_loss: 0.4475 - val_accuracy: 0.7890\n",
      "Epoch 329/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4377 - accuracy: 0.7924 - val_loss: 0.4488 - val_accuracy: 0.7893\n",
      "Epoch 330/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4379 - accuracy: 0.7933 - val_loss: 0.4505 - val_accuracy: 0.7865\n",
      "Epoch 331/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4373 - accuracy: 0.7927 - val_loss: 0.4629 - val_accuracy: 0.7783\n",
      "Epoch 332/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4374 - accuracy: 0.7936 - val_loss: 0.4487 - val_accuracy: 0.7864\n",
      "Epoch 333/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4373 - accuracy: 0.7923 - val_loss: 0.4491 - val_accuracy: 0.7869\n",
      "Epoch 334/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4381 - accuracy: 0.7930 - val_loss: 0.4474 - val_accuracy: 0.7914\n",
      "Epoch 335/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4374 - accuracy: 0.7922 - val_loss: 0.4475 - val_accuracy: 0.7894\n",
      "Epoch 336/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4377 - accuracy: 0.7925 - val_loss: 0.4550 - val_accuracy: 0.7828\n",
      "Epoch 337/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4372 - accuracy: 0.7935 - val_loss: 0.4474 - val_accuracy: 0.7886\n",
      "Epoch 338/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4375 - accuracy: 0.7925 - val_loss: 0.4512 - val_accuracy: 0.7901\n",
      "Epoch 339/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4380 - accuracy: 0.7930 - val_loss: 0.4570 - val_accuracy: 0.7842\n",
      "Epoch 340/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4375 - accuracy: 0.7930 - val_loss: 0.4494 - val_accuracy: 0.7872\n",
      "Epoch 341/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4381 - accuracy: 0.7927 - val_loss: 0.4483 - val_accuracy: 0.7890\n",
      "Epoch 342/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4367 - accuracy: 0.7933 - val_loss: 0.4563 - val_accuracy: 0.7852\n",
      "Epoch 343/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4374 - accuracy: 0.7939 - val_loss: 0.4476 - val_accuracy: 0.7902\n",
      "Epoch 344/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4380 - accuracy: 0.7925 - val_loss: 0.4517 - val_accuracy: 0.7860\n",
      "Epoch 345/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4367 - accuracy: 0.7933 - val_loss: 0.4487 - val_accuracy: 0.7926\n",
      "Epoch 346/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4373 - accuracy: 0.7931 - val_loss: 0.4588 - val_accuracy: 0.7851\n",
      "Epoch 347/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4374 - accuracy: 0.7928 - val_loss: 0.4457 - val_accuracy: 0.7923\n",
      "Epoch 348/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4368 - accuracy: 0.7935 - val_loss: 0.4491 - val_accuracy: 0.7880\n",
      "Epoch 349/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4367 - accuracy: 0.7939 - val_loss: 0.4483 - val_accuracy: 0.7907\n",
      "Epoch 350/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4373 - accuracy: 0.7939 - val_loss: 0.4494 - val_accuracy: 0.7887\n",
      "Epoch 351/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4474 - val_accuracy: 0.7916\n",
      "Epoch 352/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4364 - accuracy: 0.7933 - val_loss: 0.4582 - val_accuracy: 0.7867\n",
      "Epoch 353/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4365 - accuracy: 0.7935 - val_loss: 0.4678 - val_accuracy: 0.7687\n",
      "Epoch 354/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4367 - accuracy: 0.7933 - val_loss: 0.4499 - val_accuracy: 0.7862\n",
      "Epoch 355/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4539 - val_accuracy: 0.7874\n",
      "Epoch 356/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4368 - accuracy: 0.7931 - val_loss: 0.4585 - val_accuracy: 0.7831\n",
      "Epoch 357/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4366 - accuracy: 0.7931 - val_loss: 0.4551 - val_accuracy: 0.7841\n",
      "Epoch 358/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4362 - accuracy: 0.7930 - val_loss: 0.4515 - val_accuracy: 0.7893\n",
      "Epoch 359/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4364 - accuracy: 0.7936 - val_loss: 0.4483 - val_accuracy: 0.7913\n",
      "Epoch 360/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4368 - accuracy: 0.7933 - val_loss: 0.4497 - val_accuracy: 0.7902\n",
      "Epoch 361/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4362 - accuracy: 0.7943 - val_loss: 0.4458 - val_accuracy: 0.7908\n",
      "Epoch 362/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4363 - accuracy: 0.7936 - val_loss: 0.4517 - val_accuracy: 0.7870\n",
      "Epoch 363/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4362 - accuracy: 0.7959 - val_loss: 0.4499 - val_accuracy: 0.7901\n",
      "Epoch 364/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.4512 - val_accuracy: 0.7901\n",
      "Epoch 365/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7928 - val_loss: 0.4493 - val_accuracy: 0.7907\n",
      "Epoch 366/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4365 - accuracy: 0.7938 - val_loss: 0.4577 - val_accuracy: 0.7842\n",
      "Epoch 367/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4363 - accuracy: 0.7943 - val_loss: 0.4508 - val_accuracy: 0.7879\n",
      "Epoch 368/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4359 - accuracy: 0.7940 - val_loss: 0.4471 - val_accuracy: 0.7906\n",
      "Epoch 369/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4363 - accuracy: 0.7939 - val_loss: 0.4442 - val_accuracy: 0.7921\n",
      "Epoch 370/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4360 - accuracy: 0.7948 - val_loss: 0.4465 - val_accuracy: 0.7899\n",
      "Epoch 371/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7937 - val_loss: 0.4458 - val_accuracy: 0.7893\n",
      "Epoch 372/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4360 - accuracy: 0.7929 - val_loss: 0.4491 - val_accuracy: 0.7893\n",
      "Epoch 373/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.4495 - val_accuracy: 0.7884\n",
      "Epoch 374/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7933 - val_loss: 0.4532 - val_accuracy: 0.7872\n",
      "Epoch 375/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4362 - accuracy: 0.7939 - val_loss: 0.4544 - val_accuracy: 0.7854\n",
      "Epoch 376/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4362 - accuracy: 0.7940 - val_loss: 0.4535 - val_accuracy: 0.7844\n",
      "Epoch 377/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4356 - accuracy: 0.7942 - val_loss: 0.4474 - val_accuracy: 0.7917\n",
      "Epoch 378/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4359 - accuracy: 0.7928 - val_loss: 0.4467 - val_accuracy: 0.7943\n",
      "Epoch 379/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4360 - accuracy: 0.7936 - val_loss: 0.4519 - val_accuracy: 0.7897\n",
      "Epoch 380/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4369 - accuracy: 0.7931 - val_loss: 0.4499 - val_accuracy: 0.7901\n",
      "Epoch 381/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4355 - accuracy: 0.7932 - val_loss: 0.4502 - val_accuracy: 0.7909\n",
      "Epoch 382/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4356 - accuracy: 0.7938 - val_loss: 0.4587 - val_accuracy: 0.7839\n",
      "Epoch 383/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4364 - accuracy: 0.7935 - val_loss: 0.4456 - val_accuracy: 0.7930\n",
      "Epoch 384/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4361 - accuracy: 0.7933 - val_loss: 0.4471 - val_accuracy: 0.7911\n",
      "Epoch 385/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4352 - accuracy: 0.7947 - val_loss: 0.4569 - val_accuracy: 0.7824\n",
      "Epoch 386/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4356 - accuracy: 0.7941 - val_loss: 0.4527 - val_accuracy: 0.7897\n",
      "Epoch 387/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7929 - val_loss: 0.4478 - val_accuracy: 0.7882\n",
      "Epoch 388/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4354 - accuracy: 0.7953 - val_loss: 0.4552 - val_accuracy: 0.7857\n",
      "Epoch 389/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4355 - accuracy: 0.7948 - val_loss: 0.4507 - val_accuracy: 0.7885\n",
      "Epoch 390/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4517 - val_accuracy: 0.7890\n",
      "Epoch 391/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4358 - accuracy: 0.7947 - val_loss: 0.4456 - val_accuracy: 0.7912\n",
      "Epoch 392/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4355 - accuracy: 0.7943 - val_loss: 0.4470 - val_accuracy: 0.7930\n",
      "Epoch 393/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7935 - val_loss: 0.4481 - val_accuracy: 0.7902\n",
      "Epoch 394/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4351 - accuracy: 0.7941 - val_loss: 0.4505 - val_accuracy: 0.7854\n",
      "Epoch 395/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4350 - accuracy: 0.7943 - val_loss: 0.4515 - val_accuracy: 0.7891\n",
      "Epoch 396/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4360 - accuracy: 0.7939 - val_loss: 0.4480 - val_accuracy: 0.7896\n",
      "Epoch 397/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4352 - accuracy: 0.7933 - val_loss: 0.4473 - val_accuracy: 0.7910\n",
      "Epoch 398/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4356 - accuracy: 0.7929 - val_loss: 0.4454 - val_accuracy: 0.7913\n",
      "Epoch 399/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4351 - accuracy: 0.7931 - val_loss: 0.4509 - val_accuracy: 0.7884\n",
      "Epoch 400/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4352 - accuracy: 0.7944 - val_loss: 0.4506 - val_accuracy: 0.7871\n",
      "Epoch 401/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.4517 - val_accuracy: 0.7865\n",
      "Epoch 402/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4345 - accuracy: 0.7943 - val_loss: 0.4462 - val_accuracy: 0.7923\n",
      "Epoch 403/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4345 - accuracy: 0.7948 - val_loss: 0.4536 - val_accuracy: 0.7844\n",
      "Epoch 404/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4353 - accuracy: 0.7939 - val_loss: 0.4476 - val_accuracy: 0.7900\n",
      "Epoch 405/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4346 - accuracy: 0.7935 - val_loss: 0.4540 - val_accuracy: 0.7878\n",
      "Epoch 406/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4349 - accuracy: 0.7946 - val_loss: 0.4523 - val_accuracy: 0.7846\n",
      "Epoch 407/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4352 - accuracy: 0.7946 - val_loss: 0.4490 - val_accuracy: 0.7884\n",
      "Epoch 408/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4351 - accuracy: 0.7950 - val_loss: 0.4537 - val_accuracy: 0.7877\n",
      "Epoch 409/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4343 - accuracy: 0.7942 - val_loss: 0.4534 - val_accuracy: 0.7801\n",
      "Epoch 410/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4347 - accuracy: 0.7943 - val_loss: 0.4447 - val_accuracy: 0.7966\n",
      "Epoch 411/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4515 - val_accuracy: 0.7904\n",
      "Epoch 412/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4348 - accuracy: 0.7943 - val_loss: 0.4549 - val_accuracy: 0.7821\n",
      "Epoch 413/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4350 - accuracy: 0.7945 - val_loss: 0.4490 - val_accuracy: 0.7897\n",
      "Epoch 414/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4479 - val_accuracy: 0.7904\n",
      "Epoch 415/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4345 - accuracy: 0.7945 - val_loss: 0.4554 - val_accuracy: 0.7825\n",
      "Epoch 416/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4342 - accuracy: 0.7950 - val_loss: 0.4449 - val_accuracy: 0.7905\n",
      "Epoch 417/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4343 - accuracy: 0.7947 - val_loss: 0.4456 - val_accuracy: 0.7909\n",
      "Epoch 418/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4346 - accuracy: 0.7956 - val_loss: 0.4491 - val_accuracy: 0.7878\n",
      "Epoch 419/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4677 - val_accuracy: 0.7851\n",
      "Epoch 420/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4347 - accuracy: 0.7948 - val_loss: 0.4508 - val_accuracy: 0.7885\n",
      "Epoch 421/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4350 - accuracy: 0.7942 - val_loss: 0.4559 - val_accuracy: 0.7783\n",
      "Epoch 422/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4348 - accuracy: 0.7942 - val_loss: 0.4567 - val_accuracy: 0.7851\n",
      "Epoch 423/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4345 - accuracy: 0.7945 - val_loss: 0.4593 - val_accuracy: 0.7805\n",
      "Epoch 424/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4343 - accuracy: 0.7954 - val_loss: 0.4490 - val_accuracy: 0.7874\n",
      "Epoch 425/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4348 - accuracy: 0.7950 - val_loss: 0.4462 - val_accuracy: 0.7938\n",
      "Epoch 426/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4346 - accuracy: 0.7952 - val_loss: 0.4445 - val_accuracy: 0.7920\n",
      "Epoch 427/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4339 - accuracy: 0.7947 - val_loss: 0.4517 - val_accuracy: 0.7865\n",
      "Epoch 428/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4339 - accuracy: 0.7940 - val_loss: 0.4533 - val_accuracy: 0.7879\n",
      "Epoch 429/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4349 - accuracy: 0.7958 - val_loss: 0.4462 - val_accuracy: 0.7925\n",
      "Epoch 430/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4336 - accuracy: 0.7961 - val_loss: 0.4427 - val_accuracy: 0.7946\n",
      "Epoch 431/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4344 - accuracy: 0.7954 - val_loss: 0.4502 - val_accuracy: 0.7879\n",
      "Epoch 432/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4335 - accuracy: 0.7958 - val_loss: 0.4547 - val_accuracy: 0.7865\n",
      "Epoch 433/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4342 - accuracy: 0.7942 - val_loss: 0.4463 - val_accuracy: 0.7886\n",
      "Epoch 434/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4339 - accuracy: 0.7957 - val_loss: 0.4446 - val_accuracy: 0.7931\n",
      "Epoch 435/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4335 - accuracy: 0.7953 - val_loss: 0.4458 - val_accuracy: 0.7890\n",
      "Epoch 436/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4341 - accuracy: 0.7949 - val_loss: 0.4585 - val_accuracy: 0.7878\n",
      "Epoch 437/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4342 - accuracy: 0.7941 - val_loss: 0.4457 - val_accuracy: 0.7925\n",
      "Epoch 438/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4339 - accuracy: 0.7958 - val_loss: 0.4481 - val_accuracy: 0.7883\n",
      "Epoch 439/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4340 - accuracy: 0.7952 - val_loss: 0.4467 - val_accuracy: 0.7936\n",
      "Epoch 440/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4337 - accuracy: 0.7959 - val_loss: 0.4482 - val_accuracy: 0.7890\n",
      "Epoch 441/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4340 - accuracy: 0.7955 - val_loss: 0.4455 - val_accuracy: 0.7884\n",
      "Epoch 442/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4340 - accuracy: 0.7955 - val_loss: 0.4580 - val_accuracy: 0.7802\n",
      "Epoch 443/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4331 - accuracy: 0.7952 - val_loss: 0.4482 - val_accuracy: 0.7887\n",
      "Epoch 444/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4337 - accuracy: 0.7960 - val_loss: 0.4468 - val_accuracy: 0.7912\n",
      "Epoch 445/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4339 - accuracy: 0.7955 - val_loss: 0.4461 - val_accuracy: 0.7905\n",
      "Epoch 446/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4335 - accuracy: 0.7955 - val_loss: 0.4457 - val_accuracy: 0.7939\n",
      "Epoch 447/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4342 - accuracy: 0.7948 - val_loss: 0.4512 - val_accuracy: 0.7880\n",
      "Epoch 448/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4344 - accuracy: 0.7946 - val_loss: 0.4472 - val_accuracy: 0.7895\n",
      "Epoch 449/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4334 - accuracy: 0.7965 - val_loss: 0.4501 - val_accuracy: 0.7890\n",
      "Epoch 450/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4337 - accuracy: 0.7956 - val_loss: 0.4487 - val_accuracy: 0.7911\n",
      "Epoch 451/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4335 - accuracy: 0.7956 - val_loss: 0.4483 - val_accuracy: 0.7867\n",
      "Epoch 452/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4335 - accuracy: 0.7946 - val_loss: 0.4506 - val_accuracy: 0.7881\n",
      "Epoch 453/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4328 - accuracy: 0.7963 - val_loss: 0.4495 - val_accuracy: 0.7886\n",
      "Epoch 454/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4335 - accuracy: 0.7953 - val_loss: 0.4471 - val_accuracy: 0.7918\n",
      "Epoch 455/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4335 - accuracy: 0.7945 - val_loss: 0.4451 - val_accuracy: 0.7933\n",
      "Epoch 456/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4337 - accuracy: 0.7945 - val_loss: 0.4476 - val_accuracy: 0.7881\n",
      "Epoch 457/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4337 - accuracy: 0.7952 - val_loss: 0.4458 - val_accuracy: 0.7917\n",
      "Epoch 458/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4338 - accuracy: 0.7958 - val_loss: 0.4521 - val_accuracy: 0.7837\n",
      "Epoch 459/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4329 - accuracy: 0.7957 - val_loss: 0.4457 - val_accuracy: 0.7947\n",
      "Epoch 460/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4340 - accuracy: 0.7954 - val_loss: 0.4430 - val_accuracy: 0.7942\n",
      "Epoch 461/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4331 - accuracy: 0.7957 - val_loss: 0.4465 - val_accuracy: 0.7909\n",
      "Epoch 462/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4333 - accuracy: 0.7958 - val_loss: 0.4475 - val_accuracy: 0.7877\n",
      "Epoch 463/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.4476 - val_accuracy: 0.7925\n",
      "Epoch 464/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4333 - accuracy: 0.7955 - val_loss: 0.4469 - val_accuracy: 0.7941\n",
      "Epoch 465/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4334 - accuracy: 0.7958 - val_loss: 0.4476 - val_accuracy: 0.7903\n",
      "Epoch 466/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4332 - accuracy: 0.7953 - val_loss: 0.4488 - val_accuracy: 0.7879\n",
      "Epoch 467/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4328 - accuracy: 0.7958 - val_loss: 0.4524 - val_accuracy: 0.7829\n",
      "Epoch 468/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4330 - accuracy: 0.7960 - val_loss: 0.4474 - val_accuracy: 0.7891\n",
      "Epoch 469/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4330 - accuracy: 0.7951 - val_loss: 0.4507 - val_accuracy: 0.7878\n",
      "Epoch 470/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4336 - accuracy: 0.7954 - val_loss: 0.4561 - val_accuracy: 0.7860\n",
      "Epoch 471/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4332 - accuracy: 0.7962 - val_loss: 0.4471 - val_accuracy: 0.7921\n",
      "Epoch 472/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4329 - accuracy: 0.7956 - val_loss: 0.4539 - val_accuracy: 0.7934\n",
      "Epoch 473/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4325 - accuracy: 0.7960 - val_loss: 0.4453 - val_accuracy: 0.7939\n",
      "Epoch 474/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4325 - accuracy: 0.7966 - val_loss: 0.4555 - val_accuracy: 0.7868\n",
      "Epoch 475/500\n",
      "92096/92096 [==============================] - 4s 41us/sample - loss: 0.4327 - accuracy: 0.7954 - val_loss: 0.4455 - val_accuracy: 0.7926\n",
      "Epoch 476/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4324 - accuracy: 0.7954 - val_loss: 0.4462 - val_accuracy: 0.7920\n",
      "Epoch 477/500\n",
      "92096/92096 [==============================] - 3s 31us/sample - loss: 0.4333 - accuracy: 0.7954 - val_loss: 0.4443 - val_accuracy: 0.7949\n",
      "Epoch 478/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4326 - accuracy: 0.7955 - val_loss: 0.4516 - val_accuracy: 0.7845\n",
      "Epoch 479/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4328 - accuracy: 0.7959 - val_loss: 0.4454 - val_accuracy: 0.7906\n",
      "Epoch 480/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4324 - accuracy: 0.7956 - val_loss: 0.4429 - val_accuracy: 0.7949\n",
      "Epoch 481/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4333 - accuracy: 0.7953 - val_loss: 0.4485 - val_accuracy: 0.7918\n",
      "Epoch 482/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4323 - accuracy: 0.7955 - val_loss: 0.4470 - val_accuracy: 0.7917\n",
      "Epoch 483/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4320 - accuracy: 0.7956 - val_loss: 0.4523 - val_accuracy: 0.7897\n",
      "Epoch 484/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4328 - accuracy: 0.7963 - val_loss: 0.4466 - val_accuracy: 0.7950\n",
      "Epoch 485/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4322 - accuracy: 0.7964 - val_loss: 0.4475 - val_accuracy: 0.7925\n",
      "Epoch 486/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4324 - accuracy: 0.7956 - val_loss: 0.4425 - val_accuracy: 0.7947\n",
      "Epoch 487/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4324 - accuracy: 0.7960 - val_loss: 0.4452 - val_accuracy: 0.7920\n",
      "Epoch 488/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4324 - accuracy: 0.7963 - val_loss: 0.4486 - val_accuracy: 0.7907\n",
      "Epoch 489/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.4448 - val_accuracy: 0.7907\n",
      "Epoch 490/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4323 - accuracy: 0.7962 - val_loss: 0.4483 - val_accuracy: 0.7880\n",
      "Epoch 491/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4322 - accuracy: 0.7965 - val_loss: 0.4469 - val_accuracy: 0.7902\n",
      "Epoch 492/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4322 - accuracy: 0.7962 - val_loss: 0.4461 - val_accuracy: 0.7910\n",
      "Epoch 493/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4322 - accuracy: 0.7959 - val_loss: 0.4450 - val_accuracy: 0.7921\n",
      "Epoch 494/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4324 - accuracy: 0.7953 - val_loss: 0.4486 - val_accuracy: 0.7862\n",
      "Epoch 495/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4332 - accuracy: 0.7953 - val_loss: 0.4456 - val_accuracy: 0.7880\n",
      "Epoch 496/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4319 - accuracy: 0.7961 - val_loss: 0.4439 - val_accuracy: 0.7905\n",
      "Epoch 497/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4322 - accuracy: 0.7970 - val_loss: 0.4476 - val_accuracy: 0.7898\n",
      "Epoch 498/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4327 - accuracy: 0.7968 - val_loss: 0.4505 - val_accuracy: 0.7850\n",
      "Epoch 499/500\n",
      "92096/92096 [==============================] - 3s 30us/sample - loss: 0.4325 - accuracy: 0.7959 - val_loss: 0.4459 - val_accuracy: 0.7926\n",
      "Epoch 500/500\n",
      "92096/92096 [==============================] - 3s 29us/sample - loss: 0.4324 - accuracy: 0.7957 - val_loss: 0.4483 - val_accuracy: 0.7879\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(shuffle(pd.DataFrame(x_train_resampled),random_state=1), shuffle(pd.DataFrame(y_train_resampled),random_state=1), epochs=500,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train_resampled)\n",
    "test_predictions = model.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = pd.DataFrame(np.around(test_predictions))[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('Submission/Submission_7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MlChallenge3",
   "language": "python",
   "name": "mlchallenge3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
